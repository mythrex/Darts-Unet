{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLD9kfyhk_kX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "# import torch\n",
    "import logging\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLKwgbKYrJ9D"
   },
   "outputs": [],
   "source": [
    "from architect_graph import Architect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJ1PyV08lBtE"
   },
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZnKAbg0lDud"
   },
   "outputs": [],
   "source": [
    "def train(x_train, y_train, x_valid, y_valid, logits, model, architect, optimizer):\n",
    "    \"\"\"Trains the network. Gradient step is performed here\n",
    "\n",
    "    Args:\n",
    "        train_queue (array): Train queue\n",
    "        valid_queue (array): Validation queue\n",
    "        model (Network): Network\n",
    "        architect (Architect): the architechture of network\n",
    "        criterion (fn): Loss function\n",
    "        optimizer (Optimiser): Adam / SGD\n",
    "        lr (float): Learning Rate\n",
    "\n",
    "    Returns:\n",
    "        (float, float): returns acc and miOu\n",
    "    \"\"\"\n",
    "\n",
    "    # architect step\n",
    "    architect_step = architect.step(input_train=x_train,\n",
    "                                    target_train=y_train,\n",
    "                                    input_valid=x_valid,\n",
    "                                    target_valid=y_valid,\n",
    "                                    unrolled=args.unrolled\n",
    "                                    )\n",
    "    w_var = model.get_thetas()\n",
    "\n",
    "    # calculating accuracy and iou\n",
    "    acc = utils.accuracy(logits, y_train)\n",
    "    iou = utils.iou(logits, y_train)\n",
    "\n",
    "    with tf.control_dependencies([architect_step]):\n",
    "      loss = model._loss(logits, y_train)\n",
    "      grads = tf.gradients(loss, w_var)\n",
    "      clipped_gradients, norm = tf.clip_by_global_norm(grads, args.grad_clip)\n",
    "      opt_op = optimizer.apply_gradients(zip(clipped_gradients, w_var))\n",
    "\n",
    "    return opt_op, loss, acc, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqCIe6kipVvk"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"arch_learning_rate\": 3e-1,\n",
    "    \"arch_weight_decay\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"grad_clip\": 5,\n",
    "    \"learning_rate_min\": 0.001,\n",
    "    \"learning_rate\": 0.025,\n",
    "    \"unrolled\": True,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 4,\n",
    "    \"save\": \"EXP\"\n",
    "}\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = Struct(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sy8PC0OllMG9"
   },
   "outputs": [],
   "source": [
    "np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 1)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 12)).astype(np.float32))\n",
    "np_ds_valid = (np.random.randint(0, 256, (20, 16, 16, 1)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 12)).astype(np.float32))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(4)\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices(np_ds_valid).batch(4)\n",
    "train_it = ds_train.make_one_shot_iterator()\n",
    "valid_it = ds_valid.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3CPLYkYlNty"
   },
   "outputs": [],
   "source": [
    "from model_search import Network\n",
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "model = Network(3, 3, criterion)\n",
    "optimizer = tf.train.MomentumOptimizer(args.learning_rate_min, args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqiLkcVjra3x"
   },
   "outputs": [],
   "source": [
    "architect = Architect(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gpUdoDXlRjl"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "x_train, y_train = sess.run(train_it.get_next())\n",
    "x_valid, y_valid = sess.run(valid_it.get_next())\n",
    "net_out = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ots7BAofOy5y"
   },
   "outputs": [],
   "source": [
    "train_op, acc_op, iou_op = train(x_train=x_train, \n",
    "                  y_train=y_train,\n",
    "                  x_valid=x_valid,\n",
    "                  y_valid=y_valid,\n",
    "                  logits=net_out,\n",
    "                  model=model,\n",
    "                  architect=architect,\n",
    "                  optimizer=optimizer\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sR4pzUX9lUrp"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    logits, _, acc, iou  = sess.run([net_out, train_op, acc_op, iou_op])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIYsbuKgC4Gi"
   },
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlyRQ9al643O"
   },
   "outputs": [],
   "source": [
    "def infer(x_valid, y_valid, logits, model, criterion):\n",
    "  loss_op = model._loss(logits, y_valid)\n",
    "  acc_op = utils.accuracy(logits, y_valid)\n",
    "  iou_op = utils.iou(logits, y_valid)\n",
    "  return loss_op, acc_op, iou_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rJSvp5FQrLg"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMryBc1UQr2u"
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "  np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "  np_ds_valid = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "  ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(args.batch_size)\n",
    "  ds_valid = tf.data.Dataset.from_tensor_slices(np_ds_valid).batch(args.batch_size)\n",
    "  train_it = ds_train.make_one_shot_iterator()\n",
    "  valid_it = ds_valid.make_one_shot_iterator()\n",
    "\n",
    "  num_iterations = np_ds_train[0][0] / args.batch_size\n",
    "\n",
    "  criterion = tf.losses.sigmoid_cross_entropy\n",
    "  model = Network(3, 3, criterion)\n",
    "  \n",
    "  # Optimizer\n",
    "  optimizer = tf.train.MomentumOptimizer(args.learning_rate_min, args.momentum)\n",
    "\n",
    "  architect = Architect(model, args)\n",
    "\n",
    "  sess = tf.Session()\n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  sess.run(init)\n",
    "\n",
    "  mious = []\n",
    "  for e in range(args.epochs):\n",
    "    print(\"Epoch {}\".format(e))\n",
    "\n",
    "    tq1 = tqdm(range(num_iterations))\n",
    "    genotype = model.genotype()\n",
    "\n",
    "    # Train Loop\n",
    "    train_miou = 0\n",
    "    train_unions, train_intersections = [], []\n",
    "    for i in tq1:\n",
    "      x_train, y_train = sess.run(train_it.get_next())\n",
    "      x_valid, y_valid = sess.run(valid_it.get_next())\n",
    "\n",
    "      train_logits = model(x_train)\n",
    "      train_op, train_loss_op, train_acc_op, train_iou_op = train(x_train=x_train, \n",
    "                  y_train=y_train,\n",
    "                  x_valid=x_valid,\n",
    "                  y_valid=y_valid,\n",
    "                  logits=train_logits,\n",
    "                  model=model,\n",
    "                  architect=architect,\n",
    "                  optimizer=optimizer\n",
    "                 )\n",
    "      \n",
    "      _train, train_loss, train_acc, train_iou = sess.run([train_op, train_loss_op, train_acc_op, train_iou_op])\n",
    "      if(i % args.report_freq == 0):\n",
    "        tq1.set_postfix({\n",
    "                \"Train Loss\": train_loss\n",
    "                \"Train Acc\": train_acc,\n",
    "                \"Train IoU\": train_iou[0]\n",
    "                })\n",
    "      train_unions.append(train_iou[1])\n",
    "      train_intersections.append(train_iou[2])\n",
    "    \n",
    "    # Calculation of train miou\n",
    "    train_unions = np.array(train_unions)\n",
    "    train_intersections = np.array(train_intersections)\n",
    "    train_non_zero_mask = train_unions != 0\n",
    "    train_miou = np.mean(train_intersections[train_non_zero_mask])/(np.mean(train_unions[train_non_zero_mask]) + 1e-6)\n",
    "    \n",
    "    # Log train miou\n",
    "    print(train_miou)\n",
    "\n",
    "    # Validation loop\n",
    "    valid_unions, valid_intersections = [], []\n",
    "    tq2 = tqdm(range(num_iterations))\n",
    "    for i in tq2:\n",
    "      valid_logits = model(x_valid)\n",
    "      valid_loss_op, valid_acc_op, valid_iou_op = infer(x_valid=x_valid, \n",
    "                                                   y_valid=y_valid,\n",
    "                                                   logits=valid_logits,\n",
    "                                                   model=model,\n",
    "                                                   criterion=criterion\n",
    "                                                   )\n",
    "      valid_loss, valid_acc, valid_iou = sess.run([valid_loss_op, valid_acc_op, valid_iou_op])\n",
    "\n",
    "      if(i % args.report_freq == 0):\n",
    "        tq2.set_postfix({\n",
    "                \"Valid Loss\": valid_loss,\n",
    "                \"Valid Acc\": valid_acc,\n",
    "                \"Valid IoU\": valid_iou[0]\n",
    "                })\n",
    "        valid_unions.append(valid_iou[1])\n",
    "        valid_intersections.append(valid_iou[2])\n",
    "    \n",
    "    # Calculation of train miou\n",
    "    valid_unions = np.array(valid_unions)\n",
    "    valid_intersections = np.array(valid_intersections)\n",
    "    valid_non_zero_mask = valid_unions != 0\n",
    "    valid_miou = np.mean(valid_intersections[valid_non_zero_mask])/(np.mean(valid_unions[valid_non_zero_mask]) + 1e-6)\n",
    "    \n",
    "    #Log Miou\n",
    "    print(valid_miou)\n",
    "\n",
    "    mious.append(valid_miou)\n",
    "  \n",
    "  np.save(os.path.join(args.save,\"mIoUs.npy\"), mIoUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-dDB4CtAam4Y"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdacmI61aj-d"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"arch_learning_rate\": 3e-1,\n",
    "    \"arch_weight_decay\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"grad_clip\": 5,\n",
    "    \"learning_rate_min\": 0.001,\n",
    "    \"learning_rate\": 0.025,\n",
    "    \"unrolled\": True,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 4,\n",
    "    \"save\": \"EXP\"\n",
    "}\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = Struct(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3bvzQeHoaaUv"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "\n",
    "    args.save = 'search-{}-{}'.format(args.save,\n",
    "                                      time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    utils.create_exp_dir(args.save, scripts_to_save=glob.glob('*.py'))\n",
    "\n",
    "    log_format = '%(asctime)s %(message)s'\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                        format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "    fh = logging.FileHandler(os.path.join(args.save, 'log.txt'))\n",
    "    fh.setFormatter(logging.Formatter(log_format))\n",
    "    logging.getLogger().addHandler(fh)\n",
    "\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_search",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
