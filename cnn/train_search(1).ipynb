{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLD9kfyhk_kX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLKwgbKYrJ9D"
   },
   "outputs": [],
   "source": [
    "from architect import Architect\n",
    "from model_search import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\"cifar\")\n",
    "    parser.add_argument('--data', type=str, default='./data',\n",
    "                        help='location of the data corpus')\n",
    "    parser.add_argument('--batch_size', type=int,\n",
    "                        default=1, help='batch size')\n",
    "    parser.add_argument('--learning_rate', type=float,\n",
    "                        default=0.025, help='init learning rate')\n",
    "    parser.add_argument('--learning_rate_min', type=float,\n",
    "                        default=0.001, help='min learning rate')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "    parser.add_argument('--weight_decay', type=float,\n",
    "                        default=3e-4, help='weight decay')\n",
    "    parser.add_argument('--report_freq', type=float,\n",
    "                        default=10, help='report frequency')\n",
    "    parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "    parser.add_argument('--epochs', type=int, default=50,\n",
    "                        help='num of training epochs')\n",
    "    parser.add_argument('--init_channels', type=int,\n",
    "                        default=3, help='num of init channels')\n",
    "    parser.add_argument('--layers', type=int, default=5,\n",
    "                        help='total number of layers')\n",
    "    parser.add_argument('--model_path', type=str,\n",
    "                        default='saved_models', help='path to save the model')\n",
    "    parser.add_argument('--cutout', action='store_true',\n",
    "                        default=False, help='use cutout')\n",
    "    parser.add_argument('--cutout_length', type=int,\n",
    "                        default=16, help='cutout length')\n",
    "    parser.add_argument('--drop_path_prob', type=float,\n",
    "                        default=0.3, help='drop path probability')\n",
    "    parser.add_argument('--save', type=str, default='EXP',\n",
    "                        help='experiment name')\n",
    "    parser.add_argument('--seed', type=int, default=2, help='random seed')\n",
    "    parser.add_argument('--grad_clip', type=float,\n",
    "                        default=5, help='gradient clipping')\n",
    "    parser.add_argument('--train_portion', type=float,\n",
    "                        default=1.0, help='portion of training data')\n",
    "    parser.add_argument('--unrolled', action='store_true',\n",
    "                        default=False, help='use one-step unrolled validation loss')\n",
    "    parser.add_argument('--arch_learning_rate', type=float,\n",
    "                        default=3e-4, help='learning rate for arch encoding')\n",
    "    parser.add_argument('--arch_weight_decay', type=float,\n",
    "                        default=1e-3, help='weight decay for arch encoding')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJ1PyV08lBtE"
   },
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZnKAbg0lDud"
   },
   "outputs": [],
   "source": [
    "def train(x_train, y_train, x_valid, y_valid, model, architect, optimizer):\n",
    "    \"\"\"Trains the network. Gradient step is performed here\n",
    "\n",
    "    Args:\n",
    "        train_queue (array): Train queue\n",
    "        valid_queue (array): Validation queue\n",
    "        model (Network): Network\n",
    "        architect (Architect): the architechture of network\n",
    "        criterion (fn): Loss function\n",
    "        optimizer (Optimiser): Adam / SGD\n",
    "        lr (float): Learning Rate\n",
    "\n",
    "    Returns:\n",
    "        (float, float): returns acc and miOu\n",
    "    \"\"\"\n",
    "\n",
    "    # architect step\n",
    "    architect_step = architect.step(input_train=x_train,\n",
    "                                    target_train=y_train,\n",
    "                                    input_valid=x_valid,\n",
    "                                    target_valid=y_valid,\n",
    "                                    unrolled=args.unrolled,\n",
    "                                    )\n",
    "    \n",
    "    with tf.control_dependencies([architect_step]):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_train)\n",
    "            w_var = model.get_thetas()\n",
    "            loss = model._criterion(logits, y_train)\n",
    "            grads = tape.gradient(loss, w_var)\n",
    "            clipped_gradients, norm = tf.clip_by_global_norm(grads, args.grad_clip)\n",
    "            opt_op = optimizer.apply_gradients(zip(clipped_gradients, w_var))\n",
    "\n",
    "    # calculating accuracy and iou\n",
    "    acc = utils.accuracy(logits, y_train)\n",
    "    iou = utils.iou(logits, y_train)\n",
    "\n",
    "    return loss, acc, iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YjEkiLOWnjm"
   },
   "source": [
    "## Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqCIe6kipVvk"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"arch_learning_rate\": 3e-1,\n",
    "    \"arch_weight_decay\": 1e-3,\n",
    "    \"momentum\": 0.9,\n",
    "    \"grad_clip\": 5,\n",
    "    \"learning_rate_min\": 0.001,\n",
    "    \"learning_rate\": 0.025,\n",
    "    \"unrolled\": True,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 4,\n",
    "    \"save\": \"EXP\"\n",
    "}\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = Struct(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sy8PC0OllMG9"
   },
   "outputs": [],
   "source": [
    "np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "np_ds_valid = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(4)\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices(np_ds_valid).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3CPLYkYlNty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From operations.py:290: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:7: The name tf.layers.MaxPooling2D is deprecated. Please use tf.compat.v1.layers.MaxPooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:6: The name tf.layers.AveragePooling2D is deprecated. Please use tf.compat.v1.layers.AveragePooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From model_search.py:97: The name tf.layers.Conv2DTranspose is deprecated. Please use tf.compat.v1.layers.Conv2DTranspose instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "model = Network(3, 3, criterion)\n",
    "optimizer = tf.train.MomentumOptimizer(args.learning_rate_min, args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqiLkcVjra3x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From architect.py:39: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "architect = Architect(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gpUdoDXlRjl"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIYsbuKgC4Gi"
   },
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlyRQ9al643O"
   },
   "outputs": [],
   "source": [
    "def infer(x_valid, y_valid, logits, model, criterion):\n",
    "    loss_op = model._loss(logits, y_valid)\n",
    "    acc_op = utils.accuracy(logits, y_valid)\n",
    "    iou_op = utils.iou(logits, y_valid)\n",
    "    return loss_op, acc_op, iou_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rJSvp5FQrLg"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "\n",
    "    image_dataset = tf.data.TFRecordDataset('../../datasets/infer/infer-00000-00007.tfrecords')\n",
    "    W, H = 16, 16\n",
    "    \n",
    "    # Create a dictionary describing the features.  \n",
    "    image_feature_description = {\n",
    "        'name': tf.FixedLenFeature([], tf.string),  \n",
    "        'label_encoded': tf.FixedLenFeature([], tf.string),\n",
    "        'encoded': tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    def _parse_image_function(example_proto):\n",
    "        # Parse the input tf.Example proto using the dictionary above.\n",
    "        feature= tf.parse_single_example(example_proto, image_feature_description)\n",
    "        image= feature['encoded']\n",
    "        label = feature['label_encoded']\n",
    "        name = feature['name']\n",
    "\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        label = tf.image.decode_png(label, channels=3)\n",
    "\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = tf.image.resize(image, (W, H))\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        label = tf.image.resize(label, (W, H))\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    dataset = image_dataset.map(_parse_image_function)\n",
    "    dataset = dataset.batch(8)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMryBc1UQr2u"
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "#     np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "    np_ds_valid = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "#     ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(args.batch_size)\n",
    "#     ds_valid = tf.data.Dataset.from_tensor_slices(np_ds_valid).batch(args.batch_size)\n",
    "    ds_train = input_fn()\n",
    "    ds_valid = input_fn()\n",
    "    num_iterations = int(np_ds_train[0].shape[0] / args.batch_size)\n",
    "\n",
    "    criterion = tf.losses.sigmoid_cross_entropy\n",
    "    model = Network(3, 3, criterion)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.MomentumOptimizer(args.learning_rate_min, args.momentum)\n",
    "\n",
    "    architect = Architect(model, args)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    _logits = model(tf.convert_to_tensor(np_ds_train[0][:4]))\n",
    "    mious = [0]\n",
    "    for e in range(args.epochs):\n",
    "        tf.logging.info('Epoch {}'.format(e))\n",
    "\n",
    "        train_it = ds_train.make_one_shot_iterator()\n",
    "        valid_it = ds_valid.make_one_shot_iterator()\n",
    "\n",
    "        tq1 = tqdm(range(num_iterations))\n",
    "        genotype = model.genotype()\n",
    "        print('Genotype: {}'.format(genotype))\n",
    "\n",
    "        # Train Loop\n",
    "        train_miou = 0\n",
    "        train_unions, train_intersections = [], []    \n",
    "\n",
    "        for i in tq1:\n",
    "            x_train, y_train = train_it.get_next()\n",
    "            y_train = y_train[:,:,:,0]\n",
    "            print(y_train.shape)\n",
    "            y_train = tf.reshape(y_train, (8, 16, 16, 1))\n",
    "            x_valid, y_valid = valid_it.get_next()\n",
    "            y_valid = y_valid[:,:,:,0]\n",
    "            y_valid = tf.reshape(y_valid, (8, 16, 16, 1))\n",
    "            train_loss, train_acc, train_iou = train(x_train=x_train,\n",
    "                                                     y_train=y_train,\n",
    "                                                     x_valid=x_valid,\n",
    "                                                     y_valid=y_valid,\n",
    "                                                     model=model,\n",
    "                                                     architect=architect,\n",
    "                                                     optimizer=optimizer\n",
    "                                                     )\n",
    "            if(i % args.report_freq == 0):\n",
    "                tq1.set_postfix({\n",
    "                        \"Train Loss\": train_loss.numpy(),\n",
    "                        \"Train Acc\": train_acc.numpy(),\n",
    "                        \"Train IoU\": train_iou[0].numpy()\n",
    "                        })\n",
    "            train_intersections.append(train_iou[1].numpy())\n",
    "            train_unions.append(train_iou[2].numpy())\n",
    "    \n",
    "        # Calculation of train miou\n",
    "        train_unions = np.array(train_unions)\n",
    "        train_intersections = np.array(train_intersections)\n",
    "        train_non_zero_mask = train_unions != 0\n",
    "        train_miou = np.mean(train_intersections[train_non_zero_mask])/(np.mean(train_unions[train_non_zero_mask]) + 1e-6)\n",
    "\n",
    "        # Log train miou\n",
    "        logging.info('Train mIoU: {}'.format(train_miou))\n",
    "\n",
    "        # Validation loop\n",
    "        valid_unions, valid_intersections = [], []\n",
    "        tq2 = tqdm(range(num_iterations))\n",
    "        for i in tq2:\n",
    "            valid_logits = model(x_valid)\n",
    "            valid_loss, valid_acc, valid_iou = infer(x_valid=x_valid, \n",
    "                                                       y_valid=y_valid,\n",
    "                                                       logits=valid_logits,\n",
    "                                                       model=model,\n",
    "                                                       criterion=criterion\n",
    "                                                       )\n",
    "\n",
    "            if(i % args.report_freq == 0):\n",
    "                tq2.set_postfix({\n",
    "                                \"Valid Loss\": valid_loss.numpy(),\n",
    "                                \"Valid Acc\": valid_acc.numpy(),\n",
    "                                \"Valid IoU\": valid_iou[0].numpy()\n",
    "                                })\n",
    "            valid_intersections.append(valid_iou[1])  \n",
    "            valid_unions.append(valid_iou[2])\n",
    "\n",
    "        # Calculation of train miou\n",
    "        valid_unions = np.array(valid_unions)\n",
    "        valid_intersections = np.array(valid_intersections)\n",
    "        valid_non_zero_mask = valid_unions != 0\n",
    "        valid_miou = np.mean(valid_intersections[valid_non_zero_mask])/(np.mean(valid_unions[valid_non_zero_mask]) + 1e-6)\n",
    "\n",
    "        #Log Miou\n",
    "        logging.info('Validation mIoU: {}'.format(valid_miou))\n",
    "\n",
    "        # save the final genotype\n",
    "        if(max(mious) < valid_iou):\n",
    "            logging.info(\"Writing the computed genotype tp ./cnn/final_models/final_genotype.py\")\n",
    "            utils.write_genotype(genotype)\n",
    "\n",
    "        mious.append(valid_miou)\n",
    "  \n",
    "    np.save(os.path.join(args.save, \"mIoUs.npy\"), mious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-dDB4CtAam4Y"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdacmI61aj-d"
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    args = {\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 3e-4,\n",
    "        \"arch_learning_rate\": 3e-1,\n",
    "        \"arch_weight_decay\": 1e-3,\n",
    "        \"momentum\": 0.9,\n",
    "        \"grad_clip\": 5,\n",
    "        \"learning_rate_min\": 0.001,\n",
    "        \"learning_rate\": 0.025,\n",
    "        \"unrolled\": True,\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 4,\n",
    "        \"save\": \"EXP\",\n",
    "        \"report_freq\": 1\n",
    "    }\n",
    "\n",
    "    class Struct:\n",
    "        def __init__(self, **entries):\n",
    "            self.__dict__.update(entries)\n",
    "\n",
    "    return Struct(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3bvzQeHoaaUv",
    "outputId": "1a6babba-847a-4903-e7ea-a26548122380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : search-EXP-20191109-193342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotype: Genotype(normal=[('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('sep_conv_3x3', 0), ('dil_conv_5x5', 3), ('sep_conv_5x5', 3), ('dil_conv_3x3', 2)], normal_concat=[2, 3, 4, 5], reduce=[('sep_conv_5x5', 1), ('avg_pool_3x3', 0), ('dil_conv_5x5', 1), ('max_pool_3x3', 0), ('sep_conv_3x3', 0), ('sep_conv_3x3', 1), ('sep_conv_5x5', 4), ('max_pool_3x3', 1)], reduce_concat=[2, 3, 4, 5])\n",
      "(8, 16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:26<?, ?it/s, Train Acc=0.00146, Train Loss=3.25, Train IoU=0.00147]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:26<01:44, 26.01s/it, Train Acc=0.00146, Train Loss=3.25, Train IoU=0.00147]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:51<01:44, 26.01s/it, Train Acc=0.169, Train Loss=2.32, Train IoU=0.173]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:51<01:17, 25.88s/it, Train Acc=0.169, Train Loss=2.32, Train IoU=0.173]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [01:16<01:17, 25.88s/it, Train Acc=0.706, Train Loss=-.202, Train IoU=0.708]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [01:16<00:51, 25.62s/it, Train Acc=0.706, Train Loss=-.202, Train IoU=0.708]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [01:42<00:51, 25.62s/it, Train Acc=0.76, Train Loss=-3.26, Train IoU=0.767] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [01:42<00:25, 25.73s/it, Train Acc=0.76, Train Loss=-3.26, Train IoU=0.767]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [02:10<00:25, 25.73s/it, Train Acc=0.819, Train Loss=-8.91, Train IoU=0.821]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [02:10<00:00, 26.05s/it, Train Acc=0.819, Train Loss=-8.91, Train IoU=0.821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/09 07:36:00 PM Train mIoU: 0.495078739914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:01<?, ?it/s, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:01<00:06,  1.74s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:03<00:06,  1.74s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:03<00:05,  1.74s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:05<00:05,  1.74s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:05<00:03,  1.74s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:06<00:03,  1.74s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:06<00:01,  1.73s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:08<00:01,  1.73s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.73s/it, Valid Acc=0.833, Valid Loss=-13.3, Valid IoU=0.833]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/09 07:36:09 PM Validation mIoU: 0.832926233106\n",
      "11/09 07:36:09 PM Writing the computed genotype tp ./cnn/final_models/final_genotype.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    search_dirs = glob.glob('./search-*')\n",
    "    [shutil.rmtree(search_dir) for search_dir in search_dirs]\n",
    "    \n",
    "    args = parse_args()\n",
    "    args.save = 'search-{}-{}'.format(args.save,\n",
    "                                      time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    utils.create_exp_dir(args.save, scripts_to_save=glob.glob('*.py'))\n",
    "    \n",
    "    # logging\n",
    "    log_format = '%(asctime)s %(message)s'\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                        format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "    fh = logging.FileHandler(os.path.join(args.save, 'log.txt'))\n",
    "    fh.setFormatter(logging.Formatter(log_format))\n",
    "    logging.getLogger().addHandler(fh)\n",
    "    \n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-14-b9a45e8fff50>:2: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "ds = input_fn()\n",
    "it = ds.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(it.get_next()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1540007, shape=(16, 16, 1), dtype=float32, numpy=\n",
       "array([[[0.43516126],\n",
       "        [0.5292279 ],\n",
       "        [0.3452683 ],\n",
       "        [0.48732194],\n",
       "        [0.31998283],\n",
       "        [0.47137895],\n",
       "        [0.30243063],\n",
       "        [0.456796  ],\n",
       "        [0.30057225],\n",
       "        [0.4411892 ],\n",
       "        [0.3137334 ],\n",
       "        [0.45296952],\n",
       "        [0.32190293],\n",
       "        [0.4592965 ],\n",
       "        [0.3664359 ],\n",
       "        [0.5236181 ]],\n",
       "\n",
       "       [[0.43221235],\n",
       "        [0.4170961 ],\n",
       "        [0.37205014],\n",
       "        [0.37814733],\n",
       "        [0.35838842],\n",
       "        [0.3655147 ],\n",
       "        [0.35138226],\n",
       "        [0.36091548],\n",
       "        [0.34425634],\n",
       "        [0.3547306 ],\n",
       "        [0.3535769 ],\n",
       "        [0.35948607],\n",
       "        [0.34859842],\n",
       "        [0.3001175 ],\n",
       "        [0.34961835],\n",
       "        [0.45303375]],\n",
       "\n",
       "       [[0.3317604 ],\n",
       "        [0.5274001 ],\n",
       "        [0.28365847],\n",
       "        [0.47794035],\n",
       "        [0.24589646],\n",
       "        [0.46459946],\n",
       "        [0.22095093],\n",
       "        [0.44219023],\n",
       "        [0.2179637 ],\n",
       "        [0.42034268],\n",
       "        [0.22366273],\n",
       "        [0.43047404],\n",
       "        [0.18191943],\n",
       "        [0.31018054],\n",
       "        [0.2463068 ],\n",
       "        [0.50225896]],\n",
       "\n",
       "       [[0.40499574],\n",
       "        [0.3936342 ],\n",
       "        [0.33375493],\n",
       "        [0.36810437],\n",
       "        [0.36122122],\n",
       "        [0.38866037],\n",
       "        [0.35046297],\n",
       "        [0.36796796],\n",
       "        [0.33302364],\n",
       "        [0.35059744],\n",
       "        [0.34722793],\n",
       "        [0.37563816],\n",
       "        [0.32368892],\n",
       "        [0.287565  ],\n",
       "        [0.3210319 ],\n",
       "        [0.4482013 ]],\n",
       "\n",
       "       [[0.33931535],\n",
       "        [0.5486398 ],\n",
       "        [0.301475  ],\n",
       "        [0.497561  ],\n",
       "        [0.2664624 ],\n",
       "        [0.47280484],\n",
       "        [0.23491791],\n",
       "        [0.4782939 ],\n",
       "        [0.23846024],\n",
       "        [0.4444751 ],\n",
       "        [0.23187226],\n",
       "        [0.46653306],\n",
       "        [0.23760447],\n",
       "        [0.42841765],\n",
       "        [0.29150516],\n",
       "        [0.519268  ]],\n",
       "\n",
       "       [[0.40502486],\n",
       "        [0.41938487],\n",
       "        [0.33924723],\n",
       "        [0.37470445],\n",
       "        [0.3531124 ],\n",
       "        [0.38531074],\n",
       "        [0.35186356],\n",
       "        [0.39883664],\n",
       "        [0.3542598 ],\n",
       "        [0.35961422],\n",
       "        [0.34309092],\n",
       "        [0.39068833],\n",
       "        [0.38329768],\n",
       "        [0.4005309 ],\n",
       "        [0.4151158 ],\n",
       "        [0.48467186]],\n",
       "\n",
       "       [[0.3661557 ],\n",
       "        [0.5666386 ],\n",
       "        [0.3153247 ],\n",
       "        [0.48750785],\n",
       "        [0.27452624],\n",
       "        [0.5049241 ],\n",
       "        [0.2727484 ],\n",
       "        [0.5099219 ],\n",
       "        [0.25386068],\n",
       "        [0.45967913],\n",
       "        [0.24081019],\n",
       "        [0.49574238],\n",
       "        [0.25986773],\n",
       "        [0.4914773 ],\n",
       "        [0.35067326],\n",
       "        [0.55433524]],\n",
       "\n",
       "       [[0.41558823],\n",
       "        [0.43292713],\n",
       "        [0.35069978],\n",
       "        [0.40202016],\n",
       "        [0.3745312 ],\n",
       "        [0.40995634],\n",
       "        [0.3680163 ],\n",
       "        [0.40345156],\n",
       "        [0.35598838],\n",
       "        [0.38466293],\n",
       "        [0.34992677],\n",
       "        [0.3911909 ],\n",
       "        [0.3851674 ],\n",
       "        [0.41497675],\n",
       "        [0.45728335],\n",
       "        [0.4936696 ]],\n",
       "\n",
       "       [[0.36816794],\n",
       "        [0.5739582 ],\n",
       "        [0.33480242],\n",
       "        [0.5140877 ],\n",
       "        [0.2910617 ],\n",
       "        [0.50794655],\n",
       "        [0.27052444],\n",
       "        [0.5156207 ],\n",
       "        [0.26103917],\n",
       "        [0.47360012],\n",
       "        [0.23108682],\n",
       "        [0.49253532],\n",
       "        [0.24454203],\n",
       "        [0.48528263],\n",
       "        [0.3304305 ],\n",
       "        [0.5605827 ]],\n",
       "\n",
       "       [[0.43217662],\n",
       "        [0.44126156],\n",
       "        [0.3541629 ],\n",
       "        [0.41047424],\n",
       "        [0.38436568],\n",
       "        [0.408278  ],\n",
       "        [0.3531387 ],\n",
       "        [0.39157543],\n",
       "        [0.3474871 ],\n",
       "        [0.3700085 ],\n",
       "        [0.34464633],\n",
       "        [0.39821795],\n",
       "        [0.35470533],\n",
       "        [0.38171226],\n",
       "        [0.4052049 ],\n",
       "        [0.45925546]],\n",
       "\n",
       "       [[0.38586596],\n",
       "        [0.56915456],\n",
       "        [0.33953965],\n",
       "        [0.528453  ],\n",
       "        [0.30876148],\n",
       "        [0.48907137],\n",
       "        [0.26946923],\n",
       "        [0.4987017 ],\n",
       "        [0.2636063 ],\n",
       "        [0.47615573],\n",
       "        [0.25107384],\n",
       "        [0.51022935],\n",
       "        [0.245419  ],\n",
       "        [0.47212026],\n",
       "        [0.30033797],\n",
       "        [0.52597046]],\n",
       "\n",
       "       [[0.44320747],\n",
       "        [0.45769432],\n",
       "        [0.36749926],\n",
       "        [0.43623853],\n",
       "        [0.38774955],\n",
       "        [0.44365075],\n",
       "        [0.3826013 ],\n",
       "        [0.42190972],\n",
       "        [0.35627416],\n",
       "        [0.4023368 ],\n",
       "        [0.37743092],\n",
       "        [0.42119673],\n",
       "        [0.35748893],\n",
       "        [0.39551693],\n",
       "        [0.3747696 ],\n",
       "        [0.49443525]],\n",
       "\n",
       "       [[0.4180022 ],\n",
       "        [0.5771811 ],\n",
       "        [0.35577595],\n",
       "        [0.51177347],\n",
       "        [0.33480603],\n",
       "        [0.5122553 ],\n",
       "        [0.30335522],\n",
       "        [0.5172057 ],\n",
       "        [0.30217397],\n",
       "        [0.48803827],\n",
       "        [0.29819265],\n",
       "        [0.51654655],\n",
       "        [0.27986148],\n",
       "        [0.48712546],\n",
       "        [0.32635045],\n",
       "        [0.5414178 ]],\n",
       "\n",
       "       [[0.4461298 ],\n",
       "        [0.4479224 ],\n",
       "        [0.377418  ],\n",
       "        [0.43512225],\n",
       "        [0.35735792],\n",
       "        [0.41841012],\n",
       "        [0.34896302],\n",
       "        [0.43606582],\n",
       "        [0.35393247],\n",
       "        [0.40494862],\n",
       "        [0.34045145],\n",
       "        [0.42780402],\n",
       "        [0.37654275],\n",
       "        [0.43399772],\n",
       "        [0.37755322],\n",
       "        [0.49900487]],\n",
       "\n",
       "       [[0.40157327],\n",
       "        [0.59429646],\n",
       "        [0.3482723 ],\n",
       "        [0.5620242 ],\n",
       "        [0.3527301 ],\n",
       "        [0.57079774],\n",
       "        [0.3770498 ],\n",
       "        [0.6014729 ],\n",
       "        [0.3907153 ],\n",
       "        [0.5853749 ],\n",
       "        [0.32954165],\n",
       "        [0.56646484],\n",
       "        [0.3913498 ],\n",
       "        [0.6097195 ],\n",
       "        [0.45067868],\n",
       "        [0.60658646]],\n",
       "\n",
       "       [[0.35856295],\n",
       "        [0.43681455],\n",
       "        [0.3619494 ],\n",
       "        [0.45521948],\n",
       "        [0.37888014],\n",
       "        [0.4732497 ],\n",
       "        [0.39761725],\n",
       "        [0.49812955],\n",
       "        [0.39920524],\n",
       "        [0.47196814],\n",
       "        [0.3517376 ],\n",
       "        [0.45553073],\n",
       "        [0.36015105],\n",
       "        [0.5059144 ],\n",
       "        [0.5106487 ],\n",
       "        [0.53962713]]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.sigmoid(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.numpy().sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the softmax working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1540024, shape=(16, 16, 1), dtype=float32, numpy=\n",
       "array([[[3.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[3.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [1.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[3.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[3.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[3.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[3.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[2.],\n",
       "        [4.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [4.],\n",
       "        [2.],\n",
       "        [4.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [4.],\n",
       "        [3.],\n",
       "        [4.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [3.]]], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.round(tf.sigmoid(res)[0].numpy()*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=48603, shape=(16, 16, 1), dtype=float32, numpy=\n",
       "array([[[-0.2608236 ],\n",
       "        [ 0.11704504],\n",
       "        [-0.6399038 ],\n",
       "        [-0.05072308],\n",
       "        [-0.7538507 ],\n",
       "        [-0.11460948],\n",
       "        [-0.8357501 ],\n",
       "        [-0.17324805],\n",
       "        [-0.84457445],\n",
       "        [-0.23633718],\n",
       "        [-0.7827227 ],\n",
       "        [-0.1886797 ],\n",
       "        [-0.7450404 ],\n",
       "        [-0.1631751 ],\n",
       "        [-0.5475378 ],\n",
       "        [ 0.09454274]],\n",
       "\n",
       "       [[-0.2728305 ],\n",
       "        [-0.3347057 ],\n",
       "        [-0.5234318 ],\n",
       "        [-0.49741936],\n",
       "        [-0.58236575],\n",
       "        [-0.5515077 ],\n",
       "        [-0.6129689 ],\n",
       "        [-0.571393  ],\n",
       "        [-0.64438343],\n",
       "        [-0.5983093 ],\n",
       "        [-0.60335326],\n",
       "        [-0.5775955 ],\n",
       "        [-0.62520576],\n",
       "        [-0.8467386 ],\n",
       "        [-0.6207173 ],\n",
       "        [-0.18842053]],\n",
       "\n",
       "       [[-0.7002338 ],\n",
       "        [ 0.10971034],\n",
       "        [-0.9263861 ],\n",
       "        [-0.08829594],\n",
       "        [-1.120619  ],\n",
       "        [-0.1418395 ],\n",
       "        [-1.2601333 ],\n",
       "        [-0.23227787],\n",
       "        [-1.2775726 ],\n",
       "        [-0.3213668 ],\n",
       "        [-1.244448  ],\n",
       "        [-0.27991748],\n",
       "        [-1.5033971 ],\n",
       "        [-0.7992754 ],\n",
       "        [-1.1184075 ],\n",
       "        [ 0.00903583]],\n",
       "\n",
       "       [[-0.38469207],\n",
       "        [-0.43206143],\n",
       "        [-0.69125056],\n",
       "        [-0.5403578 ],\n",
       "        [-0.57006764],\n",
       "        [-0.4529469 ],\n",
       "        [-0.6170049 ],\n",
       "        [-0.54094434],\n",
       "        [-0.6945412 ],\n",
       "        [-0.61641407],\n",
       "        [-0.63124657],\n",
       "        [-0.50810385],\n",
       "        [-0.73687017],\n",
       "        [-0.9072398 ],\n",
       "        [-0.7490337 ],\n",
       "        [-0.20794082]],\n",
       "\n",
       "       [[-0.66634667],\n",
       "        [ 0.19517648],\n",
       "        [-0.8402839 ],\n",
       "        [-0.00975609],\n",
       "        [-1.0126457 ],\n",
       "        [-0.10888815],\n",
       "        [-1.180747  ],\n",
       "        [-0.08687901],\n",
       "        [-1.16114   ],\n",
       "        [-0.22301936],\n",
       "        [-1.1977693 ],\n",
       "        [-0.13406825],\n",
       "        [-1.165858  ],\n",
       "        [-0.28831005],\n",
       "        [-0.8880851 ],\n",
       "        [ 0.07711005]],\n",
       "\n",
       "       [[-0.3845712 ],\n",
       "        [-0.32529914],\n",
       "        [-0.6666508 ],\n",
       "        [-0.51208687],\n",
       "        [-0.60538626],\n",
       "        [-0.46706676],\n",
       "        [-0.6108577 ],\n",
       "        [-0.4103148 ],\n",
       "        [-0.60036683],\n",
       "        [-0.577039  ],\n",
       "        [-0.6495502 ],\n",
       "        [-0.44441986],\n",
       "        [-0.4755745 ],\n",
       "        [-0.40325356],\n",
       "        [-0.3428564 ],\n",
       "        [-0.06133175]],\n",
       "\n",
       "       [[-0.5487447 ],\n",
       "        [ 0.2681498 ],\n",
       "        [-0.77534187],\n",
       "        [-0.04997897],\n",
       "        [-0.97177815],\n",
       "        [ 0.01969719],\n",
       "        [-0.98072267],\n",
       "        [ 0.03969288],\n",
       "        [-1.0781269 ],\n",
       "        [-0.16163445],\n",
       "        [-1.148243  ],\n",
       "        [-0.01703084],\n",
       "        [-1.0466563 ],\n",
       "        [-0.0340941 ],\n",
       "        [-0.61608124],\n",
       "        [ 0.21820259]],\n",
       "\n",
       "       [[-0.3409109 ],\n",
       "        [-0.26991844],\n",
       "        [-0.6159648 ],\n",
       "        [-0.3970549 ],\n",
       "        [-0.51282644],\n",
       "        [-0.364146  ],\n",
       "        [-0.54073644],\n",
       "        [-0.39110398],\n",
       "        [-0.59281874],\n",
       "        [-0.46980286],\n",
       "        [-0.61936116],\n",
       "        [-0.44230914],\n",
       "        [-0.4676721 ],\n",
       "        [-0.3434291 ],\n",
       "        [-0.1712842 ],\n",
       "        [-0.02532291]],\n",
       "\n",
       "       [[-0.5400845 ],\n",
       "        [ 0.2980191 ],\n",
       "        [-0.6865436 ],\n",
       "        [ 0.05636573],\n",
       "        [-0.8902333 ],\n",
       "        [ 0.03178883],\n",
       "        [-0.9919634 ],\n",
       "        [ 0.0625031 ],\n",
       "        [-1.0405746 ],\n",
       "        [-0.10569787],\n",
       "        [-1.2021847 ],\n",
       "        [-0.02986097],\n",
       "        [-1.1279368 ],\n",
       "        [-0.05888653],\n",
       "        [-0.70623875],\n",
       "        [ 0.24352717]],\n",
       "\n",
       "       [[-0.2729761 ],\n",
       "        [-0.23604369],\n",
       "        [-0.6007904 ],\n",
       "        [-0.36200523],\n",
       "        [-0.47105885],\n",
       "        [-0.37108874],\n",
       "        [-0.6052711 ],\n",
       "        [-0.4406948 ],\n",
       "        [-0.63010335],\n",
       "        [-0.5321803 ],\n",
       "        [-0.6426563 ],\n",
       "        [-0.41289592],\n",
       "        [-0.59841967],\n",
       "        [-0.48228693],\n",
       "        [-0.3838241 ],\n",
       "        [-0.16334033]],\n",
       "\n",
       "       [[-0.46472323],\n",
       "        [ 0.27840257],\n",
       "        [-0.6653465 ],\n",
       "        [ 0.11393499],\n",
       "        [-0.8059161 ],\n",
       "        [-0.04372144],\n",
       "        [-0.9973173 ],\n",
       "        [-0.00519323],\n",
       "        [-1.0273082 ],\n",
       "        [-0.09544945],\n",
       "        [-1.0928936 ],\n",
       "        [ 0.04092312],\n",
       "        [-1.1231958 ],\n",
       "        [-0.11163473],\n",
       "        [-0.84568906],\n",
       "        [ 0.1039753 ]],\n",
       "\n",
       "       [[-0.22815472],\n",
       "        [-0.16962826],\n",
       "        [-0.54296017],\n",
       "        [-0.25644207],\n",
       "        [-0.45678186],\n",
       "        [-0.22635865],\n",
       "        [-0.4785216 ],\n",
       "        [-0.31493878],\n",
       "        [-0.5915725 ],\n",
       "        [-0.3957379 ],\n",
       "        [-0.5004672 ],\n",
       "        [-0.31786263],\n",
       "        [-0.58627975],\n",
       "        [-0.42418015],\n",
       "        [-0.5118089 ],\n",
       "        [-0.02225995]],\n",
       "\n",
       "       [[-0.33098006],\n",
       "        [ 0.31121224],\n",
       "        [-0.59374547],\n",
       "        [ 0.04710269],\n",
       "        [-0.6865274 ],\n",
       "        [ 0.04903114],\n",
       "        [-0.8313713 ],\n",
       "        [ 0.06885016],\n",
       "        [-0.836967  ],\n",
       "        [-0.04785609],\n",
       "        [-0.85591924],\n",
       "        [ 0.06621039],\n",
       "        [-0.9451488 ],\n",
       "        [-0.05150962],\n",
       "        [-0.72473836],\n",
       "        [ 0.16605163]],\n",
       "\n",
       "       [[-0.21632051],\n",
       "        [-0.20906866],\n",
       "        [-0.500522  ],\n",
       "        [-0.26098228],\n",
       "        [-0.58685017],\n",
       "        [-0.3293035 ],\n",
       "        [-0.6236005 ],\n",
       "        [-0.25714433],\n",
       "        [-0.60179794],\n",
       "        [-0.38488758],\n",
       "        [-0.66128314],\n",
       "        [-0.29081637],\n",
       "        [-0.5042487 ],\n",
       "        [-0.26555884],\n",
       "        [-0.4999467 ],\n",
       "        [-0.00398052]],\n",
       "\n",
       "       [[-0.3989141 ],\n",
       "        [ 0.3817557 ],\n",
       "        [-0.6266422 ],\n",
       "        [ 0.24938118],\n",
       "        [-0.6070602 ],\n",
       "        [ 0.2851066 ],\n",
       "        [-0.5020893 ],\n",
       "        [ 0.41160613],\n",
       "        [-0.4443066 ],\n",
       "        [ 0.34487775],\n",
       "        [-0.71025884],\n",
       "        [ 0.26744223],\n",
       "        [-0.44164205],\n",
       "        [ 0.4461335 ],\n",
       "        [-0.19792902],\n",
       "        [ 0.43298602]],\n",
       "\n",
       "       [[-0.5816069 ],\n",
       "        [-0.25410026],\n",
       "        [-0.5669132 ],\n",
       "        [-0.17960334],\n",
       "        [-0.49430418],\n",
       "        [-0.10710347],\n",
       "        [-0.41540316],\n",
       "        [-0.00748184],\n",
       "        [-0.40877777],\n",
       "        [-0.11224513],\n",
       "        [-0.61141026],\n",
       "        [-0.17834835],\n",
       "        [-0.5747087 ],\n",
       "        [ 0.02365876],\n",
       "        [ 0.04260144],\n",
       "        [ 0.15884176]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6YjEkiLOWnjm"
   ],
   "name": "train_search",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
