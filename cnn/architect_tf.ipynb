{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _concat(xs):\n",
    "    \"\"\"nd tensor to 1d tensor\n",
    "\n",
    "    Args:\n",
    "        xs (array): the array of nd tensor\n",
    "\n",
    "    Returns:\n",
    "        array: concated array\n",
    "    \"\"\"\n",
    "    return tf.concat([tf.reshape(x, [tf.size(x)]) for x in xs], axis=0, name=\"_concat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[[[1],[2],[3]], [[4], [5], [6]]], [[[2],[4],[6]], [[8], [10], [12]]]])\n",
    "b = tf.constant([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  2,  4,  6,  8, 10, 12], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(tf.reshape(a, [tf.size(a)]), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Architect(object):\n",
    "    \"\"\"Constructs the model\n",
    "\n",
    "    Parameters:\n",
    "      network_momentum(float):  network momentum\n",
    "      network_weight_decay(float): network weight decay\n",
    "      model(Network): Network archtecture with cells\n",
    "      optimise(optimiser): Adam / SGD\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, args):\n",
    "        \"\"\"Initialises the architecture\n",
    "\n",
    "        Args:\n",
    "            model (Network): Network archtecture with cells\n",
    "            args (dict): cli args\n",
    "        \"\"\"\n",
    "        self.network_momentum = args.momentum\n",
    "        self.network_weight_decay = args.weight_decay\n",
    "        self.model = model\n",
    "        self.arch_learning_rate = args.arch_learning_rate\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.arch_learning_rate,\n",
    "                                                       beta1=0.5,\n",
    "                                                       beta2=0.999)    \n",
    "    def get_model_theta(self, model):\n",
    "        specific_tensor = []\n",
    "        specific_tensor_name = []\n",
    "        for var in model.trainable_weights:\n",
    "            if not 'alphas' in var.name:\n",
    "                specific_tensor.append(var)\n",
    "                specific_tensor_name.append(var.name)\n",
    "        return specific_tensor_name, specific_tensor\n",
    "    \n",
    "    def step(self, input_train, target_train, input_valid, target_valid, lr, unrolled):\n",
    "        \"\"\"Computer a step for gradient descend\n",
    "\n",
    "        Args:\n",
    "            input_train (tensor): a train of input\n",
    "            target_train (tensor): a train of targets\n",
    "            input_valid (tensor): a train of validation\n",
    "            target_valid (tensor): a train of validation targets\n",
    "            eta (tensor): eta\n",
    "            network_optimizer (optimiser): network optimiser for network\n",
    "            unrolled (bool): True if training we need unrolled\n",
    "        \"\"\"\n",
    "        if unrolled:\n",
    "            return self._compute_unrolled_step(\n",
    "                input_train, target_train, input_valid, target_valid, self.get_model_theta(self.model)[1], lr)\n",
    "#         else:\n",
    "#             self._backward_step(input_valid, target_valid)\n",
    "        \n",
    "    def _compute_unrolled_step(self, x_train, y_train, x_valid, y_valid, w_var, lr):\n",
    "        arch_var = self.model.arch_parameters()\n",
    "        unrolled_model = self.model.new()\n",
    "        unrolled_optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = unrolled_model(x_train)\n",
    "            unrolled_w_var = self.get_model_theta(unrolled_model)[1]\n",
    "            # copy weights\n",
    "            for v,w in zip(unrolled_w_var, w_var):\n",
    "                v.assign(w)\n",
    "            unrolled_train_loss = unrolled_model._criterion(logits, y_train)\n",
    "            grads = tape.gradient(unrolled_train_loss, unrolled_w_var)\n",
    "            unrolled_optimizer.apply_gradients(zip(grads, unrolled_w_var))\n",
    "\n",
    "        with tf.GradientTape() as tape1:\n",
    "            valid_loss = unrolled_model._criterion(unrolled_model(x_valid), y_valid)\n",
    "            valid_grads = tape1.gradient(valid_loss, unrolled_w_var)\n",
    "            \n",
    "        r=1e-2\n",
    "        R = r / (tf.global_norm(valid_grads)+1e-6)\n",
    "\n",
    "        optimizer_pos=tf.train.GradientDescentOptimizer(R)\n",
    "        optimizer_pos=optimizer_pos.apply_gradients(zip(valid_grads, w_var))\n",
    "        \n",
    "        optimizer_neg=tf.train.GradientDescentOptimizer(-2*R)\n",
    "        optimizer_neg=optimizer_neg.apply_gradients(zip(valid_grads, w_var))\n",
    "\n",
    "        optimizer_back=tf.train.GradientDescentOptimizer(R)\n",
    "        optimizer_back=optimizer_back.apply_gradients(zip(valid_grads, w_var))\n",
    "        \n",
    "        with tf.GradientTape() as tape2:\n",
    "            logits_model = self.model(x_train)\n",
    "            train_loss = self.model._criterion(logits_model, y_train)\n",
    "            train_grads_pos=tape2.gradient(train_loss, arch_var)\n",
    "            \n",
    "        with tf.GradientTape() as tape3:\n",
    "            logits_model = self.model(x_train)\n",
    "            train_loss = self.model._criterion(logits_model, y_train)\n",
    "            train_grads_neg=tape3.gradient(train_loss, arch_var)\n",
    "        \n",
    "        with tf.GradientTape() as tape4:\n",
    "            valid_loss = unrolled_model._criterion(unrolled_model(x_valid), y_valid)\n",
    "            leader_grads=tape4.gradient(valid_loss, unrolled_model.arch_parameters())\n",
    "        \n",
    "        for i,(g,v) in enumerate(zip(leader_grads, arch_var)):\n",
    "            leader_grads[i]=(g-lr*tf.divide(train_grads_pos[i]-train_grads_neg[i],2*R),v)\n",
    "        \n",
    "        leader_opt=self.optimizer.apply_gradients(leader_grads)\n",
    "        return leader_opt, unrolled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_search import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "model = Network(3, 3, criterion)\n",
    "args = {\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"arch_learning_rate\": 3e-1,\n",
    "    \"arch_weight_decay\": 1e-3\n",
    "}\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.random_uniform((1, 16, 16, 3), 0, 255)\n",
    "target = tf.random_uniform((1, 16, 16, 1), 0, 1)\n",
    "input_valid = tf.random_uniform((1, 16, 16, 3), 0, 255)\n",
    "target_valid = tf.random_uniform((1, 16, 16, 1), 0, 1)\n",
    "lr=0.025\n",
    "unrolled=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.random_uniform((1, 16, 16, 3), 0, 255)\n",
    "res = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "architect = Architect(model, Struct(**args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt, model = architect.step(inp, target, input_valid, target_valid, lr, unrolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
