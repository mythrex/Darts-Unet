{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from genotypes import PRIMITIVES\n",
    "from genotypes import Genotype\n",
    "from operations import *\n",
    "import numpy as np\n",
    "from utils import get_tensor_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedOp(Model):\n",
    "    \"\"\"Makes mixed operations object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C, stride):\n",
    "        \"\"\"Makes ops array of all the arrays\n",
    "\n",
    "        Args:\n",
    "            C (int): the current state\n",
    "        \"\"\"\n",
    "        super(MixedOp, self).__init__()\n",
    "        self._ops = []\n",
    "        for primitive in PRIMITIVES:\n",
    "                op = OPS[primitive](C, stride)\n",
    "                if 'pool' in primitive:\n",
    "                    if('avg' in primitive):\n",
    "                        op = AvgPool3x3(C, stride)\n",
    "                    elif('max' in primitive):\n",
    "                        op = MaxPool3x3(C, stride)\n",
    "                self._ops.append(op)\n",
    "        \n",
    "    def call(self, x, weights):\n",
    "        \"\"\"Converts the discrete set of operation into conitnuous mixed operation\n",
    "\n",
    "        Args:\n",
    "            x (tensor): can be tensor or array, (e.g. image-array)\n",
    "            weights (tensor): tensor or array of Softmax probability of alphas\n",
    "\n",
    "        Returns:\n",
    "            tensor: sum of product(weights, operation(x))\n",
    "        \"\"\"\n",
    "        op_on_x = self._ops[0](x)\n",
    "        mask = tf.eye(int(weights.shape[0]), dtype=tf.bool)\n",
    "        s = tf.zeros_like(op_on_x)\n",
    "        for i in range(len(self._ops)):\n",
    "            s += get_tensor_at(weights, mask, i) * self._ops[i](x)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_op = MixedOp(3, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.rand(8).astype(np.float32)\n",
    "np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(2)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "it = ds_train.make_one_shot_iterator()\n",
    "image, label = it.get_next()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "out = mix_op(image, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    sess.run(init)\n",
    "    res = sess.run(out)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(Model):\n",
    "\n",
    "    def __init__(self, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev, upsample_prev):\n",
    "        super(Cell, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "        if reduction_prev:\n",
    "            self.preprocess0 = FactorizedReduce(C_prev_prev, C)\n",
    "        elif upsample_prev:\n",
    "            self.preprocess0 = FactorizedUp(C_prev_prev, C)\n",
    "        else:\n",
    "            self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 'same')\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 'same')\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "\n",
    "        self._ops = []\n",
    "        for i in range(self._steps):\n",
    "            for j in range(2+i):\n",
    "                stride = 2 if reduction and j < 2 else 1\n",
    "                op = MixedOp(C, stride)\n",
    "                self._ops.append(op)\n",
    "\n",
    "    def call(self, s0, s1, weights):\n",
    "    \n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "\n",
    "        states = [s0, s1]\n",
    "        offset = 0\n",
    "    \n",
    "        for i in range(self._steps):\n",
    "            s = sum(self._ops[offset+j](h, weights[offset+j]) for j, h in enumerate(states))\n",
    "            offset += len(states)\n",
    "            states.append(s)\n",
    "\n",
    "        return tf.concat(states[-self._multiplier:], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From operations.py:61: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cell = Cell(steps=4,\n",
    "            multiplier=4,\n",
    "            C_prev_prev=3,\n",
    "            C_prev=3,\n",
    "            C=3,\n",
    "            reduction=False,\n",
    "            reduction_prev=False,\n",
    "            upsample_prev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "weights = tf.random_uniform([14,8], 0, 1)\n",
    "s0 = tf.random_uniform([2, 16, 16, 3], 0, 255)\n",
    "s1 = tf.random_uniform([2, 16, 16, 3], 0, 255)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "cell_out = cell(s0, s1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    sess.run(init)\n",
    "    res = sess.run(cell_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16, 16, 12)\n"
     ]
    }
   ],
   "source": [
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleCell(Model):\n",
    "\n",
    "    def __init__(self, steps, multiplier, C_prev_prev, C_prev, C):\n",
    "        super(UpsampleCell, self).__init__()\n",
    "        self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 'same')\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 'same')\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "        self.UpConv = layers.Conv2DTranspose(C*self._multiplier, \n",
    "                                        kernel_size=3,\n",
    "                                        strides=2,\n",
    "                                        padding='same')\n",
    "        self.reduction = False\n",
    "\n",
    "    def call(self, s0, s1, weights):\n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "\n",
    "        s0 = self.UpConv(s0)\n",
    "        s1 = self.UpConv(s1)\n",
    "\n",
    "        return s0 + s1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample Cell Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_cell = UpsampleCell(4, 4, 3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32, 32, 12)\n"
     ]
    }
   ],
   "source": [
    "s0 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "s1 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "up_cell_out = up_cell(s0, s1, [])\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    sess.run(init)\n",
    "    res = sess.run(up_cell_out)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Model):\n",
    "\n",
    "    def __init__(self, C, net_layers, criterion, steps=4, multiplier=4, stem_multiplier=3):\n",
    "        super(Network, self).__init__()\n",
    "        self._C = C\n",
    "        self._criterion = criterion\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "        self.net_layers = net_layers\n",
    "\n",
    "        C_curr = C*stem_multiplier\n",
    "\n",
    "        # stem operation\n",
    "        self.stem_op = tf.keras.Sequential()\n",
    "        self.stem_op.add(tf.keras.layers.Conv2D(\n",
    "            C_curr, kernel_size=3, padding='same', use_bias=False))\n",
    "        self.stem_op.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n",
    "        self.cells = []\n",
    "        self.skip_ops = []\n",
    "\n",
    "        reduction_prev = False\n",
    "\n",
    "        # For reduction\n",
    "        for i in range(self.net_layers):\n",
    "            if i % 2 == 1:\n",
    "                C_curr *= 2\n",
    "                reduction = True\n",
    "            else:\n",
    "                reduction = False\n",
    "                self.skip_ops += [SkipConnection(C_curr)]\n",
    "            cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr,\n",
    "                        reduction,\n",
    "                        reduction_prev,\n",
    "                        upsample_prev=False)\n",
    "            reduction_prev = reduction\n",
    "            self.cells += [cell]\n",
    "\n",
    "            C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "\n",
    "        for i in range(self.net_layers-1):\n",
    "            if i % 2 == 0:\n",
    "                C_curr = C_curr // 2\n",
    "\n",
    "                cell = UpsampleCell(steps, multiplier,\n",
    "                                    C_prev_prev, C_prev, C_curr)\n",
    "            else:\n",
    "                cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr,\n",
    "                            reduction=False,\n",
    "                            reduction_prev=False,\n",
    "                            upsample_prev=True)\n",
    "            self.cells += [cell]\n",
    "            C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "\n",
    "        self.softmaxConv = tf.keras.Sequential()\n",
    "        self.softmaxConv.add(tf.keras.layers.Conv2D(\n",
    "            1, kernel_size=1, strides=1, padding='same'))\n",
    "        self.softmaxConv.add(Softmax())\n",
    "\n",
    "        self._initialize_alphas()\n",
    "\n",
    "    def _initialize_alphas(self):\n",
    "        k = sum(1 for i in range(self._steps) for n in range(2+i))\n",
    "        num_ops = len(PRIMITIVES)\n",
    "\n",
    "        self.alphas_normal = tf.Variable(\n",
    "            1e-3*tf.random.uniform([k, num_ops]), name='alphas_normal')\n",
    "        self.alphas_reduce = tf.Variable(\n",
    "            1e-3*tf.random.uniform([k, num_ops]), name='alphas_reduce')\n",
    "        self._arch_parameters = [\n",
    "            self.alphas_normal,\n",
    "            self.alphas_reduce,\n",
    "        ]\n",
    "\n",
    "    def arch_parameters(self):\n",
    "        return self._arch_parameters\n",
    "\n",
    "    def new(self):\n",
    "        model_new = Network(self._C, self.net_layers, self._criterion)\n",
    "        for x, y in zip(model_new.arch_parameters(), self.arch_parameters()):\n",
    "            x.assign(y)\n",
    "        return model_new\n",
    "\n",
    "    def _loss(self, logits, target):\n",
    "        return self._criterion(logits, tf.to_float(target))\n",
    "\n",
    "    def call(self, inp):\n",
    "        s0 = s1 = self.stem_op(inp)\n",
    "        self.arr = []\n",
    "        ids = []\n",
    "        pos = -1\n",
    "\n",
    "        middle = self.net_layers - 1\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            if cell.reduction:\n",
    "                weights = tf.nn.softmax(self.alphas_reduce, axis=-1)\n",
    "            else:\n",
    "                weights = tf.nn.softmax(self.alphas_normal, axis=-1)\n",
    "\n",
    "            s0, s1 = s1, cell(s0, s1, weights)\n",
    "\n",
    "            if (i < middle and i % 2 == 0):\n",
    "                self.arr.append(s1)\n",
    "                ids.append(i)\n",
    "\n",
    "            if (i > middle and i % 2 == 1):\n",
    "                C_curr = s1.shape[1]\n",
    "                s1 = self.skip_ops[-pos-1](self.arr[pos], s1)\n",
    "                pos -= 1\n",
    "\n",
    "        return self.softmaxConv(s1)\n",
    "\n",
    "    def genotype(self):\n",
    "\n",
    "        def _parse(weights):\n",
    "            gene = []\n",
    "            n = 2\n",
    "            start = 0\n",
    "            for i in range(self._steps):\n",
    "                end = start + n\n",
    "                W = weights[start:end].copy()\n",
    "                edges = sorted(range(i + 2), key=lambda x: -max(\n",
    "                    W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n",
    "                for j in edges:\n",
    "                    k_best = None\n",
    "                    for k in range(len(W[j])):\n",
    "                        if k != PRIMITIVES.index('none'):\n",
    "                            if k_best is None or W[j][k] > W[j][k_best]:\n",
    "                                k_best = k\n",
    "                    gene.append((PRIMITIVES[k_best], j))\n",
    "                start = end\n",
    "                n += 1\n",
    "            return gene\n",
    "\n",
    "            gene_normal = _parse(tf.nn.softmax(\n",
    "                self.alphas_normal, axis=-1).numpy())\n",
    "            gene_reduce = _parse(tf.nn.softmax(\n",
    "                self.alphas_reduce, dim=-1).numpy())\n",
    "\n",
    "            concat = range(2+self._steps-self._multiplier, self._steps+2)\n",
    "            genotype = Genotype(\n",
    "                normal=gene_normal, normal_concat=concat,\n",
    "                reduce=gene_reduce, reduce_concat=concat\n",
    "            )\n",
    "            return genotype\n",
    "\n",
    "    def get_thetas(self):\n",
    "        specific_tensor = []\n",
    "        specific_tensor_name = []\n",
    "        for var in self.trainable_weights:\n",
    "            if not 'alphas' in var.name:\n",
    "                specific_tensor.append(var)\n",
    "                specific_tensor_name.append(var.name)\n",
    "        return specific_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "network = Network(3, 3, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(2)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "it = ds_train.make_one_shot_iterator()\n",
    "image, label = it.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Softmax.call of <operations.Softmax object at 0x7f59040d4ad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Softmax.call of <operations.Softmax object at 0x7f59040d4ad0>>, which Python reported as:\n",
      "    def call(self, x):\n",
      "#         return self.op(x, axis)\n",
      "        return x\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method Softmax.call of <operations.Softmax object at 0x7f59040d4ad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Softmax.call of <operations.Softmax object at 0x7f59040d4ad0>>, which Python reported as:\n",
      "    def call(self, x):\n",
      "#         return self.op(x, axis)\n",
      "        return x\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    }
   ],
   "source": [
    "net_out = network(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf.initialize_all_variables().run()\n",
    "    res = sess.run(net_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 16, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.random.rand(2, 16, 16, 6).astype(np.float32)\n",
    "conv = tf.keras.Sequential()\n",
    "conv.add(ReLUConvBN(6, 6, 1, 1, 'same'))\n",
    "conv.add(FactorizedReduce(6,6))\n",
    "conv(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.Variable([[0.9], [0.5]])\n",
    "var2 = tf.Variable([[0.9], [0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero(2).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
