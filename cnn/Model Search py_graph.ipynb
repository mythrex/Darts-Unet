{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from genotypes import PRIMITIVES\n",
    "from genotypes import Genotype\n",
    "from operations import *\n",
    "import numpy as np\n",
    "from utils import get_tensor_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_BFLOAT = True\n",
    "\n",
    "class MixedOp(Model):\n",
    "    \"\"\"Makes mixed operations object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C, stride):\n",
    "        \"\"\"Makes ops array of all the arrays\n",
    "\n",
    "        Args:\n",
    "            C (int): the current state\n",
    "        \"\"\"\n",
    "        super(MixedOp, self).__init__()\n",
    "        self._ops = []\n",
    "        for primitive in PRIMITIVES:\n",
    "                op = OPS[primitive](C, stride)\n",
    "                if 'pool' in primitive:\n",
    "                    if('avg' in primitive):\n",
    "                        op = AvgPool3x3(C, stride)\n",
    "                    elif('max' in primitive):\n",
    "                        op = MaxPool3x3(C, stride)\n",
    "                self._ops.append(op)\n",
    "        \n",
    "    def call(self, x, weights):\n",
    "        \"\"\"Converts the discrete set of operation into conitnuous mixed operation\n",
    "\n",
    "        Args:\n",
    "            x (tensor): can be tensor or array, (e.g. image-array)\n",
    "            weights (tensor): tensor or array of Softmax probability of alphas\n",
    "\n",
    "        Returns:\n",
    "            tensor: sum of product(weights, operation(x))\n",
    "        \"\"\"\n",
    "        computed_ops = tf.convert_to_tensor([op(x) for op in self._ops])\n",
    "        weights = tf.reshape(weights, (weights.shape[0], 1, 1, 1, 1))\n",
    "        if(USE_BFLOAT):\n",
    "            computed_ops = tf.cast(computed_ops, dtype=tf.bfloat16, name='computed_ops_to_bfloat16')\n",
    "            weights = tf.cast(computed_ops, dtype=tf.bfloat16, name='weights_to_bfloat16')\n",
    "        return tf.reduce_sum(weights * computed_ops, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'mixed_op_3/computed_ops_to_bfloat16:0' shape=(8, 2, 16, 16, 3) dtype=bfloat16>, <tf.Tensor 'mixed_op_3/computed_ops_to_bfloat16:0' shape=(8, 2, 16, 16, 3) dtype=bfloat16>)\n"
     ]
    }
   ],
   "source": [
    "mix_op = MixedOp(3, 1)\n",
    "weights = tf.random_uniform(minval=0, maxval=2, shape=[4])\n",
    "np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(2, drop_remainder=True)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "it = ds_train.make_one_shot_iterator()\n",
    "image, label = it.get_next()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "out = mix_op(image, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "(2, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    sess.run(init)\n",
    "    res = sess.run(out)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(Model):\n",
    "\n",
    "    def __init__(self, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev, upsample_prev):\n",
    "        super(Cell, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "        if reduction_prev:\n",
    "            self.preprocess0 = FactorizedReduce(C_prev_prev, C)\n",
    "        elif upsample_prev:\n",
    "            self.preprocess0 = FactorizedUp(C_prev_prev, C)\n",
    "        else:\n",
    "            self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 'same')\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 'same')\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "\n",
    "        self._ops = []\n",
    "        for i in range(self._steps):\n",
    "            for j in range(2+i):\n",
    "                stride = 2 if reduction and j < 2 else 1\n",
    "                op = MixedOp(C, stride)\n",
    "                self._ops.append(op)\n",
    "\n",
    "    def call(self, s0, s1, weights):\n",
    "    \n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "        states = [s0, s1]\n",
    "        offset = 0\n",
    "    \n",
    "        for i in range(self._steps):\n",
    "            s = sum(self._ops[offset+j](h, weights[offset+j]) for j, h in enumerate(states))\n",
    "            offset += len(states)\n",
    "            states.append(s)\n",
    "\n",
    "        return tf.concat(states[-self._multiplier:], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = Cell(steps=4,\n",
    "            multiplier=4,\n",
    "            C_prev_prev=3,\n",
    "            C_prev=3,\n",
    "            C=3,\n",
    "            reduction=False,\n",
    "            reduction_prev=False,\n",
    "            upsample_prev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.random_uniform([14,4], 0, 1)\n",
    "s0 = tf.random_uniform([2, 16, 16, 3], 0, 255)\n",
    "s1 = tf.random_uniform([2, 16, 16, 3], 0, 255)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "cell_out = cell(s0, s1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    sess.run(init)\n",
    "    res = sess.run(cell_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16, 16, 12)\n"
     ]
    }
   ],
   "source": [
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleCell(Model):\n",
    "\n",
    "    def __init__(self, steps, multiplier, C_prev_prev, C_prev, C):\n",
    "        super(UpsampleCell, self).__init__()\n",
    "        self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 'same')\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 'same')\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "        self.UpConv = layers.Conv2DTranspose(C*self._multiplier, \n",
    "                                        kernel_size=3,\n",
    "                                        strides=2,\n",
    "                                        padding='same')\n",
    "        self.reduction = False\n",
    "\n",
    "    def call(self, s0, s1, weights):\n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "\n",
    "        s0 = self.UpConv(s0)\n",
    "        s1 = self.UpConv(s1)\n",
    "\n",
    "        return s0 + s1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample Cell Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_cell = UpsampleCell(4, 4, 3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32, 32, 12)\n"
     ]
    }
   ],
   "source": [
    "s0 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "s1 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "up_cell_out = up_cell(s0, s1, [])\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    sess.run(init)\n",
    "    res = sess.run(up_cell_out)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Model):\n",
    "\n",
    "    def __init__(self, C, net_layers, criterion, steps=4, multiplier=4, stem_multiplier=3, num_classes=1):\n",
    "        super(Network, self).__init__()\n",
    "        self._C = C\n",
    "        self._criterion = criterion\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "        self.net_layers = net_layers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        C_curr = C*stem_multiplier\n",
    "\n",
    "        # stem operation\n",
    "        self.stem_op = tf.keras.Sequential()\n",
    "        self.stem_op.add(tf.keras.layers.Conv2D(\n",
    "            C_curr, kernel_size=3, padding='same', use_bias=False))\n",
    "        self.stem_op.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n",
    "        self.cells = []\n",
    "        self.skip_ops = []\n",
    "\n",
    "        reduction_prev = False\n",
    "\n",
    "        # For reduction\n",
    "        for i in range(self.net_layers):\n",
    "            if i % 2 == 1:\n",
    "                C_curr *= 2\n",
    "                reduction = True\n",
    "            else:\n",
    "                reduction = False\n",
    "                self.skip_ops += [SkipConnection(C_curr)]\n",
    "            cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr,\n",
    "                        reduction,\n",
    "                        reduction_prev,\n",
    "                        upsample_prev=False)\n",
    "            reduction_prev = reduction\n",
    "            self.cells += [cell]\n",
    "\n",
    "            C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "\n",
    "        for i in range(self.net_layers-1):\n",
    "            if i % 2 == 0:\n",
    "                C_curr = C_curr // 2\n",
    "\n",
    "                cell = UpsampleCell(steps, multiplier,\n",
    "                                    C_prev_prev, C_prev, C_curr)\n",
    "            else:\n",
    "                cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr,\n",
    "                            reduction=False,\n",
    "                            reduction_prev=False,\n",
    "                            upsample_prev=True)\n",
    "            self.cells += [cell]\n",
    "            C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "        \n",
    "        self.softmaxConv = tf.keras.Sequential(name=\"softmaxConv\")\n",
    "        self.softmaxConv.add(tf.keras.layers.Conv2D(\n",
    "            self.num_classes, kernel_size=1, strides=1, padding='same'))\n",
    "        self.softmaxConv.add(Softmax())\n",
    "\n",
    "        self._initialize_alphas()\n",
    "\n",
    "    def _initialize_alphas(self):\n",
    "        k = sum(1 for i in range(self._steps) for n in range(2+i))\n",
    "        num_ops = len(PRIMITIVES)\n",
    "        alphas_normal = lambda: 1e-3*tf.random.uniform([k, num_ops])\n",
    "        alphas_reduce = lambda: 1e-3*tf.random.uniform([k, num_ops])\n",
    "        self.alphas_normal = tf.Variable(\n",
    "            alphas_normal, name='alphas_normal')\n",
    "        self.alphas_reduce = tf.Variable(\n",
    "            alphas_reduce, name='alphas_reduce')\n",
    "        self._arch_parameters = [\n",
    "            self.alphas_normal,\n",
    "            self.alphas_reduce,\n",
    "        ]\n",
    "\n",
    "    def arch_parameters(self):\n",
    "        return self._arch_parameters\n",
    "\n",
    "    def new(self):\n",
    "        model_new = Network(self._C, self.net_layers, self._criterion, num_classes=self.num_classes)\n",
    "        for x, y in zip(model_new.arch_parameters(), self.arch_parameters()):\n",
    "            x.assign(y)\n",
    "        return model_new\n",
    "\n",
    "    def _loss(self, logits, target):\n",
    "        b, w, h, c = target.shape\n",
    "        y = tf.reshape(tf.cast(target, tf.int64), (b, w, h))\n",
    "        y = tf.one_hot(y, self.num_classes, on_value=1.0, off_value=0.0)\n",
    "        return self._criterion(y, logits)\n",
    "\n",
    "    def call(self, inp):\n",
    "        s0 = s1 = self.stem_op(inp)\n",
    "        self.arr = []\n",
    "        ids = []\n",
    "        pos = -1\n",
    "\n",
    "        middle = self.net_layers - 1\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            if cell.reduction:\n",
    "                weights = tf.nn.softmax(self.alphas_reduce, axis=-1)\n",
    "            else:\n",
    "                weights = tf.nn.softmax(self.alphas_normal, axis=-1)\n",
    "\n",
    "            s0, s1 = s1, cell(s0, s1, weights)\n",
    "\n",
    "            if (i < middle and i % 2 == 0):\n",
    "                self.arr.append(s1)\n",
    "                ids.append(i)\n",
    "\n",
    "            if (i > middle and i % 2 == 1):\n",
    "                C_curr = s1.shape[1]\n",
    "                s1 = self.skip_ops[-pos-1](self.arr[pos], s1)\n",
    "                pos -= 1\n",
    "        return self.softmaxConv(s1)\n",
    "    \n",
    "    def genotype(self, alphas_normal, alphas_reduce):\n",
    "            def _parse(weights):\n",
    "                gene = []\n",
    "                n = 2\n",
    "                start = 0\n",
    "                for i in range(self._steps):\n",
    "                    end = start + n\n",
    "                    W = weights[start:end].copy()\n",
    "                    edges = sorted(range(i + 2), key=lambda x: -max(W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n",
    "                    for j in edges:\n",
    "                        k_best = None\n",
    "                        for k in range(len(W[j])):\n",
    "                            if k != PRIMITIVES.index('none'):\n",
    "                                if k_best is None or W[j][k] > W[j][k_best]:\n",
    "                                    k_best = k\n",
    "                        gene.append((PRIMITIVES[k_best], j))\n",
    "                    start = end\n",
    "                    n += 1\n",
    "                return gene\n",
    "\n",
    "            gene_normal = _parse(alphas_normal)\n",
    "            gene_reduce = _parse(alphas_reduce)\n",
    "\n",
    "            concat = range(2+self._steps-self._multiplier, self._steps+2)\n",
    "            genotype = Genotype(\n",
    "              normal=gene_normal, normal_concat=concat,\n",
    "              reduce=gene_reduce, reduce_concat=concat\n",
    "            )\n",
    "            return genotype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "network = Network(3, 3, criterion, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "a = network.arch_parameters()[0]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    out = sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(2, drop_remainder=True)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "it = ds_train.make_one_shot_iterator()\n",
    "image, label = it.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_out = network(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf.initialize_all_variables().run()\n",
    "    res = sess.run(net_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_theta(model):\n",
    "    specific_tensor = []\n",
    "    specific_tensor_name = []\n",
    "    for var in model.trainable_weights:\n",
    "        if not 'alphas' in var.name:\n",
    "            specific_tensor.append(var)\n",
    "            specific_tensor_name.append(var.name)\n",
    "    return specific_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network\n",
    "arch_var = model.arch_parameters()\n",
    "w_var = get_model_theta(model)\n",
    "logits = model(image)\n",
    "train_loss = model._loss(logits, label)\n",
    "train_grads = tf.gradients(train_loss, w_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf.initialize_all_variables().run()\n",
    "    out1 = sess.run(train_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.random.rand(2, 16, 16, 6).astype(np.float32)\n",
    "conv = tf.keras.Sequential()\n",
    "conv.add(ReLUConvBN(6, 6, 1, 1, 'same'))\n",
    "conv.add(FactorizedReduce(6,6))\n",
    "conv(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.Variable([[0.9], [0.5]])\n",
    "var2 = tf.Variable([[0.9], [0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero(2).name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _parse(weights):\n",
    "    with tf.variable_scope(\"parse\"):\n",
    "        primitives = tf.convert_to_tensor(PRIMITIVES)\n",
    "        gene = []\n",
    "        n = 2\n",
    "        start = 0\n",
    "        for i in range(steps):\n",
    "            end = start + n\n",
    "            W = tf.identity(weights[start:end], name=\"alphas_for_op_strided\")\n",
    "            none_idx = PRIMITIVES.index('none')\n",
    "            # make none_weight to be -inf\n",
    "            mask = np.ones(W.shape)\n",
    "            mask[:, none_idx] = -1\n",
    "            W = W * tf.convert_to_tensor(mask, dtype=W.dtype)        \n",
    "            # calc of edges\n",
    "            W_sorted = tf.sort(W, axis=-1, direction='DESCENDING', name='sorted_weights')\n",
    "            edges = tf.argsort(W_sorted[:,0], axis=-1, direction='DESCENDING', name='edges')[:2]\n",
    "\n",
    "            for idx in range(edges.shape[0]):\n",
    "                j = edges[idx]\n",
    "                j = tf.identity(j, name=\"selected_op\")\n",
    "#                 tf.get_default_graph().add_to_collection(j.name, j)\n",
    "                k_best = tf.argsort(W, axis=-1, direction='DESCENDING', name='k_best')[j][0]\n",
    "                sel_block = primitives[k_best]\n",
    "                sel_block = tf.identity(sel_block, name=\"selected_block\")\n",
    "#                 tf.get_default_graph().add_to_collection(sel_block.name, sel_block)\n",
    "                gene.append((sel_block, j))\n",
    "            start = end\n",
    "            n += 1\n",
    "        return gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = sum(1 for i in range(4) for n in range(2+i))\n",
    "num_ops = len(PRIMITIVES)\n",
    "weights = tf.nn.softmax(tf.Variable(1e-3*tf.random.uniform([k, num_ops]), name='weights'), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 4\n",
    "def calc_gene():\n",
    "    return _parse(weights)\n",
    "\n",
    "def run_gene(session):\n",
    "    res = calc_gene()\n",
    "    return session.run(res)\n",
    "\n",
    "def make_genotype():\n",
    "    gene_normal = _parse(tf.nn.softmax(weights, axis=-1))\n",
    "    gene_reduce = _parse(tf.nn.softmax(weights, axis=-1))\n",
    "\n",
    "    concat = range(2+steps-2, steps+2)\n",
    "    genotype = Genotype(\n",
    "        normal=gene_normal, normal_concat=concat,\n",
    "        reduce=gene_reduce, reduce_concat=concat\n",
    "    )\n",
    "    return genotype\n",
    "\n",
    "def ret_genotype(session):\n",
    "    genotype = make_genotype()\n",
    "    gene_normal_op = genotype.normal\n",
    "    return run_gene(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'PartitionedCall:0' shape=() dtype=string>,\n",
       "  <tf.Tensor 'PartitionedCall:1' shape=() dtype=int32>),\n",
       " (<tf.Tensor 'PartitionedCall:2' shape=() dtype=string>,\n",
       "  <tf.Tensor 'PartitionedCall:3' shape=() dtype=int32>),\n",
       " (<tf.Tensor 'PartitionedCall:4' shape=() dtype=string>,\n",
       "  <tf.Tensor 'PartitionedCall:5' shape=() dtype=int32>),\n",
       " (<tf.Tensor 'PartitionedCall:6' shape=() dtype=string>,\n",
       "  <tf.Tensor 'PartitionedCall:7' shape=() dtype=int32>),\n",
       " (<tf.Tensor 'PartitionedCall:8' shape=() dtype=string>,\n",
       "  <tf.Tensor 'PartitionedCall:9' shape=() dtype=int32>),\n",
       " (<tf.Tensor 'PartitionedCall:10' shape=() dtype=string>,\n",
       "  <tf.Tensor 'PartitionedCall:11' shape=() dtype=int32>),\n",
       " (<tf.Tensor 'PartitionedCall:12' shape=() dtype=string>,\n",
       "  <tf.Tensor 'PartitionedCall:13' shape=() dtype=int32>),\n",
       " (<tf.Tensor 'PartitionedCall:14' shape=() dtype=string>,\n",
       "  <tf.Tensor 'PartitionedCall:15' shape=() dtype=int32>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_gene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    out = ret_genotype(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('avg_pool_3x3', 1),\n",
       " ('max_pool_3x3', 0),\n",
       " ('max_pool_3x3', 1),\n",
       " ('avg_pool_3x3', 0),\n",
       " ('max_pool_3x3', 0),\n",
       " ('max_pool_3x3', 1),\n",
       " ('max_pool_3x3', 4),\n",
       " ('max_pool_3x3', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='parse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['local_variables', 'variables', 'trainable_variables']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_all_collection_keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
