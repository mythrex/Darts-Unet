{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "from model_search import Network\n",
    "from architect_graph import Architect\n",
    "from genotypes import Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From operations.py:290: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:7: The name tf.layers.MaxPooling2D is deprecated. Please use tf.compat.v1.layers.MaxPooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:6: The name tf.layers.AveragePooling2D is deprecated. Please use tf.compat.v1.layers.AveragePooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From model_search.py:93: The name tf.layers.Conv2DTranspose is deprecated. Please use tf.compat.v1.layers.Conv2DTranspose instead.\n",
      "\n",
      "WARNING:tensorflow:From model_search.py:179: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-469036e03d23>:64: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From architect_graph.py:41: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From architect_graph.py:47: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From architect_graph.py:50: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model_theta(model):\n",
    "    specific_tensor = []\n",
    "    specific_tensor_name = []\n",
    "    for var in model.trainable_weights:\n",
    "        if not 'alphas' in var.name:\n",
    "            specific_tensor.append(var)\n",
    "            specific_tensor_name.append(var.name)\n",
    "    return specific_tensor\n",
    "\n",
    "args = {\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"arch_learning_rate\": 3e-1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"grad_clip\": 5,\n",
    "    \"learning_rate\": 0.025,\n",
    "    \"learning_rate_decay\": 0.97,\n",
    "    \"learning_rate_min\": 0.0001,\n",
    "    \"num_batches_per_epoch\": 2000,\n",
    "    \n",
    "    \"unrolled\": True,\n",
    "    \"epochs\": 10,\n",
    "    \"train_batch_size\": 2,\n",
    "    \"eval_batch_size\": 2,\n",
    "    \"save\": \"EXP\",\n",
    "    \"init_channels\": 3,\n",
    "    \"num_layers\": 3,\n",
    "    \"num_classes\": 6,\n",
    "    \"crop_size\": [8, 8],\n",
    "    \"save_checkpoints_steps\": 100,\n",
    "    \"model_dir\": 'gs://unet-darts/train-search-ckptss',\n",
    "    \"max_steps\": 10000,\n",
    "    # NEW\n",
    "    \"steps_per_eval\": 2,\n",
    "    \"num_train_examples\": 16,\n",
    "    #\n",
    "    \n",
    "    \"use_tpu\": False,\n",
    "    \"use_host_call\": True,\n",
    "    \"tpu\": 'unet-darts',\n",
    "    \"zone\": 'us-central1-f',\n",
    "    \"project\": \"isro-nas\",\n",
    "}\n",
    "args.update({\"num_batches_per_epoch\": args[\"num_train_examples\"] // args[\"train_batch_size\"]})\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = Struct(**args)\n",
    "\n",
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "model = Network(3, 3, criterion, num_classes=args.num_classes)\n",
    "lr=args.learning_rate\n",
    "unrolled=args.unrolled\n",
    "W, H = args.crop_size[0], args.crop_size[1]\n",
    "NUM_IMAGES = 20\n",
    "x_train = np.random.randint(0, 256, (NUM_IMAGES, W, H, 3)).astype(np.float32)\n",
    "y_train = np.random.randint(0, args.num_classes, (NUM_IMAGES, W, H, 1)).astype(np.float32)\n",
    "x_valid = np.random.randint(0, 256, (NUM_IMAGES, W, H, 3)).astype(np.float32)\n",
    "y_valid = np.random.randint(0, args.num_classes, (NUM_IMAGES, W, H, 1)).astype(np.float32)\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(args.train_batch_size, drop_remainder=True)\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).batch(args.train_batch_size, drop_remainder=True)\n",
    "it_train = ds_train.make_one_shot_iterator()\n",
    "image, label = it_train.get_next()\n",
    "it_valid = ds_valid.make_one_shot_iterator()\n",
    "image_valid, label_valid = it_valid.get_next()\n",
    "init = tf.global_variables_initializer()\n",
    "_ = model(image)\n",
    "architect = Architect(model, args)\n",
    "\n",
    "global_step = tf.train.get_global_step()\n",
    "learning_rate_min = tf.constant(args.learning_rate_min)\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    args.learning_rate,\n",
    "    global_step,\n",
    "    decay_rate=args.learning_rate_decay,\n",
    "    decay_steps=args.num_batches_per_epoch,\n",
    "    staircase=True,\n",
    "    )\n",
    "lr = tf.maximum(learning_rate, learning_rate_min)\n",
    "\n",
    "b, w, h, c = label.shape\n",
    "y = tf.reshape(tf.cast(label, tf.int64), (b, w, h))\n",
    "y = tf.one_hot(y, args.num_classes, on_value=1.0, off_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From architect_graph.py:112: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From architect_graph.py:124: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arch_step = architect.step(image, label, image_valid, label_valid, unrolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_var = model.get_thetas()\n",
    "preds = model(image)\n",
    "loss = model._loss(preds, label)\n",
    "optimizer = tf.train.MomentumOptimizer(lr, args.momentum)\n",
    "train_op = optimizer.minimize(loss, var_list=w_var, global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_params = model.arch_parameters()\n",
    "alphas_normal, alphas_reduce = arch_params[0], arch_params[1]\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Computing Arch Step\n",
      "Computing Train Step\n",
      "Model saved in path: ./final_model/shit_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf.initialize_all_variables().run()\n",
    "    w_var_o = sess.run(w_var)\n",
    "    alphas_normal_bo, alphas_reduce_bo = sess.run([alphas_normal, alphas_reduce])\n",
    "    print(\"Computing Arch Step\")\n",
    "    sess.run(arch_step)\n",
    "    alphas_normal_ao, alphas_reduce_ao = sess.run([alphas_normal, alphas_reduce])\n",
    "    print(\"Computing Train Step\")\n",
    "    sess.run(train_op)\n",
    "    w_var_ao = sess.run(w_var)\n",
    "    save_path = saver.save(sess, \"./final_model/shit_model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.12536159e-04, 7.32944871e-04, 9.54648887e-04, 7.41222757e-04],\n",
       "       [1.92740205e-04, 2.85102869e-04, 4.22806508e-04, 8.78524093e-04],\n",
       "       [8.07227509e-04, 7.91816856e-04, 9.16260644e-04, 3.12135584e-04],\n",
       "       [6.07450493e-04, 4.67423699e-04, 4.86078876e-04, 7.58790062e-04],\n",
       "       [1.77840833e-04, 5.76221964e-06, 8.09587538e-04, 9.34876851e-04],\n",
       "       [2.95954233e-04, 1.99510701e-04, 4.28048748e-04, 7.74598157e-04],\n",
       "       [4.27998079e-04, 8.43071379e-04, 6.53319061e-04, 3.91634967e-04],\n",
       "       [9.56513337e-04, 5.22855553e-05, 3.46614630e-04, 8.97666265e-04],\n",
       "       [2.59233260e-04, 1.50762688e-04, 7.16523558e-04, 9.15468379e-04],\n",
       "       [1.24872931e-05, 6.87128224e-04, 4.30633314e-04, 4.58354625e-04],\n",
       "       [1.69412029e-04, 2.34465129e-04, 3.21025145e-04, 6.04183006e-04],\n",
       "       [1.70330648e-04, 9.72496462e-04, 2.30917110e-04, 1.98182592e-04],\n",
       "       [4.84933407e-04, 9.02137544e-04, 4.99655958e-04, 1.16319665e-04],\n",
       "       [7.15676229e-04, 2.81204004e-04, 8.78347550e-04, 3.32722557e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_normal_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.1198615e-04, 7.2746788e-04, 9.6007105e-04, 7.4182759e-04],\n",
       "       [1.8302909e-04, 2.9186808e-04, 4.3197046e-04, 8.7230606e-04],\n",
       "       [8.0202968e-04, 7.9980376e-04, 9.1616018e-04, 3.0944683e-04],\n",
       "       [5.9581187e-04, 4.7895222e-04, 4.9409480e-04, 7.5088424e-04],\n",
       "       [1.6830792e-04, 1.2588678e-05, 8.1552973e-04, 9.3164120e-04],\n",
       "       [2.9931555e-04, 1.9713894e-04, 4.2687057e-04, 7.7478675e-04],\n",
       "       [4.1851398e-04, 8.5141859e-04, 6.6222821e-04, 3.8386270e-04],\n",
       "       [9.5327944e-04, 5.5400473e-05, 3.5133364e-04, 8.9306623e-04],\n",
       "       [2.5579846e-04, 1.5495979e-04, 7.2160648e-04, 9.0962322e-04],\n",
       "       [9.9319368e-06, 6.9085346e-04, 4.3143576e-04, 4.5638229e-04],\n",
       "       [1.6581672e-04, 2.4000688e-04, 3.2327723e-04, 5.9998449e-04],\n",
       "       [1.6850508e-04, 9.7663119e-04, 2.3424468e-04, 1.9254586e-04],\n",
       "       [4.7988590e-04, 9.0659113e-04, 5.0395430e-04, 1.1261527e-04],\n",
       "       [7.0980861e-04, 2.8840150e-04, 8.8462618e-04, 3.2511406e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_normal_ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(alphas_normal_bo, alphas_normal_ao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check w_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-3.44002545e-02, -1.95918381e-01,  1.27433315e-01,\n",
       "          -2.09924355e-01, -1.80527866e-02,  7.20191747e-02,\n",
       "          -3.11945081e-02, -1.07923865e-01, -1.94553614e-01],\n",
       "         [ 4.17596102e-03,  7.32188970e-02,  2.52482742e-02,\n",
       "          -1.71959430e-01, -9.04804617e-02,  6.78667575e-02,\n",
       "           6.45583421e-02, -1.84949189e-01,  9.80690867e-02],\n",
       "         [-1.97424665e-01,  1.63378432e-01, -1.32725090e-01,\n",
       "           2.25142345e-01, -2.21933275e-01,  4.13633138e-02,\n",
       "          -7.43439496e-02, -5.44528812e-02, -1.12978280e-01]],\n",
       "\n",
       "        [[-1.03536546e-01, -1.98178440e-02,  1.99012980e-01,\n",
       "           7.96629339e-02, -7.22578466e-02, -1.48295194e-01,\n",
       "           1.04676977e-01, -2.10286930e-01,  2.21435890e-01],\n",
       "         [-1.07301041e-01, -1.66118085e-01, -2.28298008e-01,\n",
       "           1.17229715e-01,  1.84945598e-01,  1.51183948e-01,\n",
       "          -9.17023867e-02, -1.41135857e-01,  2.32118472e-01],\n",
       "         [ 6.20699376e-02, -1.36453003e-01,  9.61616635e-03,\n",
       "          -8.09987187e-02, -1.50507465e-01, -2.31381416e-01,\n",
       "          -9.96220559e-02, -8.98261219e-02, -8.48646462e-02]],\n",
       "\n",
       "        [[ 4.26831692e-02,  2.35666141e-01, -1.92518204e-01,\n",
       "          -6.32179677e-02, -4.81777191e-02, -9.70279425e-02,\n",
       "           1.74224958e-01, -1.26046777e-01, -8.11755061e-02],\n",
       "         [ 1.16830662e-01,  1.73991308e-01, -6.84522092e-02,\n",
       "          -5.87464124e-02, -6.63815737e-02,  1.09704867e-01,\n",
       "          -1.44383311e-01, -1.79995149e-01, -7.99088478e-02],\n",
       "         [ 5.92263788e-02, -2.30537087e-01, -9.60046798e-02,\n",
       "          -4.44598645e-02, -1.03328392e-01,  8.48423392e-02,\n",
       "          -2.27226868e-01,  7.26344138e-02,  1.22417048e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.15300670e-01,  9.09592956e-02,  2.09618971e-01,\n",
       "           1.09485641e-01,  2.10038707e-01, -2.27864385e-02,\n",
       "          -2.18711630e-01, -1.09282613e-01,  2.08288446e-01],\n",
       "         [-5.21260947e-02,  7.30282515e-02, -3.28297019e-02,\n",
       "          -7.02559799e-02, -2.31740743e-01,  1.17906526e-01,\n",
       "           2.22394988e-01, -9.51945782e-03,  1.26503363e-01],\n",
       "         [-1.49404407e-02, -6.50105625e-02, -2.27499470e-01,\n",
       "          -5.08477539e-02, -1.49284869e-01,  6.91413879e-06,\n",
       "           1.91929832e-01,  1.88350007e-01, -1.91575184e-01]],\n",
       "\n",
       "        [[-1.33339167e-02, -7.02903718e-02,  1.31972805e-01,\n",
       "          -2.18440652e-01, -5.65816909e-02, -9.56511497e-02,\n",
       "           1.99009493e-01, -2.17774794e-01, -2.05380812e-01],\n",
       "         [ 1.73618034e-01, -1.88674629e-02,  8.18173736e-02,\n",
       "           3.55052501e-02, -2.49508172e-02,  1.69617787e-01,\n",
       "           2.08037004e-01, -2.27537066e-01, -7.41192251e-02],\n",
       "         [-1.17251188e-01,  1.39101073e-01,  7.65448064e-02,\n",
       "           1.44372568e-01, -1.82156891e-01,  1.09643444e-01,\n",
       "           4.14167494e-02,  2.11418197e-01, -2.29357198e-01]],\n",
       "\n",
       "        [[-1.12352036e-01,  6.72356933e-02, -1.01850927e-02,\n",
       "          -2.27901608e-01,  1.38382152e-01,  1.05725870e-01,\n",
       "           2.06142142e-01,  1.30410269e-01, -6.19574338e-02],\n",
       "         [-1.33897111e-01,  2.18940526e-02, -1.14987731e-01,\n",
       "          -2.04725951e-01,  1.88961849e-01, -1.12205423e-01,\n",
       "          -8.05483013e-02,  2.19690055e-02,  1.46208152e-01],\n",
       "         [-5.53524643e-02, -1.77934781e-01,  1.74734548e-01,\n",
       "          -9.10484940e-02, -8.86517912e-02, -9.54767764e-02,\n",
       "           1.43925264e-01, -3.77574563e-03, -8.42588544e-02]]],\n",
       "\n",
       "\n",
       "       [[[-1.35795414e-01, -2.03499764e-01,  1.40037969e-01,\n",
       "           5.38610965e-02,  4.74288613e-02, -1.16509736e-01,\n",
       "           1.06731907e-01,  1.83173642e-01, -7.80981034e-02],\n",
       "         [ 2.13736162e-01, -8.08010101e-02, -1.01958394e-01,\n",
       "           8.12895149e-02,  1.10963091e-01, -2.00307339e-01,\n",
       "          -4.85909283e-02,  5.57611138e-02, -1.27011657e-01],\n",
       "         [-1.30207002e-01,  9.45579857e-02,  1.96396098e-01,\n",
       "          -2.14095414e-03,  1.40319392e-01,  1.35356471e-01,\n",
       "          -1.15143277e-01, -2.29210243e-01, -2.27798834e-01]],\n",
       "\n",
       "        [[-1.29171669e-01,  1.68400362e-01, -3.68775427e-02,\n",
       "           1.38511851e-01, -2.01898351e-01, -1.57033026e-01,\n",
       "          -1.72615454e-01, -1.53532878e-01,  8.90060514e-02],\n",
       "         [-2.13920146e-01,  1.79938003e-01, -2.16679081e-01,\n",
       "          -1.73701495e-01,  1.56994835e-01,  1.07258335e-01,\n",
       "           1.14551201e-01,  2.21236333e-01,  2.15351805e-01],\n",
       "         [-8.33487064e-02,  8.39744508e-03,  2.19461009e-01,\n",
       "           1.09141335e-01,  2.29002312e-01,  1.71315476e-01,\n",
       "          -1.74359262e-01,  1.46945372e-01, -2.02851593e-02]],\n",
       "\n",
       "        [[-1.21078961e-01, -2.41852105e-02,  1.18546322e-01,\n",
       "          -1.65055603e-01, -2.73887664e-02, -4.95882928e-02,\n",
       "           2.10286990e-01, -6.28201067e-02, -8.10418725e-02],\n",
       "         [ 1.48362592e-01, -2.12198094e-01, -1.18730485e-01,\n",
       "          -1.96442366e-01, -1.91040590e-01, -8.70390832e-02,\n",
       "          -1.20004497e-01, -1.61979839e-01,  1.75714090e-01],\n",
       "         [ 7.95546621e-02,  4.57485467e-02, -1.03226349e-01,\n",
       "           1.28751591e-01,  2.02829227e-01,  1.10816374e-01,\n",
       "           1.06847882e-02, -4.72580194e-02,  1.15298167e-01]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_var_o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.03442837, -0.19600122,  0.12719032, -0.20992821,\n",
       "          -0.01833246,  0.07180147, -0.03064003, -0.10792386,\n",
       "          -0.19448635],\n",
       "         [ 0.00414314,  0.07310251,  0.02488243, -0.17197381,\n",
       "          -0.0906544 ,  0.06768876,  0.06518925, -0.18494917,\n",
       "           0.09822389],\n",
       "         [-0.1974354 ,  0.16325174, -0.13307647,  0.22510232,\n",
       "          -0.22217709,  0.04119756, -0.07348753, -0.05445288,\n",
       "          -0.11283895]],\n",
       "\n",
       "        [[-0.10354199, -0.01992343,  0.19863144,  0.07962783,\n",
       "          -0.07248777, -0.14840886,  0.10554582, -0.21028695,\n",
       "           0.22161986],\n",
       "         [-0.10730677, -0.16625865, -0.22848445,  0.11719748,\n",
       "           0.18475099,  0.15106677, -0.09111515, -0.14113586,\n",
       "           0.23229635],\n",
       "         [ 0.0620399 , -0.13657337,  0.0093889 , -0.0810284 ,\n",
       "          -0.15057312, -0.23169768, -0.0992375 , -0.08982612,\n",
       "          -0.08481759]],\n",
       "\n",
       "        [[ 0.04264848,  0.23551881, -0.1929766 , -0.06323685,\n",
       "          -0.04846992, -0.09720816,  0.17506917, -0.12604679,\n",
       "          -0.08106883],\n",
       "         [ 0.11680314,  0.17382309, -0.06892596, -0.05877754,\n",
       "          -0.06663039,  0.10942931, -0.1438869 , -0.17999515,\n",
       "          -0.07972892],\n",
       "         [ 0.05918587, -0.23062834, -0.09636187, -0.04448066,\n",
       "          -0.10351159,  0.08468349, -0.22698776,  0.07263441,\n",
       "           0.12255176]]],\n",
       "\n",
       "\n",
       "       [[[ 0.11526269,  0.09082673,  0.20936511,  0.10944518,\n",
       "           0.20973834, -0.02295852, -0.21827768, -0.10926224,\n",
       "           0.20834106],\n",
       "         [-0.05214401,  0.07290158, -0.03299865, -0.07028698,\n",
       "          -0.2319333 ,  0.11775218,  0.22278254, -0.00951756,\n",
       "           0.1266548 ],\n",
       "         [-0.01497459, -0.06512712, -0.22803514, -0.05086839,\n",
       "          -0.14957952, -0.00030511,  0.19230454,  0.18840185,\n",
       "          -0.19144522]],\n",
       "\n",
       "        [[-0.01335619, -0.07043364,  0.13140124, -0.21846466,\n",
       "          -0.0568477 , -0.09590541,  0.1996908 , -0.21774104,\n",
       "          -0.20524825],\n",
       "         [ 0.17358252, -0.01906586,  0.08101635,  0.0354648 ,\n",
       "          -0.02533954,  0.16920105,  0.20856613, -0.22747673,\n",
       "          -0.07394979],\n",
       "         [-0.11727381,  0.13896023,  0.07601503,  0.1443482 ,\n",
       "          -0.1824749 ,  0.10938682,  0.04169526,  0.21148235,\n",
       "          -0.22925596]],\n",
       "\n",
       "        [[-0.11235739,  0.06711554, -0.01070346, -0.22791123,\n",
       "           0.13810095,  0.10562307,  0.20676528,  0.13043708,\n",
       "          -0.06176671],\n",
       "         [-0.13390477,  0.02176624, -0.11556142, -0.20470406,\n",
       "           0.18840943, -0.112448  , -0.08007281,  0.02207769,\n",
       "           0.14632207],\n",
       "         [-0.05538736, -0.17805178,  0.17399327, -0.09105928,\n",
       "          -0.08902778, -0.09583502,  0.1438567 , -0.00371054,\n",
       "          -0.08423706]]],\n",
       "\n",
       "\n",
       "       [[[-0.13581577, -0.20358792,  0.13949846,  0.05382673,\n",
       "           0.04710443, -0.116652  ,  0.10739904,  0.18320227,\n",
       "          -0.07795452],\n",
       "         [ 0.21370761, -0.08094201, -0.10262863,  0.08127028,\n",
       "           0.1104198 , -0.20052722, -0.04802001,  0.05580813,\n",
       "          -0.12693346],\n",
       "         [-0.13024145,  0.09444609,  0.1958927 , -0.00216199,\n",
       "           0.13988087,  0.13499492, -0.11496282, -0.22913262,\n",
       "          -0.22779082]],\n",
       "\n",
       "        [[-0.12918706,  0.16820891, -0.03739309,  0.13847846,\n",
       "          -0.20215169, -0.15727416, -0.17214501, -0.15349694,\n",
       "           0.08912212],\n",
       "         [-0.21392134,  0.17980082, -0.21719874, -0.17372765,\n",
       "           0.15666397,  0.1070324 ,  0.11508985,  0.22131832,\n",
       "           0.21550083],\n",
       "         [-0.08337507,  0.00830168,  0.21854056,  0.10914476,\n",
       "           0.22838418,  0.17092267, -0.1739693 ,  0.14707208,\n",
       "          -0.02024183]],\n",
       "\n",
       "        [[-0.12112019, -0.02433422,  0.11785036, -0.16507035,\n",
       "          -0.02779583, -0.04996916,  0.21051882, -0.06275357,\n",
       "          -0.08092432],\n",
       "         [ 0.1483278 , -0.21228181, -0.1194185 , -0.19642548,\n",
       "          -0.19144897, -0.08742035, -0.12001871, -0.16189693,\n",
       "           0.17573538],\n",
       "         [ 0.07954235,  0.04557279, -0.10409806,  0.12876184,\n",
       "           0.20228806,  0.11061696,  0.0110139 , -0.0471589 ,\n",
       "           0.11545537]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_var_ao[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False,  True,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False,  True,\n",
       "          False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False,  True,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False,  True,\n",
       "          False]]],\n",
       "\n",
       "\n",
       "       [[[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False]]],\n",
       "\n",
       "\n",
       "       [[[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False]],\n",
       "\n",
       "        [[False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False],\n",
       "         [False, False, False, False, False, False, False, False,\n",
       "          False]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(w_var_o[0], w_var_ao[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other way to check w_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tf.gradients(loss, w_var)\n",
    "train_op2 = optimizer.apply_gradients(zip(grads, w_var))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf.initialize_all_variables().run()\n",
    "    grads_o = sess.run(grads)\n",
    "    w_var_o2 = sess.run(w_var)\n",
    "    sess.run(train_op2)\n",
    "    w_var_ao2 = sess.run(w_var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
