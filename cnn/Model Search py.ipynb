{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from genotypes import PRIMITIVES\n",
    "from genotypes import Genotype\n",
    "from operations import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedOp(Model):\n",
    "    \"\"\"Makes mixed operations object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C, stride):\n",
    "        \"\"\"Makes ops array of all the arrays\n",
    "\n",
    "        Args:\n",
    "            C (int): the current state\n",
    "        \"\"\"\n",
    "        super(MixedOp, self).__init__()\n",
    "        self._ops = []\n",
    "        for primitive in PRIMITIVES:\n",
    "                op = OPS[primitive](C, stride)\n",
    "                if 'pool' in primitive:\n",
    "                    if('avg' in primitive):\n",
    "                        op = AvgPool3x3(C, stride)\n",
    "                    elif('max' in primitive):\n",
    "                        op = MaxPool3x3(C, stride)\n",
    "                self._ops.append(op)\n",
    "        \n",
    "    def call(self, x, weights):\n",
    "        \"\"\"Converts the discrete set of operation into conitnuous mixed operation\n",
    "\n",
    "        Args:\n",
    "            x (tensor): can be tensor or array, (e.g. image-array)\n",
    "            weights (tensor): tensor or array of Softmax probability of alphas\n",
    "\n",
    "        Returns:\n",
    "            tensor: sum of product(weights, operation(x))\n",
    "        \"\"\"\n",
    "        return sum(w * op(x) for w, op in zip(weights, self._ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(Model):\n",
    "\n",
    "    def __init__(self, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev, upsample_prev):\n",
    "        super(Cell, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "        if reduction_prev:\n",
    "            self.preprocess0 = FactorizedReduce(C_prev_prev, C)\n",
    "        elif upsample_prev:\n",
    "            self.preprocess0 = FactorizedUp(C_prev_prev, C)\n",
    "        else:\n",
    "            self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 'same')\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 'same')\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "\n",
    "        self._ops = []\n",
    "        self._bns = []\n",
    "        for i in range(self._steps):\n",
    "            for j in range(2+i):\n",
    "                stride = 2 if reduction and j < 2 else 1\n",
    "                op = MixedOp(C, stride)\n",
    "                self._ops.append(op)\n",
    "\n",
    "    def call(self, s0, s1, weights):\n",
    "    \n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "\n",
    "        states = [s0, s1]\n",
    "        offset = 0\n",
    "    \n",
    "        for i in range(self._steps):\n",
    "            s = sum(self._ops[offset+j](h, weights[offset+j]) for j, h in enumerate(states))\n",
    "            offset += len(states)\n",
    "            states.append(s)\n",
    "\n",
    "        return tf.concat(states[-self._multiplier:], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleCell(Model):\n",
    "\n",
    "    def __init__(self, steps, multiplier, C_prev_prev, C_prev, C):\n",
    "        super(UpsampleCell, self).__init__()\n",
    "        self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 'same')\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 'same')\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "        self.UpConv = layers.Conv2DTranspose(C*self._multiplier, \n",
    "                                        kernel_size=3,\n",
    "                                        strides=2,\n",
    "                                        padding='same')\n",
    "        self.reduction = False\n",
    "\n",
    "    def call(self, s0, s1, weights):\n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "\n",
    "        s0 = self.UpConv(s0)\n",
    "        s1 = self.UpConv(s1)\n",
    "\n",
    "        return s0 + s1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Model):\n",
    "\n",
    "    def __init__(self, C, net_layers, criterion, steps=4, multiplier=4, stem_multiplier=3):\n",
    "        super(Network, self).__init__()\n",
    "        self._C = C\n",
    "        self._criterion = criterion\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "        self.net_layers = net_layers\n",
    "\n",
    "        C_curr = C*stem_multiplier\n",
    "\n",
    "        # stem operation\n",
    "        self.stem_op = tf.keras.Sequential()\n",
    "        self.stem_op.add(tf.keras.layers.Conv2D(\n",
    "            C_curr, kernel_size=3, padding='same', use_bias=False))\n",
    "        self.stem_op.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n",
    "        self.cells = []\n",
    "        self.skip_ops = []\n",
    "\n",
    "        reduction_prev = False\n",
    "\n",
    "        # For reduction\n",
    "        for i in range(self.net_layers):\n",
    "            if i % 2 == 1:\n",
    "                C_curr *= 2\n",
    "                reduction = True\n",
    "            else:\n",
    "                reduction = False\n",
    "                self.skip_ops += [SkipConnection(C_curr)]\n",
    "            cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr,\n",
    "                        reduction,\n",
    "                        reduction_prev,\n",
    "                        upsample_prev=False)\n",
    "            reduction_prev = reduction\n",
    "            self.cells += [cell]\n",
    "\n",
    "            C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "\n",
    "        for i in range(self.net_layers-1):\n",
    "            if i % 2 == 0:\n",
    "                C_curr = C_curr // 2\n",
    "\n",
    "                cell = UpsampleCell(steps, multiplier,\n",
    "                                    C_prev_prev, C_prev, C_curr)\n",
    "            else:\n",
    "                cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr,\n",
    "                            reduction=False,\n",
    "                            reduction_prev=False,\n",
    "                            upsample_prev=True)\n",
    "            self.cells += [cell]\n",
    "            C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "\n",
    "        self.softmaxConv = tf.keras.Sequential()\n",
    "        self.softmaxConv.add(tf.keras.layers.Conv2D(\n",
    "            1, kernel_size=1, strides=1, padding='same'))\n",
    "        self.softmaxConv.add(Softmax())\n",
    "\n",
    "        self._initialize_alphas()\n",
    "\n",
    "    def _initialize_alphas(self):\n",
    "        k = sum(1 for i in range(self._steps) for n in range(2+i))\n",
    "        num_ops = len(PRIMITIVES)\n",
    "\n",
    "        self.alphas_normal = tf.Variable(\n",
    "            1e-3*tf.random.uniform([k, num_ops]), name='alphas_normal')\n",
    "        self.alphas_reduce = tf.Variable(\n",
    "            1e-3*tf.random.uniform([k, num_ops]), name='alphas_reduce')\n",
    "        self._arch_parameters = [\n",
    "            self.alphas_normal,\n",
    "            self.alphas_reduce,\n",
    "        ]\n",
    "\n",
    "    def arch_parameters(self):\n",
    "        return self._arch_parameters\n",
    "\n",
    "    def new(self):\n",
    "        model_new = Network(self._C, self.net_layers, self._criterion)\n",
    "        for x, y in zip(model_new.arch_parameters(), self.arch_parameters()):\n",
    "            x.assign(y)\n",
    "        return model_new\n",
    "\n",
    "    def _loss(self, logits, target):\n",
    "        return self._criterion(logits, tf.to_float(target))\n",
    "\n",
    "    def call(self, inp):\n",
    "        s0 = s1 = self.stem_op(inp)\n",
    "        self.arr = []\n",
    "        ids = []\n",
    "        pos = -1\n",
    "\n",
    "        middle = self.net_layers - 1\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            if cell.reduction:\n",
    "                weights = tf.nn.softmax(self.alphas_reduce, axis=-1)\n",
    "            else:\n",
    "                weights = tf.nn.softmax(self.alphas_normal, axis=-1)\n",
    "\n",
    "            s0, s1 = s1, cell(s0, s1, weights)\n",
    "\n",
    "            if (i < middle and i % 2 == 0):\n",
    "                self.arr.append(s1)\n",
    "                ids.append(i)\n",
    "\n",
    "            if (i > middle and i % 2 == 1):\n",
    "                print(p)\n",
    "                C_curr = s1.shape[1]\n",
    "                s1 = self.skip_ops[-pos-1](self.arr[pos], s1)\n",
    "                pos -= 1\n",
    "\n",
    "        return self.softmaxConv(s1)\n",
    "\n",
    "    def genotype(self):\n",
    "\n",
    "        def _parse(weights):\n",
    "            gene = []\n",
    "            n = 2\n",
    "            start = 0\n",
    "            for i in range(self._steps):\n",
    "                end = start + n\n",
    "                W = weights[start:end].copy()\n",
    "                edges = sorted(range(i + 2), key=lambda x: -max(\n",
    "                    W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n",
    "                for j in edges:\n",
    "                    k_best = None\n",
    "                    for k in range(len(W[j])):\n",
    "                        if k != PRIMITIVES.index('none'):\n",
    "                            if k_best is None or W[j][k] > W[j][k_best]:\n",
    "                                k_best = k\n",
    "                    gene.append((PRIMITIVES[k_best], j))\n",
    "                start = end\n",
    "                n += 1\n",
    "            return gene\n",
    "\n",
    "            gene_normal = _parse(tf.nn.softmax(\n",
    "                self.alphas_normal, axis=-1).numpy())\n",
    "            gene_reduce = _parse(tf.nn.softmax(\n",
    "                self.alphas_reduce, dim=-1).numpy())\n",
    "\n",
    "            concat = range(2+self._steps-self._multiplier, self._steps+2)\n",
    "            genotype = Genotype(\n",
    "                normal=gene_normal, normal_concat=concat,\n",
    "                reduce=gene_reduce, reduce_concat=concat\n",
    "            )\n",
    "            return genotype\n",
    "\n",
    "    def get_model_thetas(self):\n",
    "        specific_tensor = []\n",
    "        specific_tensor_name = []\n",
    "        for var in self.trainable_weights:\n",
    "            if not 'alphas' in var.name:\n",
    "                specific_tensor.append(var)\n",
    "                specific_tensor_name.append(var.name)\n",
    "        return specific_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "network = Network(3, 3, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = tf.random_uniform((1, 16, 16, 3), 0, 255)\n",
    "print(network(image).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(network.skip_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws2 = network.trainable_weights\n",
    "for w in ws2:\n",
    "    if 'aphas' in w.name:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_op = MixedOp(3, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.rand(8).astype(np.float32)\n",
    "features = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "out = mix_op(features, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = Cell(steps=4,\n",
    "            multiplier=4,\n",
    "            C_prev_prev=3,\n",
    "            C_prev=3,\n",
    "            C=3,\n",
    "            reduction=False,\n",
    "            reduction_prev=False,\n",
    "            upsample_prev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.rand(20,8).astype(np.float32)\n",
    "s0 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "s1 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "cell_out = cell(s0, s1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_cell = UpsampleCell(4, 4, 3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "s1 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "up_cell_out = up_cell(s0, s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.random.rand(2, 16, 16, 6).astype(np.float32)\n",
    "conv = tf.keras.Sequential()\n",
    "conv.add(ReLUConvBN(6, 6, 1, 1, 'same'))\n",
    "conv.add(FactorizedReduce(6,6))\n",
    "conv(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.Variable([[0.9], [0.5]])\n",
    "var2 = tf.Variable([[0.9], [0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero(2).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
