{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from genotypes import PRIMITIVES\n",
    "from genotypes import Genotype\n",
    "from operations import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedOp(Model):\n",
    "    \"\"\"Makes mixed operations object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C, stride):\n",
    "        \"\"\"Makes ops array of all the arrays\n",
    "\n",
    "        Args:\n",
    "            C (int): the current state\n",
    "        \"\"\"\n",
    "        super(MixedOp, self).__init__()\n",
    "        self._ops = []\n",
    "        for primitive in PRIMITIVES:\n",
    "                op = OPS[primitive](C, stride)\n",
    "                if 'pool' in primitive:\n",
    "                    if('avg' in primitive):\n",
    "                        op = AvgPool3x3(C, stride)\n",
    "                    elif('max' in primitive):\n",
    "                        op = MaxPool3x3(C, stride)\n",
    "                self._ops.append(op)\n",
    "        \n",
    "    def call(self, x, weights):\n",
    "        \"\"\"Converts the discrete set of operation into conitnuous mixed operation\n",
    "\n",
    "        Args:\n",
    "            x (tensor): can be tensor or array, (e.g. image-array)\n",
    "            weights (tensor): tensor or array of Softmax probability of alphas\n",
    "\n",
    "        Returns:\n",
    "            tensor: sum of product(weights, operation(x))\n",
    "        \"\"\"\n",
    "        return sum(w * op(x) for w, op in zip(weights, self._ops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(Model):\n",
    "\n",
    "    def __init__(self, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev, upsample_prev):\n",
    "        super(Cell, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "        if reduction_prev:\n",
    "            self.preprocess0 = FactorizedReduce(C_prev_prev, C)\n",
    "        elif upsample_prev:\n",
    "            self.preprocess0 = FactorizedUp(C_prev_prev, C)\n",
    "        else:\n",
    "            self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 'same')\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 'same')\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "\n",
    "        self._ops = []\n",
    "        self._bns = []\n",
    "        for i in range(self._steps):\n",
    "            for j in range(2+i):\n",
    "                stride = 2 if reduction and j < 2 else 1\n",
    "                op = MixedOp(C, stride)\n",
    "                self._ops.append(op)\n",
    "\n",
    "    def call(self, s0, s1, weights):\n",
    "    \n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "\n",
    "        states = [s0, s1]\n",
    "        offset = 0\n",
    "    \n",
    "        for i in range(self._steps):\n",
    "            s = sum(self._ops[offset+j](h, weights[offset+j]) for j, h in enumerate(states))\n",
    "            offset += len(states)\n",
    "            states.append(s)\n",
    "\n",
    "        return tf.concat(states[-self._multiplier:], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleCell(Model):\n",
    "\n",
    "    def __init__(self, steps, multiplier, C_prev_prev, C_prev, C):\n",
    "        super(UpsampleCell, self).__init__()\n",
    "        self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 'same')\n",
    "        self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 'same')\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "        self.UpConv = layers.Conv2DTranspose(C*self._multiplier, \n",
    "                                        kernel_size=3,\n",
    "                                        strides=2,\n",
    "                                        padding='same')\n",
    "        self.reduction = False\n",
    "\n",
    "    def call(self, s0, s1, weights):\n",
    "        s0 = self.preprocess0(s0)\n",
    "        s1 = self.preprocess1(s1)\n",
    "\n",
    "        s0 = self.UpConv(s0)\n",
    "        s1 = self.UpConv(s1)\n",
    "\n",
    "        return s0 + s1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Model):\n",
    "\n",
    "    def __init__(self, C, net_layers, criterion, steps=4, multiplier=4, stem_multiplier=3, num_classes=1):\n",
    "        super(Network, self).__init__()\n",
    "        self._C = C\n",
    "        self._criterion = criterion\n",
    "        self._steps = steps\n",
    "        self._multiplier = multiplier\n",
    "        self.net_layers = net_layers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        C_curr = C*stem_multiplier\n",
    "\n",
    "        # stem operation\n",
    "        self.stem_op = tf.keras.Sequential()\n",
    "        self.stem_op.add(tf.keras.layers.Conv2D(\n",
    "            C_curr, kernel_size=3, padding='same', use_bias=False))\n",
    "        self.stem_op.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n",
    "        self.cells = []\n",
    "        self.skip_ops = []\n",
    "\n",
    "        reduction_prev = False\n",
    "\n",
    "        # For reduction\n",
    "        for i in range(self.net_layers):\n",
    "            if i % 2 == 1:\n",
    "                C_curr *= 2\n",
    "                reduction = True\n",
    "            else:\n",
    "                reduction = False\n",
    "                self.skip_ops += [SkipConnection(C_curr)]\n",
    "            cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr,\n",
    "                        reduction,\n",
    "                        reduction_prev,\n",
    "                        upsample_prev=False)\n",
    "            reduction_prev = reduction\n",
    "            self.cells += [cell]\n",
    "\n",
    "            C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "\n",
    "        for i in range(self.net_layers-1):\n",
    "            if i % 2 == 0:\n",
    "                C_curr = C_curr // 2\n",
    "\n",
    "                cell = UpsampleCell(steps, multiplier,\n",
    "                                    C_prev_prev, C_prev, C_curr)\n",
    "            else:\n",
    "                cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr,\n",
    "                            reduction=False,\n",
    "                            reduction_prev=False,\n",
    "                            upsample_prev=True)\n",
    "            self.cells += [cell]\n",
    "            C_prev_prev, C_prev = C_prev, multiplier*C_curr\n",
    "        \n",
    "        self.softmaxConv = tf.keras.Sequential(name=\"softmaxConv\")\n",
    "        self.softmaxConv.add(tf.keras.layers.Conv2D(\n",
    "            self.num_classes, kernel_size=1, strides=1, padding='same'))\n",
    "        self.softmaxConv.add(Softmax())\n",
    "\n",
    "        self._initialize_alphas()\n",
    "\n",
    "    def _initialize_alphas(self):\n",
    "        k = sum(1 for i in range(self._steps) for n in range(2+i))\n",
    "        num_ops = len(PRIMITIVES)\n",
    "        alphas_normal = lambda: 1e-3*tf.random.uniform([k, num_ops])\n",
    "        alphas_reduce = lambda: 1e-3*tf.random.uniform([k, num_ops])\n",
    "        self.alphas_normal = tf.Variable(\n",
    "            alphas_normal, name='alphas_normal')\n",
    "        self.alphas_reduce = tf.Variable(\n",
    "            alphas_reduce, name='alphas_reduce')\n",
    "        self._arch_parameters = [\n",
    "            self.alphas_normal,\n",
    "            self.alphas_reduce,\n",
    "        ]\n",
    "\n",
    "    def arch_parameters(self):\n",
    "        return self._arch_parameters\n",
    "\n",
    "    def new(self):\n",
    "        model_new = Network(self._C, self.net_layers, self._criterion, num_classes=self.num_classes)\n",
    "        for x, y in zip(model_new.arch_parameters(), self.arch_parameters()):\n",
    "            x.assign(y)\n",
    "        return model_new\n",
    "\n",
    "    def _loss(self, logits, target):\n",
    "        b, w, h, c = target.shape\n",
    "        y = tf.reshape(tf.cast(target, tf.int64), (b, w, h))\n",
    "        y = tf.one_hot(y, self.num_classes, on_value=1.0, off_value=0.0)\n",
    "        return self._criterion(y, logits)\n",
    "\n",
    "    def call(self, inp):\n",
    "        s0 = s1 = self.stem_op(inp)\n",
    "        self.arr = []\n",
    "        ids = []\n",
    "        pos = -1\n",
    "\n",
    "        middle = self.net_layers - 1\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            if cell.reduction:\n",
    "                weights = tf.nn.softmax(self.alphas_reduce, axis=-1)\n",
    "            else:\n",
    "                weights = tf.nn.softmax(self.alphas_normal, axis=-1)\n",
    "\n",
    "            s0, s1 = s1, cell(s0, s1, weights)\n",
    "\n",
    "            if (i < middle and i % 2 == 0):\n",
    "                self.arr.append(s1)\n",
    "                ids.append(i)\n",
    "\n",
    "            if (i > middle and i % 2 == 1):\n",
    "                C_curr = s1.shape[1]\n",
    "                s1 = self.skip_ops[-pos-1](self.arr[pos], s1)\n",
    "                pos -= 1\n",
    "        return self.softmaxConv(s1)\n",
    "    \n",
    "    def genotype(self, alphas_normal, alphas_reduce):\n",
    "            def _parse(weights):\n",
    "                gene = []\n",
    "                n = 2\n",
    "                start = 0\n",
    "                for i in range(self._steps):\n",
    "                    end = start + n\n",
    "                    W = weights[start:end].copy()\n",
    "                    edges = sorted(range(i + 2), key=lambda x: -max(W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n",
    "                    for j in edges:\n",
    "                        k_best = None\n",
    "                        for k in range(len(W[j])):\n",
    "                            if k != PRIMITIVES.index('none'):\n",
    "                                if k_best is None or W[j][k] > W[j][k_best]:\n",
    "                                    k_best = k\n",
    "                        gene.append((PRIMITIVES[k_best], j))\n",
    "                    start = end\n",
    "                    n += 1\n",
    "                return gene\n",
    "\n",
    "            gene_normal = _parse(alphas_normal)\n",
    "            gene_reduce = _parse(alphas_reduce)\n",
    "\n",
    "            concat = range(2+self._steps-self._multiplier, self._steps+2)\n",
    "            genotype = Genotype(\n",
    "              normal=gene_normal, normal_concat=concat,\n",
    "              reduce=gene_reduce, reduce_concat=concat\n",
    "            )\n",
    "            return genotype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From operations.py:290: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:7: The name tf.layers.MaxPooling2D is deprecated. Please use tf.compat.v1.layers.MaxPooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:6: The name tf.layers.AveragePooling2D is deprecated. Please use tf.compat.v1.layers.AveragePooling2D instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "network = Network(3, 3, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ds_train = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "np_ds_valid = (np.random.randint(0, 256, (20, 16, 16, 3)).astype(np.float32), np.random.randint(0, 2, (20, 16, 16, 1)).astype(np.float32))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(2)\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices(np_ds_valid).batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-adb2eb3d3a42>:1: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "it = ds_train.make_one_shot_iterator()\n",
    "image, label = it.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [2,16,16,3] vs. [2,14,14,3] [Op:AddV2] name: network/cell/mixed_op/add/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-79fba251ddd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    897\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b0bf393e3dc5>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmiddle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    897\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aca6ef9169d7>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, s0, s1, weights)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-aca6ef9169d7>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((j, h))\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    897\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6a54af036ce9>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, weights)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m \u001b[0mof\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    544\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001b[0;32m/home/pankajb_sac_isro_gov_in/.local/lib/python2.7/site-packages/six.pyc\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,16,16,3] vs. [2,14,14,3] [Op:AddV2] name: network/cell/mixed_op/add/"
     ]
    }
   ],
   "source": [
    "print(network(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws2 = network.trainable_weights\n",
    "for w in ws2:\n",
    "    if 'aphas' in w.name:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From operations.py:7: The name tf.layers.MaxPooling2D is deprecated. Please use tf.compat.v1.layers.MaxPooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:6: The name tf.layers.AveragePooling2D is deprecated. Please use tf.compat.v1.layers.AveragePooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:130: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mix_op = MixedOp(3, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.rand(8).astype(np.float32)\n",
    "features = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "out = mix_op(features, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84, shape=(2, 16, 16, 3), dtype=float32, numpy=\n",
       "array([[[[0.32285148, 0.54710644, 1.1514405 ],\n",
       "         [0.42422813, 0.96005946, 1.0759336 ],\n",
       "         [0.14072308, 0.90018857, 1.2677069 ],\n",
       "         ...,\n",
       "         [0.933166  , 0.4263308 , 0.95550275],\n",
       "         [0.8583072 , 0.66756475, 1.0592568 ],\n",
       "         [0.72377366, 0.19719526, 1.0426829 ]],\n",
       "\n",
       "        [[0.8192141 , 1.1413007 , 0.9077792 ],\n",
       "         [0.6702423 , 1.250958  , 1.1351435 ],\n",
       "         [0.5356897 , 1.5157348 , 1.1250756 ],\n",
       "         ...,\n",
       "         [0.9008583 , 0.94851655, 1.0374324 ],\n",
       "         [0.8049585 , 1.091066  , 1.0919341 ],\n",
       "         [0.13932484, 0.6754265 , 1.5323551 ]],\n",
       "\n",
       "        [[0.78010374, 1.1057564 , 1.0542378 ],\n",
       "         [0.5173835 , 1.2058035 , 1.2370738 ],\n",
       "         [0.5772717 , 1.1649121 , 1.0180331 ],\n",
       "         ...,\n",
       "         [0.78804624, 1.1538341 , 1.1642927 ],\n",
       "         [0.686646  , 1.0289286 , 1.2927196 ],\n",
       "         [0.15988475, 0.686424  , 1.5292027 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.1126094 , 0.75892   , 0.575436  ],\n",
       "         [0.8358707 , 1.0210688 , 0.9991754 ],\n",
       "         [0.94133735, 1.2478848 , 0.9387843 ],\n",
       "         ...,\n",
       "         [0.65396893, 1.4545286 , 1.0330994 ],\n",
       "         [1.0309386 , 1.5120275 , 0.79059774],\n",
       "         [0.8786725 , 0.85305977, 0.84070116]],\n",
       "\n",
       "        [[0.96376693, 0.82327586, 0.66350895],\n",
       "         [0.5943178 , 1.2538247 , 1.1964798 ],\n",
       "         [0.37251574, 1.3930328 , 1.2886419 ],\n",
       "         ...,\n",
       "         [0.08283585, 2.0127792 , 1.6115998 ],\n",
       "         [0.08482075, 1.6294601 , 1.605371  ],\n",
       "         [0.48467255, 1.186604  , 1.4062909 ]],\n",
       "\n",
       "        [[1.0977293 , 0.8094647 , 0.56778073],\n",
       "         [1.0458442 , 0.8558529 , 0.877506  ],\n",
       "         [0.8586851 , 0.9115287 , 0.9359598 ],\n",
       "         ...,\n",
       "         [0.7949554 , 1.1282885 , 1.2143127 ],\n",
       "         [0.7915918 , 1.1424779 , 1.038937  ],\n",
       "         [0.85476947, 0.8767674 , 1.0294676 ]]],\n",
       "\n",
       "\n",
       "       [[[0.47842416, 1.0078427 , 1.1376781 ],\n",
       "         [0.63559175, 1.3240975 , 1.2192318 ],\n",
       "         [0.42877424, 1.2827879 , 1.1288124 ],\n",
       "         ...,\n",
       "         [0.568672  , 1.2918262 , 1.3743018 ],\n",
       "         [0.20719123, 0.9745621 , 1.4399204 ],\n",
       "         [0.38047302, 0.7755836 , 1.2727714 ]],\n",
       "\n",
       "        [[1.0479605 , 1.0107046 , 0.90332943],\n",
       "         [0.86594874, 1.0377157 , 1.1110247 ],\n",
       "         [0.81936526, 1.2033412 , 0.8949532 ],\n",
       "         ...,\n",
       "         [0.431982  , 1.1770843 , 1.21544   ],\n",
       "         [0.40403795, 1.1951935 , 1.289372  ],\n",
       "         [0.42262098, 0.9911303 , 1.2463598 ]],\n",
       "\n",
       "        [[0.9152578 , 1.0206959 , 1.0054836 ],\n",
       "         [0.944427  , 1.2194743 , 1.0179764 ],\n",
       "         [0.9699523 , 1.4267061 , 0.7754648 ],\n",
       "         ...,\n",
       "         [0.7075382 , 1.3480262 , 0.97636926],\n",
       "         [0.8793549 , 1.4327319 , 0.87871   ],\n",
       "         [0.53574896, 1.2250986 , 1.1154478 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.1958036 , 0.877091  , 0.70417076],\n",
       "         [0.92212343, 0.9638002 , 0.8553166 ],\n",
       "         [0.90762365, 1.0988519 , 0.9673856 ],\n",
       "         ...,\n",
       "         [0.6315272 , 1.6796834 , 1.0629458 ],\n",
       "         [0.55329716, 1.5562932 , 1.2592136 ],\n",
       "         [0.6137829 , 1.3361602 , 1.1900078 ]],\n",
       "\n",
       "        [[0.75376344, 1.0294118 , 1.063257  ],\n",
       "         [0.3306839 , 1.4433641 , 1.4410578 ],\n",
       "         [0.27500284, 1.5459025 , 1.4599806 ],\n",
       "         ...,\n",
       "         [0.15638685, 1.3542215 , 1.3867718 ],\n",
       "         [0.43772388, 1.0483679 , 1.0389813 ],\n",
       "         [0.40101612, 0.9670886 , 1.2207501 ]],\n",
       "\n",
       "        [[0.9834427 , 1.13696   , 0.97803867],\n",
       "         [0.9903933 , 1.0105847 , 0.9248635 ],\n",
       "         [0.7965536 , 1.1387165 , 1.092029  ],\n",
       "         ...,\n",
       "         [0.74603844, 1.2729694 , 0.9398918 ],\n",
       "         [0.7678344 , 1.4108233 , 0.83130264],\n",
       "         [0.92216736, 1.1149929 , 0.7898721 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = Cell(steps=4,\n",
    "            multiplier=4,\n",
    "            C_prev_prev=3,\n",
    "            C_prev=3,\n",
    "            C=3,\n",
    "            reduction=False,\n",
    "            reduction_prev=False,\n",
    "            upsample_prev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.rand(20,8).astype(np.float32)\n",
    "s0 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "s1 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "cell_out = cell(s0, s1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_cell = UpsampleCell(4, 4, 3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "s1 = np.random.rand(2, 16, 16, 3).astype(np.float32)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "up_cell_out = up_cell(s0, s1, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.random.rand(2, 16, 16, 6).astype(np.float32)\n",
    "conv = tf.keras.Sequential()\n",
    "conv.add(ReLUConvBN(6, 6, 1, 1, 'same'))\n",
    "conv.add(FactorizedReduce(6,6))\n",
    "conv(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.Variable([[0.9], [0.5]])\n",
    "var2 = tf.Variable([[0.9], [0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero(2).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
