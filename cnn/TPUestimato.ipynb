{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from model_search import Network\n",
    "from architect_graph import Architect\n",
    "\n",
    "import time\n",
    "from genotypes import PRIMITIVES\n",
    "from genotypes import Genotype\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from genotypes import Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"arch_learning_rate\": 3e-1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"grad_clip\": 5,\n",
    "    \"learning_rate\": 0.025,\n",
    "    \"learning_rate_decay\": 0.97,\n",
    "    \"learning_rate_min\": 0.0001,\n",
    "    \"num_batches_per_epoch\": 2000,\n",
    "    \n",
    "    \"unrolled\": True,\n",
    "    \"epochs\": 10,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"save\": \"EXP\",\n",
    "    \"init_channels\": 3,\n",
    "    \"num_layers\": 3,\n",
    "    \"num_classes\": 6,\n",
    "    \"crop_size\": [8, 8],\n",
    "    \"save_checkpoints_steps\": 100,\n",
    "    \"model_dir\": 'gs://unet-darts/train-search-ckptss',\n",
    "    \"max_steps\": 10000,\n",
    "    # NEW\n",
    "    \"steps_per_eval\": 2,\n",
    "    \"num_train_examples\": 16,\n",
    "    #\n",
    "    \n",
    "    \"use_tpu\": True,\n",
    "    \"use_host_call\": True,\n",
    "    \"tpu\": 'unet-darts',\n",
    "    \"zone\": 'us-central1-f',\n",
    "    \"project\": \"isro-nas\"\n",
    "}\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = Struct(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inp_fn(filename, mode, batch_size):\n",
    "    \n",
    "    def _input_fn(params):\n",
    "        image_dataset = tf.data.TFRecordDataset(filename)\n",
    "        W, H = args.crop_size[0], args.crop_size[1]\n",
    "\n",
    "        # Create a dictionary describing the features.  \n",
    "        image_feature_description = {\n",
    "            'train_name': tf.FixedLenFeature([], tf.string),  \n",
    "            'train_x': tf.FixedLenFeature([], tf.string),\n",
    "            'train_y': tf.FixedLenFeature([], tf.string),\n",
    "            'valid_name': tf.FixedLenFeature([], tf.string),  \n",
    "            'valid_x': tf.FixedLenFeature([], tf.string),\n",
    "            'valid_y': tf.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "        def _parse_image_function(example_proto):\n",
    "            # Parse the input tf.Example proto using the dictionary above.\n",
    "            feature= tf.parse_single_example(example_proto, image_feature_description)\n",
    "            train_x = feature['train_x']\n",
    "            train_y = feature['train_y']\n",
    "            valid_x = feature['valid_x']\n",
    "            valid_y = feature['valid_y']\n",
    "            train_name = feature['train_name']\n",
    "            valid_name = feature['valid_name']\n",
    "\n",
    "            train_x = tf.image.decode_png(train_x, channels=3)\n",
    "            train_y = tf.image.decode_png(train_y, channels=3)\n",
    "            valid_x = tf.image.decode_png(valid_x, channels=3)\n",
    "            valid_y = tf.image.decode_png(valid_y, channels=3)\n",
    "            \n",
    "            \n",
    "            train_x = tf.cast(train_x, tf.float32)\n",
    "            train_x = tf.image.resize(train_x, (W, H))\n",
    "            train_y = tf.cast(train_y, tf.float32)\n",
    "            train_y = tf.image.resize(train_y, (W, H))\n",
    "            valid_x = tf.cast(valid_x, tf.float32)\n",
    "            valid_x = tf.image.resize(valid_x, (W, H))\n",
    "            valid_y = tf.cast(valid_y, tf.float32)\n",
    "            valid_y = tf.image.resize(valid_y, (W, H))\n",
    "            \n",
    "            train_y = train_y[:, :, 0]\n",
    "            train_y = tf.expand_dims(train_y, axis=-1)\n",
    "            \n",
    "            valid_y = valid_y[:, :, 0]\n",
    "            valid_y = tf.expand_dims(valid_y, axis=-1)\n",
    "            \n",
    "            return ((train_x, valid_x), (train_y, valid_y))\n",
    "\n",
    "        dataset = image_dataset.map(_parse_image_function)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size,  drop_remainder=True)\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# mkdir ../../datasets/train_search\n",
    "# rm ../../datasets/train_search/*.tfrecords\n",
    "# gsutil cp -r gs://unet-darts/datasets/train-search/*.tfrecords ../../datasets/train_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inp_fn2(filename, mode, batch_size):\n",
    "    \n",
    "    def _input_fn(params):\n",
    "        W, H = args.crop_size[0], args.crop_size[1]\n",
    "        NUM_IMAGES = 20\n",
    "        x_train = np.random.randint(0, 256, (NUM_IMAGES, W, H, 3)).astype(np.float32)\n",
    "        y_train = np.random.randint(0, args.num_classes, (NUM_IMAGES, W, H, 1)).astype(np.float32)\n",
    "        x_valid = np.random.randint(0, 256, (NUM_IMAGES, W, H, 3)).astype(np.float32)\n",
    "        y_valid = np.random.randint(0, args.num_classes, (NUM_IMAGES, W, H, 1)).astype(np.float32)\n",
    "\n",
    "        ds = (x_train, x_valid), (y_train, y_valid)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ds)\n",
    "        num_epochs = None # indefinitely\n",
    "        dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size, drop_remainder=True)\n",
    "        return dataset\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneSaver(tf.estimator.SessionRunHook):\n",
    "    def __init__(self, model, alphas_normal, alphas_reduce):\n",
    "        self.model = model\n",
    "        self.alphas_normal = alphas_normal\n",
    "        self.alphas_reduce = alphas_reduce\n",
    "    \n",
    "    def begin(self):\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        \n",
    "    def end(self, session):\n",
    "        alphas_normal, alphas_reduce = session.run([self.alphas_normal, self.alphas_reduce])\n",
    "        alphas_normal = softmax(alphas_normal)\n",
    "        alphas_reduce = softmax(alphas_reduce)\n",
    "        \n",
    "        genotype = self.model.genotype(alphas_normal, alphas_reduce)        \n",
    "        self.global_step = session.run(self.global_step)\n",
    "        \n",
    "        filename = 'final_genotype.{}'.format((self.global_step))\n",
    "        tf.logging.info(\"Saving Genotype for step: {}\".format(str(self.global_step)))\n",
    "        utils.write_genotype(genotype, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    criterion = tf.losses.softmax_cross_entropy\n",
    "    model = Network(C=args.init_channels, net_layers=args.num_layers, criterion=criterion, num_classes=args.num_classes)\n",
    "    global_step = tf.train.get_global_step()\n",
    "    learning_rate_min = tf.constant(args.learning_rate_min)\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        args.learning_rate,\n",
    "        global_step,\n",
    "        decay_rate=args.learning_rate_decay,\n",
    "        decay_steps=args.num_batches_per_epoch,\n",
    "        staircase=True,\n",
    "    )\n",
    "    \n",
    "    lr = tf.maximum(learning_rate, learning_rate_min)\n",
    "    \n",
    "    optimizer = tf.train.MomentumOptimizer(lr, args.momentum)\n",
    "    criterion = tf.losses.softmax_cross_entropy\n",
    "    \n",
    "    if(args.use_tpu):\n",
    "        optimizer = tf.tpu.CrossShardOptimizer(optimizer)\n",
    "        \n",
    "    eval_hooks = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    prediction_dict = None\n",
    "    export_outputs = None\n",
    "    host_call = None\n",
    "    # 2. Loss function, training/eval ops\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        (x_train, x_valid) = features\n",
    "        (y_train, y_valid) = labels\n",
    "\n",
    "        preds = model(x_train)\n",
    "        architect = Architect(model, args)\n",
    "        # architect step\n",
    "        architect_step = architect.step(input_train=x_train,\n",
    "                                        target_train=y_train,\n",
    "                                        input_valid=x_valid,\n",
    "                                        target_valid=y_valid,\n",
    "                                        unrolled=args.unrolled,\n",
    "                                        )\n",
    "\n",
    "\n",
    "        w_var = model.get_thetas()\n",
    "        loss = model._loss(preds, y_train)\n",
    "        grads = tf.gradients(loss, w_var)\n",
    "        clipped_gradients, norm = tf.clip_by_global_norm(grads, args.grad_clip)\n",
    "        train_op = optimizer.apply_gradients(zip(clipped_gradients, w_var), global_step=tf.train.get_global_step())\n",
    "        \n",
    "        b, w, h, c = y_train.shape\n",
    "        y = tf.reshape(tf.cast(y_train, tf.int64), (b, w, h))\n",
    "        y = tf.one_hot(y, args.num_classes, on_value=1.0, off_value=0.0)\n",
    "        \n",
    "        if args.use_host_call:\n",
    "            def host_call_fn(global_step, learning_rate, loss, y, preds):\n",
    "                # Outfeed supports int32 but global_step is expected to be int64.\n",
    "                print(loss)\n",
    "                global_step = tf.reduce_mean(global_step)\n",
    "                global_step = tf.cast(global_step, tf.int64)\n",
    "                miou, conf_mat = tf.metrics.mean_iou(\n",
    "                    labels=y,\n",
    "                    predictions=tf.round(preds),\n",
    "                    num_classes=args.num_classes)\n",
    "                \n",
    "                acc = tf.metrics.accuracy(labels=y, \n",
    "                                              predictions=tf.round(preds))\n",
    "                with (tf.contrib.summary.create_file_writer(args.model_dir).as_default()):\n",
    "                    with tf.contrib.summary.always_record_summaries():\n",
    "                        tf.contrib.summary.scalar(\n",
    "                            'learning_rate', tf.reduce_mean(learning_rate),\n",
    "                            step=global_step)\n",
    "                        tf.contrib.summary.scalar(\n",
    "                            'loss', tf.reduce_mean(loss),step=global_step)\n",
    "                        tf.contrib.summary.scalar(\n",
    "                            'acc', acc,step=global_step)\n",
    "                        tf.contrib.summary.scalar(\n",
    "                            'miou', miou, step=global_step)\n",
    "                return tf.contrib.summary.all_summary_ops()\n",
    "\n",
    "            global_step_t = tf.reshape(global_step, [1])\n",
    "            learning_rate_t = tf.reshape(learning_rate, [1])\n",
    "            loss_t = tf.reshape(loss, [1])\n",
    "            host_call = (host_call_fn,\n",
    "                           [global_step_t, learning_rate_t, loss_t, y, preds])\n",
    "\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        alphas_normal = model.arch_parameters()[0]\n",
    "        alphas_reduce = model.arch_parameters()[1]\n",
    "        gene_saver = GeneSaver(model, alphas_normal, alphas_reduce)\n",
    "        eval_hooks = [gene_saver]\n",
    "        \n",
    "        (x_train, x_valid) = features\n",
    "        (y_train, y_valid) = labels\n",
    "        preds = model(x_valid)\n",
    "        loss = model._loss(preds, y_valid)\n",
    "        \n",
    "        b, w, h, c = y_valid.shape\n",
    "        y = tf.reshape(tf.cast(y_valid, tf.int64), (b, w, h))\n",
    "        y = tf.one_hot(y, args.num_classes, on_value=1.0, off_value=0.0)\n",
    "        \n",
    "        metric_fn = lambda y, preds: {\n",
    "            'miou': tf.metrics.mean_iou(\n",
    "                    labels=y,\n",
    "                    predictions=tf.round(preds),\n",
    "                    num_classes=args.num_classes\n",
    "                ),\n",
    "        \n",
    "            'acc': tf.metrics.accuracy(labels=y, \n",
    "                                      predictions=tf.round(preds)),\n",
    "#             'loss': loss\n",
    "        }\n",
    "        eval_metric_ops = (metric_fn, [y, preds])\n",
    "        \n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        x = features\n",
    "        y = labels\n",
    "        preds = model(x)\n",
    "        prediction_dict = {\"predictions\": preds}\n",
    "        export_outputs = {\"predict_export_outputs\": tf.estimator.export.PredictOutput(outputs = preds)}\n",
    "    \n",
    "    # 5. Return EstimatorSpec\n",
    "    return tf.estimator.tpu.TPUEstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = prediction_dict,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metrics = eval_metric_ops,\n",
    "        export_outputs = export_outputs,\n",
    "        evaluation_hooks=eval_hooks,\n",
    "        host_call=host_call\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions to read in respective datasets\n",
    "def get_train():\n",
    "    return make_inp_fn2(filename = tf.gfile.Glob('../../datasets/train_search/train-search-*-00008.tfrecords'),\n",
    "                        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "                        batch_size = args.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create serving input function\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "      IMAGE_LOC: tf.placeholder(tf.float32, [None])\n",
    "    }\n",
    "    \n",
    "    feature_placeholders['IMAGES'] = tf.placeholder(tf.float32, [None, args.crop_size[0], args.crop_size[1], args.init_channels])\n",
    "    \n",
    "    features = {\n",
    "    key: tf.expand_dims(tensor, -1)\n",
    "    for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "      tpu=args.tpu,\n",
    "      zone=args.zone,\n",
    "      project=args.project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.estimator.tpu.RunConfig(\n",
    "      cluster=tpu_cluster_resolver,\n",
    "      model_dir=args.model_dir,\n",
    "      save_checkpoints_steps=args.save_checkpoints_steps,\n",
    "      tpu_config=tf.contrib.tpu.TPUConfig(num_shards=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "cluster_def {\n",
      "  job {\n",
      "    name: \"worker\"\n",
      "    tasks {\n",
      "      key: 0\n",
      "      value: \"10.240.1.18:8470\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2e8d29c5d0>, '_model_dir': 'gs://unet-darts/train-search-ckptss', '_protocol': None, '_save_checkpoints_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_session_creation_timeout_secs': 7200, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f2e8d319fd0>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_experimental_max_worker_delay_secs': None, '_evaluation_master': u'grpc://10.240.1.18:8470', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': u'grpc://10.240.1.18:8470'}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "INFO:tensorflow:Querying Tensorflow master (grpc://10.240.1.18:8470) for TPU system metadata.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11183773590916195805)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5961164671056845700)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6457306311337005987)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4459697946670094731)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14908122987920093202)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10753415780127312604)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 15568337349046208395)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1524341935926109007)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13316842258816907255)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 13650408446542780439)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2280584580084243208)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-29T17:51:18Z\n",
      "INFO:tensorflow:TPU job name worker\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://unet-darts/train-search-ckptss/model.ckpt-3\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:802: load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "INFO:tensorflow:Init TPU system\n",
      "INFO:tensorflow:Initialized TPU in 8 seconds\n",
      "INFO:tensorflow:Starting infeed thread controller.\n",
      "INFO:tensorflow:Starting outfeed thread controller.\n",
      "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
      "WARNING:tensorflow:TPUPollingThread found TPU unet-darts in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Stop infeed thread controller\n",
      "INFO:tensorflow:Shutting down InfeedController thread.\n",
      "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Infeed thread finished, shutting down.\n",
      "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
      "INFO:tensorflow:infeed marked as finished\n",
      "INFO:tensorflow:Stop output thread controller\n",
      "INFO:tensorflow:Shutting down OutfeedController thread.\n",
      "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
      "INFO:tensorflow:outfeed marked as finished\n",
      "INFO:tensorflow:Shutdown TPU system.\n",
      "INFO:tensorflow:Saving Genotype for step: 3\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-29-17:52:03\n",
      "INFO:tensorflow:Saving dict for global step 3: acc = 0.71809894, global_step = 3, loss = 1.8874016, miou = 0.39712805\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3: gs://unet-darts/train-search-ckptss/model.ckpt-3\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.71809894, 'global_step': 3, 'loss': 1.8874016, 'miou': 0.39712805}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.tpu.TPUEstimator(\n",
    "    use_tpu=args.use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=config,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    eval_batch_size=args.eval_batch_size,\n",
    "    params=vars(args)\n",
    ")\n",
    "estimator.evaluate(input_fn = get_train(), steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn=get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training for 10000 steps. Current step 78.\n",
      "INFO:tensorflow:Querying Tensorflow master (grpc://10.240.1.18:8470) for TPU system metadata.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11183773590916195805)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5961164671056845700)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6457306311337005987)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4459697946670094731)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14908122987920093202)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10753415780127312604)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 15568337349046208395)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1524341935926109007)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13316842258816907255)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 13650408446542780439)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2280584580084243208)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:TPU job name worker\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://unet-darts/train-search-ckptss/model.ckpt-78\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 78 into gs://unet-darts/train-search-ckptss/model.ckpt.\n",
      "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
      "INFO:tensorflow:Installing graceful shutdown hook.\n",
      "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
      "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
      "\n",
      "INFO:tensorflow:Init TPU system\n",
      "INFO:tensorflow:Initialized TPU in 7 seconds\n",
      "INFO:tensorflow:Starting infeed thread controller.\n",
      "INFO:tensorflow:Starting outfeed thread controller.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU unet-darts in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Enqueue next (2) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
      "INFO:tensorflow:loss = 1.9186516, step = 80\n",
      "INFO:tensorflow:Saving checkpoints for 80 into gs://unet-darts/train-search-ckptss/model.ckpt.\n",
      "INFO:tensorflow:Stop infeed thread controller\n",
      "INFO:tensorflow:Shutting down InfeedController thread.\n",
      "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Infeed thread finished, shutting down.\n",
      "INFO:tensorflow:infeed marked as finished\n",
      "INFO:tensorflow:Stop output thread controller\n",
      "INFO:tensorflow:Shutting down OutfeedController thread.\n",
      "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
      "INFO:tensorflow:outfeed marked as finished\n",
      "INFO:tensorflow:Shutdown TPU system.\n",
      "INFO:tensorflow:Loss for final step: 1.9186516.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "INFO:tensorflow:Finished training up to step 80. Elapsed seconds 167.\n",
      "INFO:tensorflow:Starting to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-29T13:31:55Z\n",
      "INFO:tensorflow:TPU job name worker\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://unet-darts/train-search-ckptss/model.ckpt-80\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Init TPU system\n",
      "INFO:tensorflow:Initialized TPU in 11 seconds\n",
      "INFO:tensorflow:Starting infeed thread controller.\n",
      "INFO:tensorflow:Starting outfeed thread controller.\n",
      "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
      "WARNING:tensorflow:TPUPollingThread found TPU unet-darts in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Enqueue next (2) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Evaluation [2/2]\n",
      "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
      "INFO:tensorflow:Stop infeed thread controller\n",
      "INFO:tensorflow:Shutting down InfeedController thread.\n",
      "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Infeed thread finished, shutting down.\n",
      "INFO:tensorflow:infeed marked as finished\n",
      "INFO:tensorflow:Stop output thread controller\n",
      "INFO:tensorflow:Shutting down OutfeedController thread.\n",
      "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
      "INFO:tensorflow:outfeed marked as finished\n",
      "INFO:tensorflow:Shutdown TPU system.\n",
      "INFO:tensorflow:Saving Genotype for step: 80\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-29-13:32:43\n",
      "INFO:tensorflow:Saving dict for global step 80: acc = 0.7246094, global_step = 80, loss = 1.8561516, miou = 0.40579003\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 80: gs://unet-darts/train-search-ckptss/model.ckpt-80\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:Eval results: {'acc': 0.7246094, 'loss': 1.8561516, 'global_step': 80, 'miou': 0.40579003}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception KeyboardInterrupt in <bound method ScopedTFGraph.__del__ of <tensorflow.python.framework.c_api_util.ScopedTFGraph object at 0x7f34e4bb4510>> ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:TPU job name worker\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://unet-darts/train-search-ckptss/model.ckpt-80\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 80 into gs://unet-darts/train-search-ckptss/model.ckpt.\n",
      "INFO:tensorflow:Initialized dataset iterators in 1 seconds\n",
      "INFO:tensorflow:Installing graceful shutdown hook.\n",
      "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
      "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
      "\n",
      "INFO:tensorflow:Init TPU system\n",
      "INFO:tensorflow:Initialized TPU in 7 seconds\n",
      "INFO:tensorflow:Starting infeed thread controller.\n",
      "INFO:tensorflow:Starting outfeed thread controller.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU unet-darts in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Enqueue next (2) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
      "INFO:tensorflow:loss = 1.9186516, step = 82\n",
      "INFO:tensorflow:Saving checkpoints for 82 into gs://unet-darts/train-search-ckptss/model.ckpt.\n",
      "INFO:tensorflow:Stop infeed thread controller\n",
      "INFO:tensorflow:Shutting down InfeedController thread.\n",
      "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Infeed thread finished, shutting down.\n",
      "INFO:tensorflow:infeed marked as finished\n",
      "INFO:tensorflow:Stop output thread controller\n",
      "INFO:tensorflow:Shutting down OutfeedController thread.\n",
      "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
      "INFO:tensorflow:outfeed marked as finished\n",
      "INFO:tensorflow:Shutdown TPU system.\n",
      "INFO:tensorflow:Loss for final step: 1.9186516.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "INFO:tensorflow:Finished training up to step 82. Elapsed seconds 395.\n",
      "INFO:tensorflow:Starting to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-29T13:35:43Z\n",
      "INFO:tensorflow:TPU job name worker\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://unet-darts/train-search-ckptss/model.ckpt-82\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Init TPU system\n",
      "INFO:tensorflow:Initialized TPU in 10 seconds\n",
      "INFO:tensorflow:Starting infeed thread controller.\n",
      "INFO:tensorflow:Starting outfeed thread controller.\n",
      "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
      "WARNING:tensorflow:TPUPollingThread found TPU unet-darts in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Enqueue next (2) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Evaluation [2/2]\n",
      "INFO:tensorflow:Stop infeed thread controller\n",
      "INFO:tensorflow:Shutting down InfeedController thread.\n",
      "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
      "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Infeed thread finished, shutting down.\n",
      "INFO:tensorflow:infeed marked as finished\n",
      "INFO:tensorflow:Stop output thread controller\n",
      "INFO:tensorflow:Shutting down OutfeedController thread.\n",
      "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
      "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
      "INFO:tensorflow:outfeed marked as finished\n",
      "INFO:tensorflow:Shutdown TPU system.\n",
      "INFO:tensorflow:Saving Genotype for step: 82\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-29-13:36:31\n",
      "INFO:tensorflow:Saving dict for global step 82: acc = 0.7246094, global_step = 82, loss = 1.8327141, miou = 0.40579003\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 82: gs://unet-darts/train-search-ckptss/model.ckpt-82\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:Eval results: {'acc': 0.7246094, 'loss': 1.8327141, 'global_step': 82, 'miou': 0.40579003}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:TPU job name worker\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://unet-darts/train-search-ckptss/model.ckpt-82\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 82 into gs://unet-darts/train-search-ckptss/model.ckpt.\n",
      "INFO:tensorflow:Initialized dataset iterators in 1 seconds\n",
      "INFO:tensorflow:Installing graceful shutdown hook.\n",
      "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
      "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
      "\n",
      "INFO:tensorflow:Init TPU system\n",
      "INFO:tensorflow:Initialized TPU in 7 seconds\n",
      "INFO:tensorflow:Starting infeed thread controller.\n",
      "INFO:tensorflow:Starting outfeed thread controller.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU unet-darts in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Enqueue next (2) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
      "INFO:tensorflow:loss = 1.9186516, step = 84\n",
      "INFO:tensorflow:Saving checkpoints for 84 into gs://unet-darts/train-search-ckptss/model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "current_step = estimator.latest_checkpoint()\n",
    "if(not current_step):\n",
    "    current_step = 0\n",
    "else:\n",
    "    current_step = int(estimator.latest_checkpoint().split('-')[-1])\n",
    "tf.logging.info('Training for %d steps. Current step %d.' % (args.max_steps, current_step))\n",
    "\n",
    "start_timestamp = time.time()\n",
    "while current_step < args.max_steps:\n",
    "    next_checkpoint = min(current_step + args.steps_per_eval, args.max_steps)\n",
    "    estimator.train(input_fn=input_fn, max_steps=next_checkpoint)\n",
    "    current_step = next_checkpoint\n",
    "\n",
    "    elapsed_time = int(time.time() - start_timestamp)\n",
    "    tf.logging.info('Finished training up to step %d. Elapsed seconds %d.' % (current_step, elapsed_time))\n",
    "    tf.logging.info('Starting to evaluate.')\n",
    "\n",
    "    eval_results = estimator.evaluate(\n",
    "        input_fn=input_fn,\n",
    "        steps=args.num_train_examples // args.eval_batch_size\n",
    "    )\n",
    "\n",
    "    tf.logging.info('Eval results: %s' % eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom estimator's train and evaluate function\n",
    "def train_and_evaluate(output_dir, estimator):\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = get_train(),\n",
    "                                    max_steps = 1000)\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = get_train(),\n",
    "                                  steps = None, throttle_secs=600)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-28130f1d2463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(args.model_dir, estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = tf.losses.softmax_cross_entropy\n",
    "model = Network(C=args.init_channels, net_layers=args.num_layers, criterion=criterion, num_classes=args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-1c4497d2f5b8>:1: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-1c4497d2f5b8>:1: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "(x_train, x_valid), (y_train, y_valid) = get_train()(vars(args)).make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'one_hot:0' shape=(8, 4, 4, 6) dtype=float32>, <tf.Tensor 'network/softmaxConv/softmax/Softmax:0' shape=(8, 4, 4, 6) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "loss = model._loss(logits, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent' type=NoOp>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "optimizer.minimize(loss, var_list=model.get_thetas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext:2' shape=(8, 4, 4, 1) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'network/softmaxConv/softmax/Softmax:0' shape=(8, 4, 4, 6) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, w, h, c = y_train.shape\n",
    "y = tf.reshape(tf.cast(y_train, tf.int64), (b, w, h))\n",
    "y = tf.one_hot(y, args.num_classes, on_value=1.0, off_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(8, 4, 4, 6) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "miou = tf.metrics.mean_iou(\n",
    "    labels=y,\n",
    "    predictions=tf.round(logits),\n",
    "    num_classes=args.num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.metrics.mean_iou(\n",
    "    labels=tf.constant([[1, 0, 0], [0, 1, 0]]),\n",
    "    predictions=tf.constant([[1, 0, 0], [0, 0.99999, 0]]),\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_op = tf.local_variables_initializer()\n",
    "global_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run([local_op, global_op])\n",
    "    out = sess.run(miou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
