{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from model_search import Network\n",
    "from architect_graph import Architect\n",
    "\n",
    "import time\n",
    "from genotypes import PRIMITIVES\n",
    "from genotypes import Genotype\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.enable_eager_execution()\n",
    "tf.set_random_seed(6969)\n",
    "np.random.seed(6969)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from genotypes import Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"arch_learning_rate\": 3e-1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"grad_clip\": 5,\n",
    "    \"learning_rate\": 0.9,\n",
    "    \"learning_rate_decay\": 0.97,\n",
    "    \"learning_rate_min\": 0.0001,\n",
    "    \"num_batches_per_epoch\": 2000,\n",
    "    \n",
    "    \"unrolled\": True,\n",
    "    \"epochs\": 10,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"save\": \"EXP\",\n",
    "    \"init_channels\": 3,\n",
    "    \"num_layers\": 3,\n",
    "    \"num_classes\": 6,\n",
    "    \"crop_size\": [8, 8],\n",
    "    \"save_checkpoints_steps\": 100,\n",
    "    \"model_dir\": 'gs://unet-darts/train-search-ckptss',\n",
    "    \"max_steps\": 10000,\n",
    "    # NEW\n",
    "    \"steps_per_eval\": 2,\n",
    "    \"num_train_examples\": 16,\n",
    "    \"num_batches_per_epoch\": 2,\n",
    "    #\n",
    "    \"seed\": 6969,\n",
    "    \n",
    "    \"use_tpu\": False,\n",
    "    \"use_host_call\": False,\n",
    "    \"tpu\": 'unet-darts',\n",
    "#     \"zone\": 'us-central1-f',\n",
    "#     \"project\": \"isro-nas\"\n",
    "    \"zone\": None,\n",
    "    \"project\": None\n",
    "}\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = Struct(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inp_fn(filename, mode, batch_size):\n",
    "    \n",
    "    def _input_fn(params):\n",
    "        image_dataset = tf.data.TFRecordDataset(filename)\n",
    "        W, H = args.crop_size[0], args.crop_size[1]\n",
    "\n",
    "        # Create a dictionary describing the features.  \n",
    "        image_feature_description = {\n",
    "            'train_name': tf.FixedLenFeature([], tf.string),  \n",
    "            'train_x': tf.FixedLenFeature([], tf.string),\n",
    "            'train_y': tf.FixedLenFeature([], tf.string),\n",
    "            'valid_name': tf.FixedLenFeature([], tf.string),  \n",
    "            'valid_x': tf.FixedLenFeature([], tf.string),\n",
    "            'valid_y': tf.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "        def _parse_image_function(example_proto):\n",
    "            # Parse the input tf.Example proto using the dictionary above.\n",
    "            feature= tf.parse_single_example(example_proto, image_feature_description)\n",
    "            train_x = feature['train_x']\n",
    "            train_y = feature['train_y']\n",
    "            valid_x = feature['valid_x']\n",
    "            valid_y = feature['valid_y']\n",
    "            train_name = feature['train_name']\n",
    "            valid_name = feature['valid_name']\n",
    "\n",
    "            train_x = tf.image.decode_png(train_x, channels=3)\n",
    "            train_y = tf.image.decode_png(train_y, channels=3)\n",
    "            valid_x = tf.image.decode_png(valid_x, channels=3)\n",
    "            valid_y = tf.image.decode_png(valid_y, channels=3)\n",
    "            \n",
    "            \n",
    "            train_x = tf.cast(train_x, tf.float32)\n",
    "            train_x = tf.image.resize(train_x, (W, H))\n",
    "            train_y = tf.cast(train_y, tf.float32)\n",
    "            train_y = tf.image.resize(train_y, (W, H))\n",
    "            valid_x = tf.cast(valid_x, tf.float32)\n",
    "            valid_x = tf.image.resize(valid_x, (W, H))\n",
    "            valid_y = tf.cast(valid_y, tf.float32)\n",
    "            valid_y = tf.image.resize(valid_y, (W, H))\n",
    "            \n",
    "            train_y = train_y[:, :, 0]\n",
    "            train_y = tf.expand_dims(train_y, axis=-1)\n",
    "            \n",
    "            valid_y = valid_y[:, :, 0]\n",
    "            valid_y = tf.expand_dims(valid_y, axis=-1)\n",
    "            \n",
    "            return ((train_x, valid_x), (train_y, valid_y))\n",
    "\n",
    "        dataset = image_dataset.map(_parse_image_function)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size,  drop_remainder=True)\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inp_fn2(filename, mode, batch_size):\n",
    "    \n",
    "    def _input_fn(params):\n",
    "        W, H = args.crop_size[0], args.crop_size[1]\n",
    "        NUM_IMAGES = 20\n",
    "        x_train = np.random.randint(0, 256, (NUM_IMAGES, W, H, 3)).astype(np.float32)\n",
    "        y_train = np.random.randint(0, args.num_classes, (NUM_IMAGES, W, H, 1)).astype(np.float32)\n",
    "        x_valid = np.random.randint(0, 256, (NUM_IMAGES, W, H, 3)).astype(np.float32)\n",
    "        y_valid = np.random.randint(0, args.num_classes, (NUM_IMAGES, W, H, 1)).astype(np.float32)\n",
    "\n",
    "        ds = (x_train, x_valid), (y_train, y_valid)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ds)\n",
    "        num_epochs = None # indefinitely\n",
    "        dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size, drop_remainder=True)\n",
    "        return dataset\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneSaver(tf.estimator.SessionRunHook):\n",
    "    def __init__(self, model, alphas_normal, alphas_reduce):\n",
    "        self.model = model\n",
    "        self.alphas_normal = alphas_normal\n",
    "        self.alphas_reduce = alphas_reduce\n",
    "    \n",
    "    def begin(self):\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        \n",
    "    def end(self, session):\n",
    "        alphas_normal, alphas_reduce = session.run([self.alphas_normal, self.alphas_reduce])\n",
    "        alphas_normal = softmax(alphas_normal)\n",
    "        alphas_reduce = softmax(alphas_reduce)\n",
    "        \n",
    "        genotype = self.model.genotype(alphas_normal, alphas_reduce)        \n",
    "        self.global_step = session.run(self.global_step)\n",
    "        \n",
    "        filename = 'final_genotype.{}'.format((self.global_step))\n",
    "        tf.logging.info(\"Saving Genotype for step: {}\".format(str(self.global_step)))\n",
    "        utils.write_genotype(genotype, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    criterion = tf.losses.softmax_cross_entropy\n",
    "    model = Network(C=args.init_channels, net_layers=args.num_layers, criterion=criterion, num_classes=args.num_classes)\n",
    "#     _ = model(np.random.randn(args.train_batch_size, args.crop_size[0], args.crop_size[1], 3))\n",
    "    eval_hooks = None\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    prediction_dict = None\n",
    "    export_outputs = None\n",
    "    host_call = None\n",
    "    \n",
    "    # 2. Loss function, training/eval ops\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        learning_rate_min = tf.constant(args.learning_rate_min)\n",
    "\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            args.learning_rate,\n",
    "            global_step,\n",
    "            decay_rate=args.learning_rate_decay,\n",
    "            decay_steps=args.num_batches_per_epoch,\n",
    "            staircase=True,\n",
    "        )\n",
    "\n",
    "        lr = tf.maximum(learning_rate, learning_rate_min)\n",
    "\n",
    "        optimizer = tf.train.MomentumOptimizer(lr, args.momentum)\n",
    "\n",
    "        if(args.use_tpu):\n",
    "            optimizer = tf.tpu.CrossShardOptimizer(optimizer)\n",
    "        (x_train, x_valid) = features\n",
    "        (y_train, y_valid) = labels\n",
    "\n",
    "        preds = model(x_train)\n",
    "        architect = Architect(model, args)\n",
    "       # architect step\n",
    "        \n",
    "        update_ops0 = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops0):\n",
    "            architect_step = architect.step(input_train=x_train,\n",
    "                                            target_train=y_train,\n",
    "                                            input_valid=x_valid,\n",
    "                                            target_valid=y_valid,\n",
    "                                            unrolled=args.unrolled,\n",
    "                                            )\n",
    "        w_var = model.get_thetas()\n",
    "        loss = model._loss(preds, y_train)\n",
    "        grads = tf.gradients(loss, w_var, name='train_gradients')\n",
    "        \n",
    "        with tf.control_dependencies([architect_step]):\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                train_op = optimizer.apply_gradients(zip(grads, w_var), global_step=tf.train.get_global_step())\n",
    "\n",
    "\n",
    "    # 5. Return EstimatorSpec\n",
    "    return tf.estimator.tpu.TPUEstimatorSpec(\n",
    "        mode = mode,\n",
    "        predictions = prediction_dict,\n",
    "        loss = loss,\n",
    "        train_op = train_op,\n",
    "        eval_metrics = eval_metric_ops,\n",
    "        export_outputs = export_outputs,\n",
    "        evaluation_hooks=eval_hooks,\n",
    "        host_call=host_call\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions to read in respective datasets\n",
    "def get_train():\n",
    "    return make_inp_fn2(filename = tf.gfile.Glob('../../datasets/train_search/train-search-*-00008.tfrecords'),\n",
    "                        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "                        batch_size = args.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create serving input function\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "      IMAGE_LOC: tf.placeholder(tf.float32, [None])\n",
    "    }\n",
    "    \n",
    "    feature_placeholders['IMAGES'] = tf.placeholder(tf.float32, [None, args.crop_size[0], args.crop_size[1], args.init_channels])\n",
    "    \n",
    "    features = {\n",
    "    key: tf.expand_dims(tensor, -1)\n",
    "    for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "      tpu=args.tpu,\n",
    "      zone=args.zone,\n",
    "      project=args.project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = tf.estimator.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    model_dir=args.model_dir,\n",
    "    save_checkpoints_steps=args.save_checkpoints_steps,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(num_shards=8),\n",
    "    tf_random_seed=args.seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "cluster_def {\n",
      "  job {\n",
      "    name: \"worker\"\n",
      "    tasks {\n",
      "      key: 0\n",
      "      value: \"10.240.1.18:8470\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2bb1a96e50>, '_model_dir': 'gs://unet-darts/train-search-ckptss', '_protocol': None, '_save_checkpoints_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_tf_random_seed': 6969, '_save_summary_steps': 100, '_device_fn': None, '_session_creation_timeout_secs': 7200, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f2bb90d9490>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_experimental_max_worker_delay_secs': None, '_evaluation_master': u'grpc://10.240.1.18:8470', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': u'grpc://10.240.1.18:8470'}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.tpu.TPUEstimator(\n",
    "    use_tpu=args.use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=config,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    eval_batch_size=args.eval_batch_size,\n",
    "    params=vars(args)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "WARNING:tensorflow:From operations.py:290: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:7: The name tf.layers.MaxPooling2D is deprecated. Please use tf.compat.v1.layers.MaxPooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:6: The name tf.layers.AveragePooling2D is deprecated. Please use tf.compat.v1.layers.AveragePooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From model_search.py:93: The name tf.layers.Conv2DTranspose is deprecated. Please use tf.compat.v1.layers.Conv2DTranspose instead.\n",
      "\n",
      "WARNING:tensorflow:From model_search.py:179: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From architect_graph.py:41: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From architect_graph.py:97: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From architect_graph.py:111: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://unet-darts/train-search-ckptss/model.ckpt-290\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 290 into gs://unet-darts/train-search-ckptss/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 300 into gs://unet-darts/train-search-ckptss/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 1.8932021.\n",
      "INFO:tensorflow:training_loop marked as finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator at 0x7f2bb1a96dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn = get_train(), steps=10)\n",
    "# Loss for final step: 1.9186516."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01695889, -0.04184179, -0.01425209,  0.04107325],\n",
       "       [-0.04151864,  0.00794181,  0.08955112, -0.05951698],\n",
       "       [ 0.02892872, -0.04694319, -0.01564714,  0.03687111],\n",
       "       [-0.00940474, -0.00713697,  0.04399676, -0.02644248],\n",
       "       [ 0.00102057, -0.03073446, -0.02404075,  0.05464585],\n",
       "       [ 0.02468788,  0.0012726 , -0.045113  ,  0.0225525 ],\n",
       "       [ 0.01003213, -0.00243887, -0.05038981,  0.04622243],\n",
       "       [ 0.01834823, -0.01843441, -0.02245464,  0.02499198],\n",
       "       [ 0.02915651, -0.02340005, -0.02678607,  0.02285247],\n",
       "       [ 0.01329712, -0.00685036, -0.02164326,  0.01748462],\n",
       "       [-0.02285887,  0.0109119 ,  0.02861176, -0.01453894],\n",
       "       [-0.00064974,  0.00058517,  0.00407862, -0.00187617],\n",
       "       [-0.0025976 ,  0.00103705,  0.00718386, -0.00399489],\n",
       "       [-0.00473083,  0.00820372,  0.01349145, -0.01548955]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_variable_value('network/alphas_normal')\n",
    "# array([[ 0.01695889, -0.04184179, -0.01425209,  0.04107325],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.21160507, -0.21848902,  0.23653212,  0.11754844,\n",
       "           0.07842084,  0.20762058, -0.02427896,  0.05266505,\n",
       "           0.06588185],\n",
       "         [-0.10964472, -0.19849841,  0.20948522, -0.08818717,\n",
       "          -0.1918711 ,  0.14931907, -0.10729859, -0.17201567,\n",
       "          -0.11432522],\n",
       "         [-0.12347911,  0.16643406, -0.05902734, -0.03249671,\n",
       "           0.11748508,  0.14278087, -0.05715536,  0.21601404,\n",
       "          -0.22197345]],\n",
       "\n",
       "        [[-0.19773257,  0.21238694, -0.08473241,  0.08368283,\n",
       "          -0.11171204, -0.11749534, -0.12242602, -0.14338504,\n",
       "          -0.21754499],\n",
       "         [ 0.11206506, -0.10706716,  0.08288258,  0.09993035,\n",
       "           0.04749881,  0.07117351,  0.05172399, -0.18064596,\n",
       "          -0.08402789],\n",
       "         [-0.11511762,  0.21876034,  0.06738853,  0.0756783 ,\n",
       "           0.12194356, -0.16608292,  0.0934642 ,  0.01872056,\n",
       "          -0.22174531]],\n",
       "\n",
       "        [[ 0.22120355, -0.08398765, -0.07401478,  0.13258912,\n",
       "          -0.20800927,  0.12645443, -0.06177693, -0.21864271,\n",
       "           0.1966012 ],\n",
       "         [ 0.04349887,  0.03574362, -0.1086015 , -0.06313333,\n",
       "          -0.05268743, -0.17980942, -0.06347769,  0.09602766,\n",
       "          -0.0339951 ],\n",
       "         [ 0.19228919, -0.09028449,  0.08544632,  0.08014271,\n",
       "           0.12048281, -0.19255777,  0.14316139, -0.17451784,\n",
       "          -0.03126677]]],\n",
       "\n",
       "\n",
       "       [[[-0.09517287, -0.1635905 , -0.10247717,  0.16602947,\n",
       "          -0.17802711, -0.04520962, -0.1094667 ,  0.05879199,\n",
       "           0.12594679],\n",
       "         [-0.15388548, -0.03262915,  0.03216514,  0.07442784,\n",
       "           0.05456139, -0.19574286, -0.05440907,  0.01420919,\n",
       "          -0.09803659],\n",
       "         [ 0.20420824, -0.10862117,  0.2510207 , -0.10801602,\n",
       "          -0.15047666, -0.04455966,  0.20879772,  0.02125593,\n",
       "          -0.22095272]],\n",
       "\n",
       "        [[-0.09073101, -0.13217498, -0.13684434, -0.06230374,\n",
       "           0.20658247,  0.01345848, -0.19904876,  0.15933268,\n",
       "           0.08739638],\n",
       "         [ 0.04296954, -0.17917709,  0.10341185, -0.01668229,\n",
       "          -0.02438099, -0.0345993 ,  0.15547465,  0.13218579,\n",
       "           0.18072762],\n",
       "         [-0.14060313,  0.05772287,  0.06063473,  0.08873516,\n",
       "           0.12997565,  0.1291954 , -0.06076911, -0.11779717,\n",
       "           0.16214459]],\n",
       "\n",
       "        [[ 0.15843488, -0.04136933,  0.23396257, -0.08236232,\n",
       "           0.04707328, -0.00108011,  0.18839784, -0.08481348,\n",
       "          -0.09785996],\n",
       "         [-0.20953993,  0.14085008, -0.19125752,  0.1119641 ,\n",
       "          -0.07265671,  0.01441791, -0.16407642,  0.08034308,\n",
       "           0.20065564],\n",
       "         [-0.17684925, -0.1848586 ,  0.0617777 , -0.23882835,\n",
       "          -0.13852905,  0.0035592 , -0.14655   ,  0.01640091,\n",
       "           0.02090381]]],\n",
       "\n",
       "\n",
       "       [[[-0.06206481, -0.1527274 , -0.12501702, -0.20631349,\n",
       "           0.22730312, -0.0644552 , -0.19745892, -0.16490613,\n",
       "           0.05690599],\n",
       "         [-0.19145507,  0.20597218, -0.19253556, -0.12168183,\n",
       "          -0.00527504, -0.00168605, -0.1421524 , -0.0433886 ,\n",
       "          -0.2050979 ],\n",
       "         [ 0.0565372 ,  0.10038555,  0.13711126,  0.08901417,\n",
       "           0.0226217 , -0.07127938,  0.03391531, -0.17204314,\n",
       "           0.22494636]],\n",
       "\n",
       "        [[-0.23989145,  0.01987918,  0.09913882, -0.17638458,\n",
       "           0.04842267,  0.1493999 , -0.09237082, -0.13734029,\n",
       "           0.10087728],\n",
       "         [ 0.18844493, -0.02786795,  0.14841416, -0.15153329,\n",
       "           0.06201072, -0.06036875, -0.03769335, -0.01140408,\n",
       "           0.09942881],\n",
       "         [-0.17177317,  0.20107187, -0.024222  ,  0.06555283,\n",
       "           0.00106538,  0.14795062,  0.07586069,  0.20141049,\n",
       "           0.13120367]],\n",
       "\n",
       "        [[-0.03860411,  0.03996883, -0.20111999, -0.23806019,\n",
       "           0.18971322,  0.17728572,  0.08323558, -0.01731708,\n",
       "           0.08623554],\n",
       "         [-0.19482851,  0.12608616, -0.0186291 ,  0.0760134 ,\n",
       "           0.24586512,  0.2318046 , -0.03222284, -0.14407808,\n",
       "          -0.05698298],\n",
       "         [ 0.10747351,  0.07322785,  0.23915224, -0.16117783,\n",
       "           0.06658652,  0.21644749, -0.13925184, -0.05370368,\n",
       "           0.02181797]]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_variable_value('network/sequential/conv2d/kernel:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = tf.losses.softmax_cross_entropy\n",
    "model = Network(C=args.init_channels, net_layers=args.num_layers, criterion=criterion, num_classes=args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-1c4497d2f5b8>:1: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-1c4497d2f5b8>:1: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "(x_train, x_valid), (y_train, y_valid) = get_train()(vars(args)).make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'one_hot:0' shape=(8, 4, 4, 6) dtype=float32>, <tf.Tensor 'network/softmaxConv/softmax/Softmax:0' shape=(8, 4, 4, 6) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "loss = model._loss(logits, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent' type=NoOp>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "optimizer.minimize(loss, var_list=model.get_thetas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext:2' shape=(8, 4, 4, 1) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'network/softmaxConv/softmax/Softmax:0' shape=(8, 4, 4, 6) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, w, h, c = y_train.shape\n",
    "y = tf.reshape(tf.cast(y_train, tf.int64), (b, w, h))\n",
    "y = tf.one_hot(y, args.num_classes, on_value=1.0, off_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(8, 4, 4, 6) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "miou = tf.metrics.mean_iou(\n",
    "    labels=y,\n",
    "    predictions=tf.round(logits),\n",
    "    num_classes=args.num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.metrics.mean_iou(\n",
    "    labels=tf.constant([[1, 0, 0], [0, 1, 0]]),\n",
    "    predictions=tf.constant([[1, 0, 0], [0, 0.99999, 0]]),\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_op = tf.local_variables_initializer()\n",
    "global_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run([local_op, global_op])\n",
    "    out = sess.run(miou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
