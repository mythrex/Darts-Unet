{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _concat(xs):\n",
    "    \"\"\"nd tensor to 1d tensor\n",
    "\n",
    "    Args:\n",
    "        xs (array): the array of nd tensor\n",
    "\n",
    "    Returns:\n",
    "        array: concated array\n",
    "    \"\"\"\n",
    "    return tf.concat([tf.reshape(x, [tf.size(x)]) for x in xs], axis=0, name=\"_concat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[[[1],[2],[3]], [[4], [5], [6]]], [[[2],[4],[6]], [[8], [10], [12]]]])\n",
    "b = tf.constant([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat/concat:0' shape=(12,) dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(tf.reshape(a, [tf.size(a)]), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Architect(object):\n",
    "    \"\"\"Constructs the model\n",
    "\n",
    "    Parameters:\n",
    "      network_momentum(float):  network momentum\n",
    "      network_weight_decay(float): network weight decay\n",
    "      model(Network): Network archtecture with cells\n",
    "      optimise(optimiser): Adam / SGD\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, args):\n",
    "        \"\"\"Initialises the architecture\n",
    "\n",
    "        Args:\n",
    "            model (Network): Network archtecture with cells\n",
    "            args (dict): cli args\n",
    "        \"\"\"\n",
    "        self.network_momentum = args.momentum\n",
    "        self.network_weight_decay = args.weight_decay\n",
    "        self.model = model\n",
    "        self.arch_learning_rate = args.arch_learning_rate\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.arch_learning_rate,\n",
    "                                                beta1=0.5,\n",
    "                                                beta2=0.999)    \n",
    "        self.learning_rate = args.learning_rate\n",
    "\n",
    "    def get_model_theta(self, model):\n",
    "        specific_tensor = []\n",
    "        specific_tensor_name = []\n",
    "        for var in model.trainable_weights:\n",
    "            if not 'alphas' in var.name:\n",
    "                specific_tensor.append(var)\n",
    "                specific_tensor_name.append(var.name)\n",
    "        return specific_tensor\n",
    "    \n",
    "    def step(self, input_train, target_train, input_valid, target_valid, unrolled):\n",
    "        \"\"\"Computer a step for gradient descend\n",
    "\n",
    "        Args:\n",
    "            input_train (tensor): a train of input\n",
    "            target_train (tensor): a train of targets\n",
    "            input_valid (tensor): a train of validation\n",
    "            target_valid (tensor): a train of validation targets\n",
    "            eta (tensor): eta\n",
    "            network_optimizer (optimiser): network optimiser for network\n",
    "            unrolled (bool): True if training we need unrolled\n",
    "        \"\"\"\n",
    "        if unrolled:\n",
    "#             w_regularization_loss = tf.add_n(utils.get_var(tf.losses.get_regularization_losses(),'network')[1])\n",
    "            w_regularization_loss = 0.25\n",
    "            logits = self.model(input_train)\n",
    "            train_loss = self.model._loss(logits, target_train)\n",
    "            train_loss += 1e4*0.25*w_regularization_loss\n",
    "            return self._compute_unrolled_step(input_train, \n",
    "                                               target_train, \n",
    "                                               input_valid, \n",
    "                                               target_valid,\n",
    "                                               self.get_model_theta(self.model),\n",
    "                                               train_loss,\n",
    "                                               self.learning_rate\n",
    "                                              )\n",
    "        else:\n",
    "            return self._backward_step(input_valid, target_valid)\n",
    "        \n",
    "    \n",
    "    def _compute_unrolled_step(self, x_train, y_train, x_valid, y_valid, w_var, train_loss, lr):\n",
    "        arch_var = self.model.arch_parameters()\n",
    "        \n",
    "        unrolled_model = self.model.new()\n",
    "        logits = unrolled_model(x_train)\n",
    "        unrolled_train_loss = unrolled_model._loss(logits, y_train)  \n",
    "        unrolled_w_var = self.get_model_theta(unrolled_model)\n",
    "        copy_weight_opts = [v.assign(w) for v,w in zip(unrolled_w_var,w_var)]\n",
    "        #w'\n",
    "        with tf.control_dependencies(copy_weight_opts):\n",
    "            unrolled_optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "            unrolled_optimizer = unrolled_optimizer.minimize(unrolled_train_loss, var_list=unrolled_w_var)\n",
    "\n",
    "        valid_logits = unrolled_model(x_valid)\n",
    "        valid_loss = unrolled_model._loss(valid_logits, y_valid)\n",
    "        tf.summary.scalar('valid_loss', valid_loss)\n",
    "\n",
    "        with tf.control_dependencies([unrolled_optimizer]):\n",
    "            valid_grads = tf.gradients(valid_loss, unrolled_w_var)\n",
    "\n",
    "        r=1e-2\n",
    "        R = r / (tf.global_norm(valid_grads)+1e-6)\n",
    "\n",
    "        optimizer_pos=tf.train.GradientDescentOptimizer(R)\n",
    "        optimizer_pos=optimizer_pos.apply_gradients(zip(valid_grads, w_var))\n",
    "\n",
    "        optimizer_neg=tf.train.GradientDescentOptimizer(-2*R)\n",
    "        optimizer_neg=optimizer_neg.apply_gradients(zip(valid_grads, w_var))\n",
    "\n",
    "        optimizer_back=tf.train.GradientDescentOptimizer(R)\n",
    "        optimizer_back=optimizer_back.apply_gradients(zip(valid_grads, w_var))\n",
    "\n",
    "        with tf.control_dependencies([optimizer_pos]):\n",
    "            train_grads_pos=tf.gradients(train_loss, arch_var)\n",
    "            with tf.control_dependencies([optimizer_neg]):\n",
    "                train_grads_neg=tf.gradients(train_loss,arch_var)\t\n",
    "                with tf.control_dependencies([optimizer_back]):\n",
    "                  leader_opt= self.optimizer\n",
    "                  leader_grads=leader_opt.compute_gradients(valid_loss, var_list =unrolled_model.arch_parameters())\n",
    "        for i,(g,v) in enumerate(leader_grads):\n",
    "            leader_grads[i]=(g - self.learning_rate * tf.divide(train_grads_pos[i]-train_grads_neg[i],2*R),v)\n",
    "\n",
    "        leader_opt=leader_opt.apply_gradients(leader_grads)\n",
    "        return leader_opt\n",
    "    \n",
    "    def _backward_step(self, input_valid, target_valid):\n",
    "        \"\"\"Backward step for validation\n",
    "\n",
    "        Args:\n",
    "            input_train (tensor): a train of input\n",
    "            target_train (tensor): a train of targets\n",
    "        \"\"\"\n",
    "        loss = self.model._loss(self.model(input_valid), target_valid)\n",
    "        opt = self.optimizer.minimize(loss, var_list=model.get_weights())\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_search import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From operations.py:290: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
      "\n",
      "WARNING:tensorflow:From operations.py:7: The name tf.layers.MaxPooling2D is deprecated. Please use tf.compat.v1.layers.MaxPooling2D instead.\n",
      "\n",
      "WARNING:tensorflow:From model_search.py:97: The name tf.layers.Conv2DTranspose is deprecated. Please use tf.compat.v1.layers.Conv2DTranspose instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = tf.losses.sigmoid_cross_entropy\n",
    "model = Network(3, 3, criterion)\n",
    "args = {\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 3e-4,\n",
    "    \"arch_learning_rate\": 3e-1,\n",
    "    \"arch_weight_decay\": 1e-3,\n",
    "    \"learning_rate\": 0.025\n",
    "}\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ds_train = (np.random.randint(0, 256, (20, 4, 4, 3)).astype(np.float32), np.random.randint(0, 2, (20, 4, 4, 1)).astype(np.float32))\n",
    "np_ds_valid = (np.random.randint(0, 256, (20, 4, 4, 3)).astype(np.float32), np.random.randint(0, 2, (20, 4, 4, 1)).astype(np.float32))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(np_ds_train).batch(1)\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices(np_ds_valid).batch(1)\n",
    "\n",
    "it_train = ds_train.make_one_shot_iterator()\n",
    "image, label = it_train.get_next()\n",
    "it_valid = ds_valid.make_one_shot_iterator()\n",
    "image_valid, label_valid = it_valid.get_next()\n",
    "lr=0.025\n",
    "unrolled=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "res = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "architect = Architect(model, Struct(**args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From model_search.py:198: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "opt = architect.step(image, label, image_valid, label_valid, unrolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    tf.initialize_all_variables().run()\n",
    "    out = sess.run(opt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
