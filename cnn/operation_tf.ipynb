{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPS = {\n",
    "    'none': lambda C, stride: Zero(stride),\n",
    "    'avg_pool_3x3': lambda C, stride: layers.AveragePooling2D(3, strides=stride, padding='same'),\n",
    "    'max_pool_3x3': lambda C, stride: layers.MaxPooling2D(3, strides=stride, padding='same'),\n",
    "    'skip_connect': lambda C, stride: Identity() if stride == 1 else FactorizedReduce(C, C),\n",
    "    'sep_conv_3x3': lambda C, stride: SepConv(C, C, 3, stride, 'same'),\n",
    "    'sep_conv_5x5': lambda C, stride: SepConv(C, C, 5, stride, 'same'),\n",
    "    'sep_conv_7x7': lambda C, stride: SepConv(C, C, 7, stride, 'same'),\n",
    "    'dil_conv_3x3': lambda C, stride: DilConv(C, C, 3, stride, 'same', 2),\n",
    "    'dil_conv_5x5': lambda C, stride: DilConv(C, C, 5, stride, 'same', 2),\n",
    "    'conv_7x1_1x7': lambda C, stride: Conv_7x1_1x7(C, stride)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUConvBN(tf.keras.layers.Layer):\n",
    "    \"\"\"Applies ReLU, Conv and BatchNormalisation operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding='same'):\n",
    "        \"\"\"Initializes the operation\n",
    "\n",
    "        Args:\n",
    "            C_in (int): no of kernels in\n",
    "            C_out (int): no of kernels out\n",
    "            kernel_size (int): size of kernel\n",
    "            stride (int): stride\n",
    "            padding (int): padding\n",
    "            affine (bool), optional): Defaults to True.\n",
    "        \"\"\"\n",
    "        super(ReLUConvBN, self).__init__()\n",
    "        self.relu = tf.nn.relu\n",
    "        self.conv = layers.Conv2D(filters=C_out,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  strides=stride,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\"Applies the ReLU, Conv, BN to input\n",
    "\n",
    "        Args:\n",
    "            x (tensor): array or tensor (can be image)\n",
    "\n",
    "        Returns:\n",
    "            tensor: array or tensor with operations applied on it\n",
    "        \"\"\"\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilConv(tf.keras.layers.Layer):\n",
    "    \"\"\"Applies ReLU, Conv with dilation and BatchNormalisation operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation):\n",
    "        super(DilConv, self).__init__()\n",
    "        self.relu = tf.nn.relu\n",
    "        self.dil_conv = layers.Conv2D(filters=C_out, \n",
    "                                      kernel_size=kernel_size, \n",
    "                                      strides=stride, \n",
    "                                      padding=padding,\n",
    "                                      dilation_rate=dilation,\n",
    "                                      use_bias=False\n",
    "                                     )\n",
    "        self.conv = layers.Conv2D(filters=C_out,\n",
    "                                  kernel_size=1,\n",
    "                                  strides=1,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Applies the ReLU, Conv, BN to input\n",
    "\n",
    "        Args:\n",
    "            x (tensor): array or tensor (can be image)\n",
    "\n",
    "        Returns:\n",
    "            tensor: array or tensor with operations applied on it\n",
    "        \"\"\"\n",
    "        x = self.relu(x)\n",
    "        x = self.dil_conv(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepConv(tf.keras.layers.Layer):\n",
    "    \"\"\"Applies ReLU, Sep Conv with dilation and BatchNormalisation operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding):\n",
    "        super(SepConv, self).__init__()\n",
    "        self.relu = tf.nn.relu\n",
    "        self.conv1 = layers.Conv2D(filters=C_in,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  strides=stride,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.conv2 = layers.Conv2D(filters=C_in,\n",
    "                                  kernel_size=1,\n",
    "                                  strides=stride,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv3 = layers.Conv2D(filters=C_in,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  strides=1,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.conv4 = layers.Conv2D(filters=C_out,\n",
    "                                  kernel_size=1,\n",
    "                                  strides=1,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Applies the ReLU, Conv, BN to input\n",
    "\n",
    "        Args:\n",
    "            x (tensor): array or tensor (can be image)\n",
    "\n",
    "        Returns:\n",
    "            tensor: array or tensor with operations applied on it\n",
    "        \"\"\"\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(tf.keras.layers.Layer):\n",
    "    \"\"\"Apply the identity operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def call(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zero(tf.keras.layers.Layer):\n",
    "    \"\"\"Makes array element zero with given stride\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stride):\n",
    "        super(Zero, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.stride == 1:\n",
    "            return tf.multiply(x, 0)\n",
    "        return tf.multiply(x[:, ::self.stride, ::self.stride, :], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_7x1_1x7(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, C, stride):\n",
    "    super(Conv_7x1_1x7, self).__init__()\n",
    "    self.relu = tf.nn.relu\n",
    "    self.conv1 = layers.Conv2D(filters=C,\n",
    "                             kernel_size=(1,7),\n",
    "                             strides=(1, stride),\n",
    "                             padding='same',\n",
    "                             use_bias=False)\n",
    "    self.conv2 = layers.Conv2D(filters=C,\n",
    "                             kernel_size=(7,1),\n",
    "                             strides=(stride, 1),\n",
    "                             padding='same',\n",
    "                             use_bias=False)\n",
    "    self.bn = layers.BatchNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.relu(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn(x)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizedReduce(tf.keras.layers.Layer):\n",
    "    \"\"\"Applies ReLU, conv with stride=2 and c_out/2 \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(FactorizedReduce, self).__init__()\n",
    "        assert C_out % 2 == 0\n",
    "        self.relu = tf.nn.relu\n",
    "        self.conv_1 = layers.Conv2D(filters=C_out//2, \n",
    "                                    kernel_size=1,\n",
    "                                    strides=2, \n",
    "                                    padding='same', \n",
    "                                    use_bias=False)\n",
    "        self.conv_2 = layers.Conv2D(filters=C_out//2, \n",
    "                                    kernel_size=1,\n",
    "                                    strides=2, \n",
    "                                    padding='same', \n",
    "                                    use_bias=False)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"concats conv and Batch normalise them\n",
    "\n",
    "        Args:\n",
    "            x (tensor): array or tensor (can be image)\n",
    "\n",
    "        Returns:\n",
    "            tensor: tensor of operations on input\n",
    "        \"\"\"\n",
    "        x = self.relu(x)\n",
    "        out = tf.concat([self.conv_1(x), self.conv_2(x[:, 1:, 1:, :])], axis=3)\n",
    "        out = self.bn(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizedUp(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, C_in, C_out):\n",
    "    super(FactorizedUp, self).__init__()\n",
    "    self.relu = tf.nn.relu\n",
    "    self.trans_conv1 = layers.Conv2DTranspose(filters=C_out, \n",
    "                                             kernel_size=3,\n",
    "                                             strides=2,\n",
    "                                             padding='same',\n",
    "                                             )\n",
    "    self.trans_conv2 = layers.Conv2DTranspose(filters=C_out,\n",
    "                                             kernel_size=3,\n",
    "                                             strides=2,\n",
    "                                             padding='same',\n",
    "                                             )\n",
    "    \n",
    "    self.bn = layers.BatchNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.relu(x)\n",
    "    out = (self.trans_conv1(x) + self.trans_conv2(x)) * 0.5\n",
    "    out = self.bn(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnection(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, C):    \n",
    "    super(SkipConnection, self).__init__()\n",
    "    self.relu = tf.nn.relu\n",
    "    self.conv = layers.Conv2D(filters=C,\n",
    "                             kernel_size=3,\n",
    "                             strides=1,\n",
    "                             padding='same',\n",
    "                             use_bias=False)\n",
    "\n",
    "  def call(self, s0, s1):\n",
    "    s0 = self.relu(s0)\n",
    "    s1 = self.relu(s1)\n",
    "    x = tf.concat([s1, s0], axis=3)\n",
    "    x = self.conv(x)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sep_conv_7x7', (1, 16, 16, 6))\n",
      "('sep_conv_3x3', (1, 16, 16, 6))\n",
      "('none', (1, 16, 16, 3))\n",
      "('dil_conv_5x5', (1, 8, 8, 6))\n",
      "('skip_connect', (1, 16, 16, 3))\n",
      "('max_pool_3x3', (1, 14, 14, 3))\n",
      "('dil_conv_3x3', (1, 12, 12, 6))\n",
      "('avg_pool_3x3', (1, 14, 14, 3))\n",
      "('conv_7x1_1x7', (1, 16, 16, 6))\n",
      "('sep_conv_5x5', (1, 16, 16, 6))\n",
      "Pass\n"
     ]
    }
   ],
   "source": [
    "for op in OPS:\n",
    "    model = OPS[op](6, 1)\n",
    "\n",
    "    image = tf.random_uniform([1, 16, 16, 3], 0, 255, seed=0, dtype=tf.bfloat16)\n",
    "\n",
    "    ip = tf.placeholder(tf.bfloat16, shape=[None, 16, 16, 3], name = \"input\")\n",
    "    out = model(ip)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        image = sess.run(image)\n",
    "        out = sess.run(out, {ip: image})\n",
    "        print(op, out.shape)\n",
    "print('Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sep_conv_7x7', (1, 16, 16, 6))\n",
      "('sep_conv_3x3', (1, 16, 16, 6))\n",
      "('none', (1, 16, 16, 3))\n",
      "('dil_conv_5x5', (1, 16, 16, 6))\n",
      "('skip_connect', (1, 16, 16, 3))\n",
      "('max_pool_3x3', (1, 16, 16, 3))\n",
      "('dil_conv_3x3', (1, 16, 16, 6))\n",
      "('avg_pool_3x3', (1, 16, 16, 3))\n",
      "('conv_7x1_1x7', (1, 16, 16, 6))\n",
      "('sep_conv_5x5', (1, 16, 16, 6))\n",
      "Pass\n"
     ]
    }
   ],
   "source": [
    "for op in OPS:\n",
    "    model = OPS[op](6, 1)\n",
    "\n",
    "    image = tf.random_uniform([1, 16, 16, 3], 0, 255, seed=0, dtype=tf.bfloat16)\n",
    "\n",
    "    ip = tf.placeholder(tf.bfloat16, shape=[None, 16, 16, 3], name = \"input\")\n",
    "    out = model(ip)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        image = sess.run(image)\n",
    "        out = sess.run(out, {ip: image})\n",
    "        print(op, out.shape)\n",
    "print('Pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Skip Connection Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SkipConnection(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[[[-2.57018547e+01,  7.61903229e+01, -3.45278358e+01,\n          -5.72116356e+01,  1.26228523e+01,  8.30161095e+00],\n         [-4.53565216e+01,  5.90059395e+01, -7.78427734e+01,\n          -4.51087723e+01,  1.96594200e+01, -2.17728271e+01],\n         [-3.78554611e+01,  6.83958206e+01, -8.30463867e+01,\n          -4.79010162e+01, -7.03880835e+00, -3.36997681e+01],\n         ...,\n         [-7.99613094e+00,  6.40714874e+01, -3.66161537e+01,\n          -2.66654663e+01,  2.62819099e+01, -1.66042209e+00],\n         [-2.34229183e+01,  5.17971725e+01, -3.66127586e+01,\n          -4.10278931e+01, -9.38137323e-02, -7.03476143e+00],\n         [-4.30943031e+01,  6.05036640e+00, -4.04830284e+01,\n          -5.66074753e+01, -2.16268654e+01,  4.25936174e+00]],\n\n        [[-4.94909554e+01,  9.09436493e+01, -8.67251892e+01,\n          -6.36064949e+01,  2.13529282e+01, -1.88705063e+01],\n         [-7.74965134e+01,  9.92491226e+01, -1.10210274e+02,\n          -8.35157318e+01,  3.90716057e+01, -2.11505527e+01],\n         [-4.00234680e+01, -1.84381218e+01, -8.12903442e+01,\n           3.23257232e+00,  6.44881248e+00, -4.53211784e+01],\n         ...,\n         [-6.22253227e+01,  9.67921753e+01, -1.46833572e+02,\n          -2.01705742e+01,  8.15413132e+01, -6.76078110e+01],\n         [-5.81512833e+01, -2.11156578e+01, -1.36577301e+02,\n           3.11246929e+01,  4.04988518e+01, -8.95357819e+01],\n         [-3.54642487e+01, -2.52454448e+00, -4.85342903e+01,\n          -4.43812561e+01, -1.30654621e+01,  8.24523747e-01]],\n\n        [[-6.77391968e+01,  5.96715202e+01, -7.74788513e+01,\n          -7.69253006e+01,  1.01868165e+00, -1.32284241e+01],\n         [-7.40155487e+01,  7.78080750e+01, -1.37188217e+02,\n          -3.57185059e+01,  4.85170708e+01, -6.43924713e+01],\n         [-9.59733276e+01,  3.96537132e+01, -1.80275833e+02,\n          -1.92790070e+01,  6.16730995e+01, -8.68394394e+01],\n         ...,\n         [-7.42173462e+01,  6.64554138e+01, -1.32984802e+02,\n          -2.27691288e+01,  5.10788956e+01, -7.56631851e+01],\n         [ 1.49093294e+00,  2.96701527e+00, -5.97532310e+01,\n           6.32925339e+01,  3.69947319e+01, -7.26561584e+01],\n         [-1.75588169e+01, -3.59368944e+00, -7.10392838e+01,\n          -1.64102539e-02,  7.88503551e+00, -2.55195541e+01]],\n\n        ...,\n\n        [[-1.76744385e+01,  5.27106047e-01, -2.63586502e+01,\n          -1.53687239e+00, -5.40139580e+00, -2.21775360e+01],\n         [-6.89619827e+01, -2.81733761e+01, -8.27778778e+01,\n          -1.11997318e+00,  3.14137821e+01, -4.65441971e+01],\n         [-8.76259766e+01, -4.28141098e+01, -1.25212433e+02,\n           1.96293602e+01,  3.43364067e+01, -8.77583694e+01],\n         ...,\n         [-9.16067352e+01, -7.26044846e+01, -1.64549179e+02,\n           4.91880074e+01,  4.79318504e+01, -1.15561310e+02],\n         [-5.19634895e+01,  4.32963943e+01, -1.08599693e+02,\n           1.81007957e+01,  6.13245316e+01, -8.18364258e+01],\n         [-5.99000931e+01,  1.64973888e+01, -1.03957756e+02,\n           2.38437867e+00,  4.57824783e+01, -6.13046608e+01]],\n\n        [[-5.03090820e+01,  7.92624331e+00, -3.39663506e+01,\n          -5.61375732e+01, -2.18432922e+01,  1.02051270e+00],\n         [-5.36571236e+01, -1.69657879e+01, -6.37024193e+01,\n          -2.99647856e+00,  8.96926212e+00, -4.55297852e+01],\n         [-6.35462570e+01,  1.03312826e+01, -1.09852364e+02,\n           1.12363577e+01,  3.88848343e+01, -7.48301697e+01],\n         ...,\n         [-8.32152328e+01, -3.77999992e+01, -1.59636032e+02,\n           5.76926308e+01,  7.34345551e+01, -1.17269714e+02],\n         [-4.79142265e+01,  2.88896503e+01, -8.50314026e+01,\n           2.72671967e+01,  8.50743179e+01, -6.45131531e+01],\n         [-5.58761101e+01, -1.49972343e+00, -1.13074829e+02,\n           4.55414009e+01,  9.10814362e+01, -7.66313095e+01]],\n\n        [[-1.82450161e+01, -3.03277045e-01, -2.67801018e+01,\n           1.34086618e+01,  1.81960869e+01, -2.76990852e+01],\n         [-6.84590769e+00, -3.85046959e+01, -1.86253510e+01,\n           4.57233276e+01, -1.30617580e+01, -5.34230042e+01],\n         [-5.31964417e+01,  2.74249020e+01, -6.41893539e+01,\n          -1.09134007e+00,  3.58701630e+01, -5.07112617e+01],\n         ...,\n         [-6.10478172e+01, -3.10197296e+01, -1.02551376e+02,\n           4.27776604e+01,  5.05676079e+01, -8.35764618e+01],\n         [-2.46421013e+01,  3.74993668e+01, -3.15012741e+01,\n           2.46936398e+01,  6.65503922e+01, -4.21986656e+01],\n         [-1.94295921e+01, -4.30718384e+01, -5.79539986e+01,\n           5.87252884e+01,  4.99326782e+01, -4.89989662e+01]]]],\n      dtype=float32) has invalid type <type 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7ec2179b3955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1165\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \"\"\"\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    307\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    308\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    310\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([[[[-2.57018547e+01,  7.61903229e+01, -3.45278358e+01,\n          -5.72116356e+01,  1.26228523e+01,  8.30161095e+00],\n         [-4.53565216e+01,  5.90059395e+01, -7.78427734e+01,\n          -4.51087723e+01,  1.96594200e+01, -2.17728271e+01],\n         [-3.78554611e+01,  6.83958206e+01, -8.30463867e+01,\n          -4.79010162e+01, -7.03880835e+00, -3.36997681e+01],\n         ...,\n         [-7.99613094e+00,  6.40714874e+01, -3.66161537e+01,\n          -2.66654663e+01,  2.62819099e+01, -1.66042209e+00],\n         [-2.34229183e+01,  5.17971725e+01, -3.66127586e+01,\n          -4.10278931e+01, -9.38137323e-02, -7.03476143e+00],\n         [-4.30943031e+01,  6.05036640e+00, -4.04830284e+01,\n          -5.66074753e+01, -2.16268654e+01,  4.25936174e+00]],\n\n        [[-4.94909554e+01,  9.09436493e+01, -8.67251892e+01,\n          -6.36064949e+01,  2.13529282e+01, -1.88705063e+01],\n         [-7.74965134e+01,  9.92491226e+01, -1.10210274e+02,\n          -8.35157318e+01,  3.90716057e+01, -2.11505527e+01],\n         [-4.00234680e+01, -1.84381218e+01, -8.12903442e+01,\n           3.23257232e+00,  6.44881248e+00, -4.53211784e+01],\n         ...,\n         [-6.22253227e+01,  9.67921753e+01, -1.46833572e+02,\n          -2.01705742e+01,  8.15413132e+01, -6.76078110e+01],\n         [-5.81512833e+01, -2.11156578e+01, -1.36577301e+02,\n           3.11246929e+01,  4.04988518e+01, -8.95357819e+01],\n         [-3.54642487e+01, -2.52454448e+00, -4.85342903e+01,\n          -4.43812561e+01, -1.30654621e+01,  8.24523747e-01]],\n\n        [[-6.77391968e+01,  5.96715202e+01, -7.74788513e+01,\n          -7.69253006e+01,  1.01868165e+00, -1.32284241e+01],\n         [-7.40155487e+01,  7.78080750e+01, -1.37188217e+02,\n          -3.57185059e+01,  4.85170708e+01, -6.43924713e+01],\n         [-9.59733276e+01,  3.96537132e+01, -1.80275833e+02,\n          -1.92790070e+01,  6.16730995e+01, -8.68394394e+01],\n         ...,\n         [-7.42173462e+01,  6.64554138e+01, -1.32984802e+02,\n          -2.27691288e+01,  5.10788956e+01, -7.56631851e+01],\n         [ 1.49093294e+00,  2.96701527e+00, -5.97532310e+01,\n           6.32925339e+01,  3.69947319e+01, -7.26561584e+01],\n         [-1.75588169e+01, -3.59368944e+00, -7.10392838e+01,\n          -1.64102539e-02,  7.88503551e+00, -2.55195541e+01]],\n\n        ...,\n\n        [[-1.76744385e+01,  5.27106047e-01, -2.63586502e+01,\n          -1.53687239e+00, -5.40139580e+00, -2.21775360e+01],\n         [-6.89619827e+01, -2.81733761e+01, -8.27778778e+01,\n          -1.11997318e+00,  3.14137821e+01, -4.65441971e+01],\n         [-8.76259766e+01, -4.28141098e+01, -1.25212433e+02,\n           1.96293602e+01,  3.43364067e+01, -8.77583694e+01],\n         ...,\n         [-9.16067352e+01, -7.26044846e+01, -1.64549179e+02,\n           4.91880074e+01,  4.79318504e+01, -1.15561310e+02],\n         [-5.19634895e+01,  4.32963943e+01, -1.08599693e+02,\n           1.81007957e+01,  6.13245316e+01, -8.18364258e+01],\n         [-5.99000931e+01,  1.64973888e+01, -1.03957756e+02,\n           2.38437867e+00,  4.57824783e+01, -6.13046608e+01]],\n\n        [[-5.03090820e+01,  7.92624331e+00, -3.39663506e+01,\n          -5.61375732e+01, -2.18432922e+01,  1.02051270e+00],\n         [-5.36571236e+01, -1.69657879e+01, -6.37024193e+01,\n          -2.99647856e+00,  8.96926212e+00, -4.55297852e+01],\n         [-6.35462570e+01,  1.03312826e+01, -1.09852364e+02,\n           1.12363577e+01,  3.88848343e+01, -7.48301697e+01],\n         ...,\n         [-8.32152328e+01, -3.77999992e+01, -1.59636032e+02,\n           5.76926308e+01,  7.34345551e+01, -1.17269714e+02],\n         [-4.79142265e+01,  2.88896503e+01, -8.50314026e+01,\n           2.72671967e+01,  8.50743179e+01, -6.45131531e+01],\n         [-5.58761101e+01, -1.49972343e+00, -1.13074829e+02,\n           4.55414009e+01,  9.10814362e+01, -7.66313095e+01]],\n\n        [[-1.82450161e+01, -3.03277045e-01, -2.67801018e+01,\n           1.34086618e+01,  1.81960869e+01, -2.76990852e+01],\n         [-6.84590769e+00, -3.85046959e+01, -1.86253510e+01,\n           4.57233276e+01, -1.30617580e+01, -5.34230042e+01],\n         [-5.31964417e+01,  2.74249020e+01, -6.41893539e+01,\n          -1.09134007e+00,  3.58701630e+01, -5.07112617e+01],\n         ...,\n         [-6.10478172e+01, -3.10197296e+01, -1.02551376e+02,\n           4.27776604e+01,  5.05676079e+01, -8.35764618e+01],\n         [-2.46421013e+01,  3.74993668e+01, -3.15012741e+01,\n           2.46936398e+01,  6.65503922e+01, -4.21986656e+01],\n         [-1.94295921e+01, -4.30718384e+01, -5.79539986e+01,\n           5.87252884e+01,  4.99326782e+01, -4.89989662e+01]]]],\n      dtype=float32) has invalid type <type 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "t1 = tf.random_uniform([1, 16, 16, 6], 0, 255, seed=0, dtype=tf.int32)\n",
    "t2 = tf.random_uniform([1, 16, 16, 6], 0, 255, seed=0, dtype=tf.int32)\n",
    "\n",
    "s0 = tf.placeholder(tf.float32, shape=[None, 16, 16, 6], name = \"state0\")\n",
    "s1 = tf.placeholder(tf.float32, shape=[None, 16, 16, 6], name = \"state1\")\n",
    "out = model(s0, s1)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    t1 = sess.run(t1)\n",
    "    t2 = sess.run(t2)\n",
    "    out = sess.run(out, {s0: t1, s1: t2})\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
