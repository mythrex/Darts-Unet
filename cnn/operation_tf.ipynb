{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPS = {\n",
    "    'none': lambda C, stride: Zero(stride),\n",
    "    'avg_pool_3x3': lambda C, stride: layers.AveragePooling2D(3, strides=stride, padding='same'),\n",
    "    'max_pool_3x3': lambda C, stride: layers.MaxPooling2D(3, strides=stride, padding='same'),\n",
    "    'skip_connect': lambda C, stride: Identity() if stride == 1 else FactorizedReduce(C, C),\n",
    "    'sep_conv_3x3': lambda C, stride: SepConv(C, C, 3, stride, 'same'),\n",
    "    'sep_conv_5x5': lambda C, stride: SepConv(C, C, 5, stride, 'same'),\n",
    "    'sep_conv_7x7': lambda C, stride: SepConv(C, C, 7, stride, 'same'),\n",
    "    'dil_conv_3x3': lambda C, stride: DilConv(C, C, 3, stride, 'same', 2),\n",
    "    'dil_conv_5x5': lambda C, stride: DilConv(C, C, 5, stride, 'same', 2),\n",
    "    'conv_7x1_1x7': lambda C, stride: Conv_7x1_1x7(C, stride)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUConvBN(tf.keras.layers.Layer):\n",
    "    \"\"\"Applies ReLU, Conv and BatchNormalisation operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding='same'):\n",
    "        \"\"\"Initializes the operation\n",
    "\n",
    "        Args:\n",
    "            C_in (int): no of kernels in\n",
    "            C_out (int): no of kernels out\n",
    "            kernel_size (int): size of kernel\n",
    "            stride (int): stride\n",
    "            padding (int): padding\n",
    "            affine (bool), optional): Defaults to True.\n",
    "        \"\"\"\n",
    "        super(ReLUConvBN, self).__init__()\n",
    "        self.relu = tf.nn.relu\n",
    "        self.conv = layers.Conv2D(filters=C_out,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  strides=stride,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\"Applies the ReLU, Conv, BN to input\n",
    "\n",
    "        Args:\n",
    "            x (tensor): array or tensor (can be image)\n",
    "\n",
    "        Returns:\n",
    "            tensor: array or tensor with operations applied on it\n",
    "        \"\"\"\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilConv(tf.keras.layers.Layer):\n",
    "    \"\"\"Applies ReLU, Conv with dilation and BatchNormalisation operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation):\n",
    "        super(DilConv, self).__init__()\n",
    "        self.relu = tf.nn.relu\n",
    "        self.dil_conv = layers.Conv2D(filters=C_out, \n",
    "                                      kernel_size=kernel_size, \n",
    "                                      strides=stride, \n",
    "                                      padding=padding,\n",
    "                                      dilation_rate=dilation,\n",
    "                                      use_bias=False\n",
    "                                     )\n",
    "        self.conv = layers.Conv2D(filters=C_out,\n",
    "                                  kernel_size=1,\n",
    "                                  strides=1,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Applies the ReLU, Conv, BN to input\n",
    "\n",
    "        Args:\n",
    "            x (tensor): array or tensor (can be image)\n",
    "\n",
    "        Returns:\n",
    "            tensor: array or tensor with operations applied on it\n",
    "        \"\"\"\n",
    "        x = self.relu(x)\n",
    "        x = self.dil_conv(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepConv(tf.keras.layers.Layer):\n",
    "    \"\"\"Applies ReLU, Sep Conv with dilation and BatchNormalisation operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding):\n",
    "        super(SepConv, self).__init__()\n",
    "        self.relu = tf.nn.relu\n",
    "        self.conv1 = layers.Conv2D(filters=C_in,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  strides=stride,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.conv2 = layers.Conv2D(filters=C_in,\n",
    "                                  kernel_size=1,\n",
    "                                  strides=stride,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv3 = layers.Conv2D(filters=C_in,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  strides=1,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.conv4 = layers.Conv2D(filters=C_out,\n",
    "                                  kernel_size=1,\n",
    "                                  strides=1,\n",
    "                                  padding='same',\n",
    "                                  use_bias=False\n",
    "                                 )\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Applies the ReLU, Conv, BN to input\n",
    "\n",
    "        Args:\n",
    "            x (tensor): array or tensor (can be image)\n",
    "\n",
    "        Returns:\n",
    "            tensor: array or tensor with operations applied on it\n",
    "        \"\"\"\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(tf.keras.layers.Layer):\n",
    "    \"\"\"Apply the identity operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def call(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zero(tf.keras.layers.Layer):\n",
    "    \"\"\"Makes array element zero with given stride\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stride):\n",
    "        super(Zero, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.stride == 1:\n",
    "            return tf.multiply(x, 0)\n",
    "        return tf.multiply(x[:, ::self.stride, ::self.stride, :], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_7x1_1x7(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, C, stride):\n",
    "    super(Conv_7x1_1x7, self).__init__()\n",
    "    self.relu = tf.nn.relu\n",
    "    self.conv1 = layers.Conv2D(filters=C,\n",
    "                             kernel_size=(1,7),\n",
    "                             strides=(1, stride),\n",
    "                             padding='same',\n",
    "                             use_bias=False)\n",
    "    self.conv2 = layers.Conv2D(filters=C,\n",
    "                             kernel_size=(7,1),\n",
    "                             strides=(stride, 1),\n",
    "                             padding='same',\n",
    "                             use_bias=False)\n",
    "    self.bn = layers.BatchNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.relu(x)\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn(x)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizedReduce(tf.keras.layers.Layer):\n",
    "    \"\"\"Applies ReLU, conv with stride=2 and c_out/2 \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(FactorizedReduce, self).__init__()\n",
    "        assert C_out % 2 == 0\n",
    "        self.relu = tf.nn.relu\n",
    "        self.conv_1 = layers.Conv2D(filters=C_out//2, \n",
    "                                    kernel_size=1,\n",
    "                                    strides=2, \n",
    "                                    padding='same', \n",
    "                                    use_bias=False)\n",
    "        self.conv_2 = layers.Conv2D(filters=C_out//2, \n",
    "                                    kernel_size=1,\n",
    "                                    strides=2, \n",
    "                                    padding='same', \n",
    "                                    use_bias=False)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"concats conv and Batch normalise them\n",
    "\n",
    "        Args:\n",
    "            x (tensor): array or tensor (can be image)\n",
    "\n",
    "        Returns:\n",
    "            tensor: tensor of operations on input\n",
    "        \"\"\"\n",
    "        x = self.relu(x)\n",
    "        out = tf.concat([self.conv_1(x), self.conv_2(x[:, 1:, 1:, :])], axis=3)\n",
    "        out = self.bn(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizedUp(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, C_in, C_out):\n",
    "    super(FactorizedUp, self).__init__()\n",
    "    self.relu = tf.nn.relu\n",
    "    self.trans_conv1 = layers.Conv2DTranspose(filters=C_out, \n",
    "                                             kernel_size=3,\n",
    "                                             strides=2,\n",
    "                                             padding='same',\n",
    "                                             )\n",
    "    self.trans_conv2 = layers.Conv2DTranspose(filters=C_out,\n",
    "                                             kernel_size=3,\n",
    "                                             strides=2,\n",
    "                                             padding='same',\n",
    "                                             )\n",
    "    \n",
    "    self.bn = layers.BatchNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.relu(x)\n",
    "    out = (self.trans_conv1(x) + self.trans_conv2(x)) * 0.5\n",
    "    out = self.bn(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnection(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, C):    \n",
    "    super(SkipConnection, self).__init__()\n",
    "    self.relu = tf.nn.relu\n",
    "    self.conv = layers.Conv2D(filters=C,\n",
    "                             kernel_size=3,\n",
    "                             strides=1,\n",
    "                             padding='same',\n",
    "                             use_bias=False)\n",
    "    self.bn = layers.BatchNormalization()\n",
    "\n",
    "  def call(self, s0, s1):\n",
    "    s0 = self.relu(s0)\n",
    "    s1 = self.relu(s1)\n",
    "    x = tf.concat([s1, s0], axis=3)\n",
    "    x = self.conv(x)\n",
    "    out = self.bn(x)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none (1, 16, 16, 3)\n",
      "avg_pool_3x3 (1, 16, 16, 3)\n",
      "max_pool_3x3 (1, 16, 16, 3)\n",
      "skip_connect (1, 16, 16, 3)\n",
      "sep_conv_3x3 (1, 16, 16, 6)\n",
      "sep_conv_5x5 (1, 16, 16, 6)\n",
      "sep_conv_7x7 (1, 16, 16, 6)\n",
      "dil_conv_3x3 (1, 16, 16, 6)\n",
      "dil_conv_5x5 (1, 16, 16, 6)\n",
      "conv_7x1_1x7 (1, 16, 16, 6)\n",
      "Pass\n"
     ]
    }
   ],
   "source": [
    "for op in OPS:\n",
    "    model = OPS[op](6, 1)\n",
    "\n",
    "    image = tf.random_uniform([1, 16, 16, 3], 0, 255, seed=0, dtype=tf.int32)\n",
    "\n",
    "    ip = tf.placeholder(tf.float32, shape=[None, 16, 16, 3], name = \"input\")\n",
    "    out = model(ip)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        image = sess.run(image)\n",
    "        out = sess.run(out, {ip: image})\n",
    "        print(op, out.shape)\n",
    "print('Pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Skip Connection Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SkipConnection(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-7ec2179b3955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"state0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"state1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bgh/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# In graph mode, failure to build the layer's graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# implies a user-side bug. We don't catch exceptions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: call() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "t1 = tf.random_uniform([1, 16, 16, 6], 0, 255, seed=0, dtype=tf.int32)\n",
    "t2 = tf.random_uniform([1, 16, 16, 6], 0, 255, seed=0, dtype=tf.int32)\n",
    "\n",
    "s0 = tf.placeholder(tf.float32, shape=[None, 16, 16, 6], name = \"state0\")\n",
    "s1 = tf.placeholder(tf.float32, shape=[None, 16, 16, 6], name = \"state1\")\n",
    "out = model(s0, s1)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    t1 = sess.run(t1)\n",
    "    t2 = sess.run(t2)\n",
    "    out = sess.run(out, {s0: t1, s1: t2})\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bgh)",
   "language": "python",
   "name": "bgh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
